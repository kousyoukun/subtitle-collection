1
00:00:18,476 --> 00:00:23,481
"Nulla che sia grande entra nella vita
dei mortali senza una maledizione."

2
00:00:23,606 --> 00:00:27,861
SOFOCLE

3
00:00:31,156 --> 00:00:34,659
Sì, dai, siediti,
vedi se riesci a metterti comodo.

4
00:00:37,579 --> 00:00:38,580
A posto? Va bene.

5
00:00:43,043 --> 00:00:44,419
Ripresa uno. Ciac.

6
00:00:46,880 --> 00:00:48,923
Vuoi cominciare presentandoti?

7
00:00:50,467 --> 00:00:53,344
Salve, mondo. Bailey. Terza.

8
00:00:53,970 --> 00:00:56,306
- A posto?
- Questa è la parte peggiore.

9
00:00:57,515 --> 00:00:58,516
Non mi piace.

10
00:00:59,851 --> 00:01:02,228
Ho lavorato in Facebook nel 2011 e 2012.

11
00:01:02,312 --> 00:01:05,190
Sono stata
tra le prime dipendenti di Instagram.

12
00:01:05,273 --> 00:01:08,693
<i>Ho lavorato in Google, YouTube.</i>

13
00:01:08,777 --> 00:01:11,696
<i>Apple, Google, Twitter, Palm.</i>

14
00:01:12,739 --> 00:01:15,533
Ho lavorato a Mozilla Labs,
poi sono passato a Firefox.

15
00:01:15,617 --> 00:01:17,994
Stiamo girando? Tutti...

16
00:01:18,078 --> 00:01:18,953
Ottimo.

17
00:01:21,206 --> 00:01:26,169
Il mio ultimo ruolo in Twitter è stato
di vicepresidente senior Ingegneria.

18
00:01:27,462 --> 00:01:29,255
<i>Sono stato presidente di Pinterest.</i>

19
00:01:29,339 --> 00:01:32,717
Prima sono stato
Responsabile della monetizzazione

20
00:01:32,801 --> 00:01:34,260
in Facebook per cinque anni.

21
00:01:34,344 --> 00:01:37,972
In Twitter, ho gestito per qualche anno
la piattaforma di sviluppo,

22
00:01:38,056 --> 00:01:40,225
poi sono diventato
Head of Consumer Product.

23
00:01:40,308 --> 00:01:44,270
Sono stato il co-inventore
di Google Drive, Gmail Chat,

24
00:01:44,354 --> 00:01:47,232
le pagine di Facebook
e del "Mi piace" di Facebook.

25
00:01:47,440 --> 00:01:50,777
Sì. Per questo ho passato otto mesi

26
00:01:50,860 --> 00:01:52,779
a parlare con degli avvocati.

27
00:01:54,030 --> 00:01:55,406
È inquietante.

28
00:01:58,409 --> 00:02:02,914
Mentre ero lì, l'ho sempre vista
fondamentalmente come una cosa positiva.

29
00:02:03,373 --> 00:02:05,375
Non so se la penso ancora così.

30
00:02:05,458 --> 00:02:10,588
Ho lasciato Google a giugno 2017
per perplessità di carattere etico.

31
00:02:10,672 --> 00:02:14,134
E non solo in Google,
ma nel settore in generale.

32
00:02:14,217 --> 00:02:15,593
Sono molto preoccupato.

33
00:02:16,719 --> 00:02:17,804
Molto preoccupato.

34
00:02:19,097 --> 00:02:21,808
Oggi è facile perdere di vista il fatto

35
00:02:21,891 --> 00:02:27,814
che questi strumenti hanno creato
cose meravigliose nel mondo.

36
00:02:27,897 --> 00:02:31,943
Hanno riunito familiari smarriti,
hanno trovato donatori di organi.

37
00:02:32,026 --> 00:02:37,866
In tutto il mondo, ci sono stati
cambiamenti radicali importanti

38
00:02:37,949 --> 00:02:40,743
grazie a queste piattaforme,
cambiamenti positivi.

39
00:02:40,827 --> 00:02:44,956
Secondo me, siamo stati ingenui
in merito al rovescio della medaglia.

40
00:02:45,540 --> 00:02:48,585
Sono cose che, una volta lanciate,
prendono vita propria

41
00:02:48,668 --> 00:02:52,005
e vengono usate
in modo diverso da come ti aspettavi.

42
00:02:52,088 --> 00:02:56,509
Credo fermamente
che nessuno volesse queste conseguenze.

43
00:02:56,593 --> 00:02:59,554
Non c'è un solo cattivo. Assolutamente no.

44
00:03:01,639 --> 00:03:03,600
Allora, qual è il problema?

45
00:03:09,147 --> 00:03:11,357
Esiste un problema e qual è il problema?

46
00:03:18,323 --> 00:03:22,118
È difficile dire un solo...
Voglio accennare a vari problemi.

47
00:03:22,493 --> 00:03:23,661
Qual è il problema?

48
00:03:28,124 --> 00:03:32,253
UN DOCUMENTARIO ORIGINALE NETFLIX

49
00:03:33,504 --> 00:03:37,675
<i>Nonostante le crescenti critiche,</i>
<i>i colossi Big Tech stanno crescendo.</i>

50
00:03:37,759 --> 00:03:40,929
È al vaglio l'intero settore tecnologico.

51
00:03:41,012 --> 00:03:46,142
E un nuovo studio fa luce sul legame
tra salute mentale e uso dei social.

52
00:03:46,226 --> 00:03:48,478
<i>Ci parlerà delle ultime ricerche...</i>

53
00:03:49,187 --> 00:03:51,397
<i>...di cui non si parla affatto.</i>

54
00:03:51,481 --> 00:03:56,319
<i>Decine di milioni di americani soffrono</i>
<i>di dipendenza dai dispositivi elettronici.</i>

55
00:03:56,402 --> 00:03:59,364
<i>È aggravato dal fatto</i>
<i>che ora ci si può isolare...</i>

56
00:03:59,447 --> 00:04:00,698
UN AMICO TI HA TAGGATO

57
00:04:00,782 --> 00:04:02,742
...in una bolla, grazie alla tecnologia.

58
00:04:02,825 --> 00:04:06,788
Le bufale diventano più evolute
e minacciano le società di tutto il mondo.

59
00:04:06,871 --> 00:04:10,333
Non ce l'aspettavamo quando abbiamo
creato Twitter più di 12 anni fa.

60
00:04:10,416 --> 00:04:14,754
I funzionari non credono che gli attacchi
informatici russi si fermeranno.

61
00:04:14,837 --> 00:04:18,132
Stanno costringendo YouTube
a ripulire il sito.

62
00:04:18,216 --> 00:04:21,552
<i>TikTok, se parli con bambini</i>
<i>tra gli otto e i 14 anni,</i>

63
00:04:21,636 --> 00:04:24,013
<i>non li convincerai mai a cancellarlo.</i>

64
00:04:24,097 --> 00:04:26,349
Isla, puoi apparecchiare la tavola?

65
00:04:26,432 --> 00:04:29,978
<i>La domanda è se i social portano</i>
<i>i vostri figli alla depressione.</i>

66
00:04:30,061 --> 00:04:32,105
Isla, metti la tavola, per favore?

67
00:04:32,188 --> 00:04:35,316
<i>La chirurgia estetica è</i>
<i>così in voga tra gli adolescenti</i>

68
00:04:35,400 --> 00:04:37,902
che i chirurghi hanno coniato
una nuova sindrome,

69
00:04:37,986 --> 00:04:40,530
la dismorfia da Snapchat
che porta i giovani

70
00:04:40,613 --> 00:04:43,741
a richiedere interventi
per somigliare ai selfie filtrati.

71
00:04:43,825 --> 00:04:45,910
Perché gliel'hai fatto comprare?

72
00:04:45,994 --> 00:04:49,580
Che dovevo fare? Tutti gli altri
in classe sua ce l'avevano.

73
00:04:50,164 --> 00:04:51,165
Ha solo 11 anni.

74
00:04:51,249 --> 00:04:55,086
Non sei obbligata ad averne uno.
Resta sconnessa quanto vuoi.

75
00:04:55,169 --> 00:04:59,340
Ehi, sono connessa anche senza cellulare.
Sono su Internet adesso.

76
00:04:59,424 --> 00:05:03,094
E poi, non è una vera connessione,
ma solo un mucchio di...

77
00:05:03,177 --> 00:05:06,514
Il capitalismo della sorveglianza
ha plasmato politica e cultura

78
00:05:06,597 --> 00:05:08,308
in modi impercettibili a molti.

79
00:05:08,391 --> 00:05:10,101
<i>L'ISIS ha ispirato i follower</i>

80
00:05:10,184 --> 00:05:12,812
<i>e ora i suprematisti bianchi</i>
<i>fanno lo stesso.</i>

81
00:05:12,895 --> 00:05:14,147
Recentemente in India,

82
00:05:14,230 --> 00:05:17,442
<i>i linciatori online hanno ucciso</i>
<i>una dozzina di persone...</i>

83
00:05:17,525 --> 00:05:20,361
<i>Non sono semplici bufale,</i>
<i>hanno delle conseguenze.</i>

84
00:05:20,445 --> 00:05:24,073
<i>Come si fa a gestire un'epidemia</i>
<i>nell'era delle notizie false?</i>

85
00:05:24,157 --> 00:05:26,993
Si prende il coronavirus
mangiando cibo cinese?

86
00:05:27,535 --> 00:05:32,540
Siamo passati dall'era dell'informazione
all'era della disinformazione.

87
00:05:32,623 --> 00:05:34,667
La nostra democrazia è sotto attacco.

88
00:05:34,751 --> 00:05:39,005
<i>Ho detto che penso</i>
<i>che questi strumenti oggi cominciano</i>

89
00:05:39,088 --> 00:05:41,799
a minare il tessuto
e il funzionamento sociale.

90
00:06:00,151 --> 00:06:03,446
Asa fa il discorso di benvenuto.
Riproduciamo il video.

91
00:06:04,197 --> 00:06:07,325
E poi "Signore e signori, Tristan Harris".

92
00:06:07,408 --> 00:06:08,826
- Bene.
- Ottimo.

93
00:06:08,951 --> 00:06:10,495
Quindi, salgo sul palco...

94
00:06:11,621 --> 00:06:12,622
E...

95
00:06:13,915 --> 00:06:16,042
Dico: "Grazie di essere venuti."

96
00:06:17,919 --> 00:06:22,048
Oggi voglio parlare
di un nuovo programma per la tecnologia

97
00:06:22,131 --> 00:06:25,468
e lo voglio fare
perché se chiedi alla gente:

98
00:06:25,551 --> 00:06:28,137
"Cosa c'è che non va nel settore tech?"

99
00:06:28,346 --> 00:06:31,641
parte una litania
di rimostranze e scandali.

100
00:06:31,724 --> 00:06:33,893
Ci hanno rubato i dati,
induce dipendenza,

101
00:06:33,976 --> 00:06:37,730
ci sono le notizie false,
la polarizzazione, le elezioni truccate.

102
00:06:38,189 --> 00:06:41,609
Ma c'è qualcosa
alla base di tutti questi problemi

103
00:06:41,692 --> 00:06:44,612
che provoca tutte queste cose
contemporaneamente?

104
00:06:46,447 --> 00:06:48,408
- Andava bene?
- Benissimo. Sì.

105
00:06:50,827 --> 00:06:52,954
Cerco di... Voglio che capiscano...

106
00:06:53,037 --> 00:06:55,206
C'è un problema nel settore tech,

107
00:06:55,289 --> 00:07:00,211
non ha un nome
e deriva da un'unica origine...

108
00:07:05,091 --> 00:07:09,387
<i>Se ti guardi intorno, hai la sensazione</i>
<i>che il mondo stia impazzendo.</i>

109
00:07:12,765 --> 00:07:15,143
Viene da chiedersi: "È normale...

110
00:07:16,102 --> 00:07:18,771
o siamo tutti vittime di un incantesimo?"

111
00:07:22,316 --> 00:07:25,153
EX ESPERTO DI ETICA
DEL DESIGN DIGITALE GOOGLE

112
00:07:25,236 --> 00:07:27,905
COFONDATORE
CENTER FOR HUMANE TECHNOLOGY

113
00:07:27,989 --> 00:07:30,491
<i>Vorrei che più persone capissero</i>
<i>come funziona,</i>

114
00:07:30,575 --> 00:07:34,036
<i>non dovrebbero saperlo</i>
<i>solo gli addetti ai lavori.</i>

115
00:07:34,120 --> 00:07:35,788
<i>Dovrebbero saperlo tutti.</i>

116
00:07:47,383 --> 00:07:48,301
- Ehilà!
- Ciao.

117
00:07:48,843 --> 00:07:50,595
- Tristan. Piacere.
- Tristan?

118
00:07:50,678 --> 00:07:51,721
- Sì.
- Fantastico.

119
00:07:53,097 --> 00:07:55,933
<i>Harris è l'ex esperto</i>
<i>di etica del design di Google,</i>

120
00:07:56,017 --> 00:07:59,395
definito la cosa più simile
a una coscienza nella Silicon Valley.

121
00:07:59,479 --> 00:08:04,192
Chiede all'industria tecnologica
di usare un design etico per i prodotti.

122
00:08:04,275 --> 00:08:06,903
<i>È raro che un addetto ai lavori</i>
<i>sia così schietto,</i>

123
00:08:06,986 --> 00:08:10,198
<i>ma Tristan Harris crede</i>
<i>che qualcuno debba pur esserlo.</i>

124
00:08:11,324 --> 00:08:12,700
<i>Quando ero a Google,</i>

125
00:08:12,783 --> 00:08:16,037
facevo parte del team Gmail
e mi stava venendo l'esaurimento

126
00:08:16,120 --> 00:08:18,372
perché parlavamo tantissimo di...

127
00:08:19,457 --> 00:08:23,169
Dell'aspetto della posta in arrivo,
di che colore doveva essere.

128
00:08:23,252 --> 00:08:25,880
Io sentivo di avere
una dipendenza dalle email

129
00:08:26,297 --> 00:08:27,632
e trovavo affascinante

130
00:08:27,715 --> 00:08:31,511
che nessuno a Gmail cercasse di ridurre
gli aspetti che creano dipendenza.

131
00:08:31,969 --> 00:08:34,514
Così, dissi:
"Qualcun altro ci sta pensando?

132
00:08:34,597 --> 00:08:36,390
Non ne parla nessuno."

133
00:08:36,849 --> 00:08:41,229
Avvertivo questa frustrazione
verso il settore in generale,

134
00:08:41,312 --> 00:08:43,314
sentivo che avevamo perso la via.

135
00:08:46,817 --> 00:08:49,820
Mi sono sforzato per cercare di capire

136
00:08:49,904 --> 00:08:52,573
come potevamo cambiare
le cose dall'interno.

137
00:08:55,201 --> 00:08:59,497
Decisi di preparare una presentazione,
una sorta di chiamata alle armi.

138
00:09:00,998 --> 00:09:04,961
Ogni giorno tornavo a casa
e ci lavoravo un paio d'ore ogni sera.

139
00:09:06,170 --> 00:09:11,884
In pratica, diceva che era la prima volta
nella storia che 50 designer...

140
00:09:12,426 --> 00:09:15,555
bianchi tra i 20 e i 35 anni,
in California,

141
00:09:15,888 --> 00:09:20,268
avevano preso decisioni che avrebbero
avuto effetti su due miliardi di persone.

142
00:09:20,893 --> 00:09:24,438
Due miliardi di persone avranno
pensieri che non intendevano avere

143
00:09:24,522 --> 00:09:28,401
perché un designer Google ha detto:
"Le notifiche funzionano così

144
00:09:28,484 --> 00:09:30,778
sullo schermo che ti sveglia al mattino."

145
00:09:30,861 --> 00:09:35,283
E Google ha la responsabilità morale
di risolvere questo problema.

146
00:09:36,075 --> 00:09:41,581
Ho inviato questa presentazione
a 15-20 colleghi più stretti in Google.

147
00:09:41,872 --> 00:09:44,959
Ero molto agitato,
non sapevo come l'avrebbero presa.

148
00:09:46,335 --> 00:09:50,464
Al lavoro il giorno dopo, quasi tutti i PC
avevano aperta la presentazione.

149
00:09:50,548 --> 00:09:52,049
ATTENZIONE

150
00:09:52,133 --> 00:09:54,552
Arrivammo
a 400 visualizzazioni contemporanee

151
00:09:54,635 --> 00:09:56,053
e continuava a crescere.

152
00:09:56,137 --> 00:09:57,972
Ho ricevuto e-mail da tutta l'azienda.

153
00:09:58,180 --> 00:10:00,266
Da tutti i reparti dicevano:

154
00:10:00,349 --> 00:10:02,852
"Hanno questo problema anche i miei figli,

155
00:10:02,935 --> 00:10:06,689
le persone che mi circondano.
Dobbiamo fare qualcosa."

156
00:10:07,481 --> 00:10:10,818
Mi sembrava di lanciare
una rivoluzione o qualcosa del genere.

157
00:10:11,861 --> 00:10:15,197
Poi ho scoperto che Larry Page era
stato informato della presentazione

158
00:10:15,281 --> 00:10:17,366
in tre riunioni diverse quel giorno.

159
00:10:17,950 --> 00:10:23,205
Si è creata una sorta di momento culturale
che Google ha dovuto prendere sul serio.

160
00:10:26,000 --> 00:10:27,251
E poi...

161
00:10:28,377 --> 00:10:29,462
niente.

162
00:10:34,300 --> 00:10:36,135
Tutti nel 2006...

163
00:10:37,219 --> 00:10:39,221
inclusi tutti noi di Facebook,

164
00:10:39,305 --> 00:10:43,392
ammiravamo tantissimo Google
e quello che Google aveva realizzato,

165
00:10:43,476 --> 00:10:47,396
ovvero un servizio incredibilmente utile

166
00:10:47,480 --> 00:10:51,442
che, per quanto ne sapevamo,
faceva tanto bene al mondo,

167
00:10:51,525 --> 00:10:54,695
e parallelamente ha costruito
una macchina dei soldi.

168
00:10:55,404 --> 00:11:00,034
Avevamo una tale invidia
e ci sembrava estremamente elegante...

169
00:11:00,826 --> 00:11:02,161
e perfetto.

170
00:11:02,953 --> 00:11:05,122
Facebook era nato da un paio d'anni

171
00:11:05,831 --> 00:11:08,376
e io ero stato assunto
per cercare di capire

172
00:11:08,459 --> 00:11:10,586
quale doveva essere il modello d'impresa.

173
00:11:10,670 --> 00:11:13,422
Da Responsabile
della monetizzazione, il punto era:

174
00:11:13,506 --> 00:11:17,051
"Sei quello che deve capire
come far fruttare questa cosa."

175
00:11:17,134 --> 00:11:19,804
C'erano tante persone che ci lavoravano,

176
00:11:19,887 --> 00:11:25,476
ma io ero chiaramente una delle persone
che doveva far notare...

177
00:11:26,769 --> 00:11:28,479
Primo, dobbiamo fare soldi...

178
00:11:29,313 --> 00:11:33,651
e secondo me questo modello pubblicitario
è il modo più elegante.

179
00:11:43,035 --> 00:11:44,453
Mamma ha mandato un video.

180
00:11:44,537 --> 00:11:47,873
È quello di un talk show,
ma è bello. Quello è un genio.

181
00:11:47,957 --> 00:11:50,584
Parla di cancellare i social,
cosa che devi fare.

182
00:11:50,668 --> 00:11:52,878
Mi conviene bloccare le sue email.

183
00:11:52,962 --> 00:11:56,090
Non so proprio di cosa parla.
Lei è peggio di me.

184
00:11:56,173 --> 00:11:58,467
- Lo usa per le ricette.
- E il lavoro.

185
00:11:58,551 --> 00:12:00,511
- La ginnastica.
- Per sapere come stiamo.

186
00:12:00,594 --> 00:12:03,222
Noi e tutti quelli
che ha conosciuto in vita sua.

187
00:12:04,932 --> 00:12:07,893
<i>Se stai scorrendo i post del tuo social</i>

188
00:12:07,977 --> 00:12:11,731
<i>mentre ci guardi, metti giù</i>
<i>quel dannato telefono e ascolta.</i>

189
00:12:11,814 --> 00:12:14,817
La prossima ospite ha scritto
un libro straordinario

190
00:12:14,900 --> 00:12:18,112
su come ci stia rovinando la vita.

191
00:12:18,195 --> 00:12:19,447
Accogliamo l'autore

192
00:12:19,530 --> 00:12:24,076
di <i>Dieci ragioni per cancellare</i>
<i>subito i tuoi account social,</i>

193
00:12:24,493 --> 00:12:25,870
Jaron Lanier.

194
00:12:27,997 --> 00:12:31,834
<i>Aziende come Google e Facebook</i>
<i>sono tra le più ricche</i>

195
00:12:31,917 --> 00:12:33,711
e affermate di tutti i tempi.

196
00:12:34,295 --> 00:12:36,839
Hanno relativamente pochi dipendenti.

197
00:12:36,922 --> 00:12:40,468
Hanno solo un computer gigante
che fa soldi a palate.

198
00:12:41,510 --> 00:12:45,222
Per che cosa li pagano?
È una domanda molto importante.

199
00:12:47,308 --> 00:12:49,977
<i>Io investo in tecnologia da 35 anni.</i>

200
00:12:50,811 --> 00:12:54,356
<i>Nei primi 50 anni della Silicon Valley,</i>
<i>si facevano prodotti.</i>

201
00:12:54,440 --> 00:12:58,402
Hardware, software,
li vendeva ai clienti, semplice attività.

202
00:12:58,486 --> 00:13:01,447
Da dieci anni,
i giganti della Silicon Valley

203
00:13:01,530 --> 00:13:03,866
si vendono gli utenti.

204
00:13:03,949 --> 00:13:05,910
È un po' banale dirlo adesso

205
00:13:05,993 --> 00:13:09,205
ma poiché non paghiamo
i prodotti che usiamo,

206
00:13:09,288 --> 00:13:12,166
sono gli inserzionisti
a pagare questi prodotti.

207
00:13:12,249 --> 00:13:14,210
Gli inserzionisti sono i clienti.

208
00:13:14,668 --> 00:13:16,086
In vendita ci siamo noi.

209
00:13:16,170 --> 00:13:17,630
Il detto classico è:

210
00:13:17,713 --> 00:13:21,592
"Se il prodotto non lo paghi,
vuol dire che il prodotto sei tu".

211
00:13:21,675 --> 00:13:23,302
IL PRODOTTO SEI TU

212
00:13:23,385 --> 00:13:27,223
Tanti pensano che Google sia
solo una casella di ricerca

213
00:13:27,306 --> 00:13:31,101
e Facebook un posto per vedere
che fanno gli amici, le loro foto,

214
00:13:31,185 --> 00:13:35,481
ma non si rendono conto che fanno
a gara per attirare la tua attenzione.

215
00:13:36,524 --> 00:13:41,111
Facebook, Snapchat, Twitter,
Instagram, YouTube,

216
00:13:41,195 --> 00:13:45,658
il loro modello di business
è intrattenere le persone sullo schermo.

217
00:13:46,283 --> 00:13:50,955
L'obiettivo è attirare il più possibile
l'attenzione di una determinata persona.

218
00:13:51,455 --> 00:13:53,582
Quanto del tuo tempo ci dedicherai?

219
00:13:53,874 --> 00:13:56,669
Quanta della tua vita
possiamo avere per noi?

220
00:13:58,587 --> 00:14:01,090
<i>Se pensi a come funzionano queste aziende,</i>

221
00:14:01,173 --> 00:14:02,591
<i>comincia ad avere senso.</i>

222
00:14:03,050 --> 00:14:06,095
Ci sono tanti servizi su Internet
che crediamo gratuiti,

223
00:14:06,178 --> 00:14:09,473
ma non sono gratuiti,
li pagano gli inserzionisti.

224
00:14:09,557 --> 00:14:11,559
Perché pagano queste aziende?

225
00:14:11,642 --> 00:14:14,687
Li pagano perché ci facciano
vedere la loro pubblicità.

226
00:14:14,770 --> 00:14:18,357
Siamo noi il prodotto.
Comprano la nostra attenzione.

227
00:14:18,774 --> 00:14:20,442
È troppo semplicistico.

228
00:14:20,526 --> 00:14:23,654
Il prodotto è il cambiamento
graduale e impercettibile

229
00:14:23,737 --> 00:14:26,282
del tuo comportamento
e della tua percezione.

230
00:14:27,658 --> 00:14:30,244
Questo è l'unico prodotto possibile.

231
00:14:30,327 --> 00:14:34,081
Non c'è nient'altro in tavola
che si possa definire un prodotto.

232
00:14:34,164 --> 00:14:36,709
È l'unica cosa che può produrre profitti.

233
00:14:37,668 --> 00:14:39,253
Cambiare quello che fai,

234
00:14:39,336 --> 00:14:41,922
il tuo modo di pensare,
la persona che sei.

235
00:14:42,631 --> 00:14:44,967
È un cambiamento graduale. È tenue.

236
00:14:45,301 --> 00:14:48,971
Se puoi dire a qualcuno:
"Dammi dieci milioni di dollari

237
00:14:49,054 --> 00:14:54,310
e io cambierò il mondo dell'uno percento
nella direzione che vuoi tu..."

238
00:14:54,810 --> 00:14:58,188
Il mondo intero! Vale un sacco di soldi.

239
00:15:00,691 --> 00:15:04,570
<i>È quello che ogni azienda</i>
<i>ha sempre sognato,</i>

240
00:15:04,653 --> 00:15:10,910
avere la garanzia
che la sua pubblicità avrà successo.

241
00:15:11,327 --> 00:15:13,996
È questo il loro business.
Vendono certezze.

242
00:15:14,079 --> 00:15:14,914
CERTEZZA

243
00:15:14,997 --> 00:15:19,460
<i>Per avere successo in questo settore,</i>
<i>devi avere ottime previsioni.</i>

244
00:15:19,543 --> 00:15:20,544
OTTIME PREVISIONI

245
00:15:20,628 --> 00:15:24,173
<i>Le ottime predizioni</i>
<i>iniziano con un imperativo.</i>

246
00:15:25,215 --> 00:15:26,926
<i>Servono tanti dati.</i>

247
00:15:27,009 --> 00:15:29,053
DATI

248
00:15:29,136 --> 00:15:31,555
Tanti lo chiamano
capitalismo della sorveglianza.

249
00:15:31,639 --> 00:15:34,350
Il capitalismo
che trae profitto dal monitoraggio

250
00:15:34,433 --> 00:15:38,062
dei luoghi in cui vanno tutti
da parte dei colossi della tecnologia

251
00:15:38,145 --> 00:15:42,858
il cui interesse è garantire
il massimo successo agli inserzionisti.

252
00:15:42,942 --> 00:15:45,569
Questo è un nuovo tipo di mercato.

253
00:15:45,653 --> 00:15:48,072
È un mercato mai esistito prima.

254
00:15:48,822 --> 00:15:55,371
Ed è un mercato che tratta
esclusivamente proiezioni di borsa umane.

255
00:15:56,080 --> 00:16:01,585
Ci sono mercati che trattano le proiezioni
della pancetta di maiale o del petrolio.

256
00:16:02,127 --> 00:16:07,591
Ora abbiamo mercati che trattano
proiezioni di borsa umane su larga scala.

257
00:16:08,175 --> 00:16:13,472
E questi mercati hanno prodotto
le migliaia di miliardi di dollari

258
00:16:14,014 --> 00:16:19,269
che hanno fatto delle società Internet
le aziende più ricche

259
00:16:19,353 --> 00:16:20,854
nella storia...

260
00:16:21,438 --> 00:16:22,815
dell'umanità.

261
00:16:27,403 --> 00:16:31,073
<i>La gente deve sapere</i>
<i>che tutto quello che fa online</i>

262
00:16:31,156 --> 00:16:34,326
<i>viene osservato, tracciato e misurato.</i>

263
00:16:35,035 --> 00:16:39,623
Ogni singola cosa che fai viene
attentamente monitorata e registrata.

264
00:16:39,707 --> 00:16:43,836
Su quale immagine ti soffermi
per guardarla e per quanto tempo.

265
00:16:43,919 --> 00:16:45,796
Sì, per quanto tempo la guardi.

266
00:16:45,879 --> 00:16:47,631
NAVIYA_R
TEMPO DI COINVOLGIMENTO

267
00:16:47,715 --> 00:16:49,883
RYAN_M
TEMPO DI COINVOLGIMENTO

268
00:16:50,509 --> 00:16:53,804
<i>Sanno se le persone si sentono sole</i>
<i>o se sono depresse.</i>

269
00:16:53,887 --> 00:16:57,099
<i>Sanno se guardano le foto dei propri ex.</i>

270
00:16:57,182 --> 00:17:00,853
<i>Sanno cosa fai a notte fonda,</i>
<i>praticamente sanno tutto.</i>

271
00:17:01,270 --> 00:17:03,230
<i>Se sei introverso o estroverso,</i>

272
00:17:03,313 --> 00:17:06,316
<i>che tipo di fobie hai,</i>
<i>che tipo di personalità hai.</i>

273
00:17:08,193 --> 00:17:11,613
<i>Hanno più informazioni su di noi</i>

274
00:17:11,697 --> 00:17:14,575
<i>di quanto si sia mai</i>
<i>immaginato nella storia umana.</i>

275
00:17:14,950 --> 00:17:16,618
<i>È una cosa senza precedenti.</i>

276
00:17:18,579 --> 00:17:22,458
Tutti questi dati
che riversiamo continuamente

277
00:17:22,875 --> 00:17:26,962
alimentano questi sistemi
senza quasi nessuna supervisione umana

278
00:17:27,463 --> 00:17:30,674
e che fanno previsioni sempre migliori

279
00:17:30,966 --> 00:17:33,302
su cosa faremo e su chi siamo.

280
00:17:34,887 --> 00:17:36,346
CONSIGLIATO PER TE

281
00:17:36,430 --> 00:17:39,892
<i>Tanti si fanno l'idea sbagliata</i>
<i>che si vendano nostri dati.</i>

282
00:17:40,350 --> 00:17:43,187
Non è nell'interesse di Facebook
cedere i dati.

283
00:17:45,522 --> 00:17:47,232
<i>Che ci fanno con questi dati?</i>

284
00:17:51,070 --> 00:17:54,490
<i>Costruiscono modelli</i>
<i>che prevedono le nostre azioni.</i>

285
00:17:54,573 --> 00:17:57,326
<i>E chi ha il modello migliore vince.</i>

286
00:18:02,623 --> 00:18:04,041
Scorrimento più lento.

287
00:18:04,124 --> 00:18:07,002
Siamo a fine del tempo medio,
ridurre carico annunci.

288
00:18:07,086 --> 00:18:08,921
Passa ad amici e parenti.

289
00:18:09,546 --> 00:18:11,340
<i>Dall'altra parte dello schermo,</i>

290
00:18:11,423 --> 00:18:15,469
<i>è quasi come se avessero</i>
<i>un nostro avatar tipo bambola vudù.</i>

291
00:18:16,762 --> 00:18:19,473
<i>Tutte le cose</i>
<i>che abbiamo fatto, i nostri clic,</i>

292
00:18:19,556 --> 00:18:21,642
i video che abbiamo visto, i Mi piace

293
00:18:21,725 --> 00:18:25,354
vengono riutilizzati per costruire
un modello sempre più preciso.

294
00:18:25,854 --> 00:18:29,858
Una volta realizzato il modello,
puoi prevedere cosa farà quella persona.

295
00:18:29,942 --> 00:18:31,777
Bene, faccio una prova.

296
00:18:32,569 --> 00:18:33,487
<i>Dove andrai,</i>

297
00:18:33,570 --> 00:18:36,115
<i>quali video possono interessarti di più,</i>

298
00:18:36,198 --> 00:18:39,159
<i>quali emozioni</i>
<i>suscitano in te una reazione.</i>

299
00:18:39,243 --> 00:18:40,410
Sì, perfetto.

300
00:18:41,370 --> 00:18:42,788
Gli<i> epic fail</i> dell'anno.

301
00:18:48,544 --> 00:18:51,088
- Ha funzionato.
- Vado con un altro video.

302
00:18:51,171 --> 00:18:54,466
Bellissimo. Infiliamoci
una pubblicità prima che cominci.

303
00:18:56,343 --> 00:18:59,721
<i>Tante aziende tecnologiche</i>
<i>hanno tre obiettivi principali.</i>

304
00:18:59,805 --> 00:19:03,809
<i>C'è l'obiettivo del coinvolgimento</i>
<i>per aumentare l'uso dei contenuti.</i>

305
00:19:04,601 --> 00:19:06,145
C'è l'obiettivo di crescita

306
00:19:06,228 --> 00:19:10,774
<i>per farti tornare, invitare gli amici,</i>
<i>fare in modo che questi ne invitino altri.</i>

307
00:19:11,650 --> 00:19:14,987
Poi c'è l'obiettivo pubblicitario
per cui, mentre succede questo,

308
00:19:15,070 --> 00:19:17,406
guadagniamo con le pubblicità.

309
00:19:19,366 --> 00:19:21,994
Ognuno di questi obiettivi
si avvale di algoritmi

310
00:19:22,077 --> 00:19:26,415
che calcolano cosa farti vedere
per continuare a far salire i numeri.

311
00:19:26,623 --> 00:19:29,918
In Facebook
parlavamo spesso di questa idea

312
00:19:30,002 --> 00:19:34,006
di poterlo manovrare
con una manopola in base alle esigenze.

313
00:19:34,673 --> 00:19:38,510
E parlavamo del fatto
che la manopola l'avesse Mark.

314
00:19:41,305 --> 00:19:44,349
"Ehi, voglio più utenti in Corea oggi."

315
00:19:45,684 --> 00:19:46,685
Gira la manopola.

316
00:19:47,394 --> 00:19:48,896
"Aumentiamo gli annunci."

317
00:19:49,980 --> 00:19:51,815
"Aumentiamo la monetizzazione."

318
00:19:52,858 --> 00:19:53,984
Perciò...

319
00:19:54,610 --> 00:19:59,239
in tutte queste aziende,
c'è questo livello di precisione.

320
00:19:59,990 --> 00:20:02,409
Non so come non mi abbiano ammonito.

321
00:20:02,492 --> 00:20:05,704
- L'arbitro faceva schifo.
- Sei arrivato fino…

322
00:20:05,787 --> 00:20:08,457
- È Rebecca. Vai a parlarle.
- So chi è.

323
00:20:08,624 --> 00:20:10,834
- Vai a parlarle.
- Ci sto lavorando.

324
00:20:10,918 --> 00:20:14,421
Il calendario dice che è in pausa.
Dovremmo essere in diretta.

325
00:20:15,255 --> 00:20:16,465
Lo sollecito?

326
00:20:17,132 --> 00:20:18,050
Sbizzarrisciti.

327
00:20:21,595 --> 00:20:24,181
"È entrato il tuo amico Tyler. Salutalo."

328
00:20:26,016 --> 00:20:27,184
Andiamo, amico.

329
00:20:27,267 --> 00:20:28,769
Saluta.

330
00:20:29,394 --> 00:20:31,647
Non sei nemmeno... Vai a parlarle.

331
00:20:31,730 --> 00:20:34,775
È APPENA ENTRATO
IL TUO AMICO TYLER! SALUTALO!

332
00:20:36,902 --> 00:20:37,986
CONNESSIONI DI RETE

333
00:20:38,070 --> 00:20:40,447
Nuovo link! Va bene, ci siamo.

334
00:20:40,948 --> 00:20:46,078
Continua con un post
dell'utente 079044238820, Rebecca.

335
00:20:46,161 --> 00:20:49,790
Buona idea. Le coordinate GPS
indicano che sono vicini.

336
00:20:52,167 --> 00:20:55,837
REBECCA_G
HO TROVATO L'ANIMA GEMELLA!

337
00:20:55,921 --> 00:20:57,506
È pronto per un annuncio.

338
00:20:57,631 --> 00:20:58,632
Vai con l'asta.

339
00:20:58,715 --> 00:21:00,050
ANTEPRIMA
CERA CAPELLI

340
00:21:00,133 --> 00:21:02,803
Venduto! Alla cera per capelli.

341
00:21:03,387 --> 00:21:07,933
C'erano 468 offerenti. Abbiamo venduto
Ben a 3.262 cent a immagine.

342
00:21:17,109 --> 00:21:21,530
<i>Abbiamo creato un mondo</i>
<i>in cui essere connessi è fondamentale,</i>

343
00:21:22,072 --> 00:21:23,907
<i>soprattutto per i giovani,</i>

344
00:21:23,991 --> 00:21:28,328
<i>e tuttavia, in questo mondo,</i>
<i>ogni volta che due persone si collegano,</i>

345
00:21:29,162 --> 00:21:33,250
l'unico modo per finanziarlo
è attraverso una terza persona nascosta

346
00:21:33,333 --> 00:21:35,627
che paga per manipolare
quelle due persone.

347
00:21:36,128 --> 00:21:39,381
Abbiamo creato
una generazione mondiale di persone

348
00:21:39,464 --> 00:21:44,011
che crescono in un contesto
in cui il senso della comunicazione,

349
00:21:44,094 --> 00:21:47,431
il senso stesso di cultura
è la manipolazione.

350
00:21:47,514 --> 00:21:52,311
Abbiamo messo l'inganno e il raggiro
al centro di tutto ciò che facciamo.

351
00:21:55,355 --> 00:21:59,276
"Una tecnologia sufficientemente avanzata
è indistinguibile dalla magia."

352
00:22:05,741 --> 00:22:07,242
- Prendi l'altro...
- Ok.

353
00:22:07,326 --> 00:22:09,369
- Dove la tengo?
- Va benissimo.

354
00:22:09,453 --> 00:22:10,620
- Qui?
- Sì.

355
00:22:10,704 --> 00:22:13,707
Come viene in video se faccio...

356
00:22:13,790 --> 00:22:15,459
- Beh, possiamo...
- Così?

357
00:22:15,542 --> 00:22:16,835
- Cosa?
- Sì.

358
00:22:16,918 --> 00:22:18,545
- Fallo di nuovo.
- Esatto, sì.

359
00:22:19,046 --> 00:22:20,589
No, probabilmente non...

360
00:22:22,466 --> 00:22:23,884
Questo è meno...

361
00:22:31,016 --> 00:22:33,393
Chris qui sta letteralmente impazzendo.

362
00:22:34,728 --> 00:22:35,562
Vi piace?

363
00:22:35,645 --> 00:22:37,773
MAGIA!

364
00:22:37,856 --> 00:22:41,068
<i>Avevo cinque anni</i>
<i>quando ho imparato i giochi di prestigio.</i>

365
00:22:41,151 --> 00:22:45,781
<i>Sarei in grado di ingannare gli adulti,</i>
<i>adulti laureati.</i>

366
00:22:54,915 --> 00:22:58,960
<i>I prestigiatori sono stati quasi</i>
<i>come i primi neuroscienziati e psicologi.</i>

367
00:22:59,044 --> 00:23:03,382
<i>Sono stati loro a capire per primi</i>
<i>come funziona la mente delle persone.</i>

368
00:23:04,216 --> 00:23:07,719
<i>Loro provano in tempo reale</i>
<i>un sacco di cose con le persone.</i>

369
00:23:09,137 --> 00:23:14,017
Un mago capisce una parte della mente
che noi non conosciamo.

370
00:23:14,101 --> 00:23:15,936
Perciò, l'illusione funziona.

371
00:23:16,019 --> 00:23:20,607
Medici, avvocati, gente
che sa costruire 747 o missili nucleari

372
00:23:20,690 --> 00:23:24,361
non ne sanno di più
sulla vulnerabilità della loro mente.

373
00:23:24,444 --> 00:23:26,113
È una disciplina a parte,

374
00:23:26,571 --> 00:23:28,990
che riguarda tutti gli esseri umani.

375
00:23:30,909 --> 00:23:34,079
<i>Da questa prospettiva,</i>
<i>si ha un'idea molto diversa</i>

376
00:23:34,162 --> 00:23:35,831
<i>di cosa faccia la tecnologia.</i>

377
00:23:36,873 --> 00:23:41,044
<i>Allo Stanford Persuasive Technology Lab</i>
<i>studiavamo proprio questo.</i>

378
00:23:41,628 --> 00:23:45,882
Come sfruttare ciò che sappiamo
di cosa persuada la gente

379
00:23:45,966 --> 00:23:48,385
e integrarlo nella tecnologia.

380
00:23:48,468 --> 00:23:50,887
Tanti tra il pubblico sono già dei geni.

381
00:23:50,971 --> 00:23:55,851
È così, ma il mio obiettivo è trasformarvi
in geni del cambiamento comportamentale.

382
00:23:56,852 --> 00:24:01,148
Tanti nomi importanti della Silicon Valley
hanno seguito quel corso,

383
00:24:01,231 --> 00:24:05,485
<i>personaggi importanti</i>
<i>di Facebook, Uber e altre aziende,</i>

384
00:24:05,569 --> 00:24:09,197
per imparare
a rendere più persuasiva la tecnologia.

385
00:24:09,614 --> 00:24:10,824
<i>C'era anche Tristan.</i>

386
00:24:12,242 --> 00:24:16,538
La tecnologia persuasiva è un design
volutamente applicato all'estremo

387
00:24:16,621 --> 00:24:18,874
per modificare
il comportamento delle persone.

388
00:24:18,957 --> 00:24:23,336
Vogliamo che facciano qualcosa,
che continuino a fare così col dito.

389
00:24:23,420 --> 00:24:26,256
Se scorri giù e aggiorni,
sopra esce una cosa nuova.

390
00:24:26,339 --> 00:24:28,508
Scorri, aggiorni, nuovo. Ogni volta.

391
00:24:28,592 --> 00:24:33,513
<i>In psicologia, lo chiamiamo</i>
<i>rinforzo intermittente positivo.</i>

392
00:24:33,805 --> 00:24:37,142
Non sai quando ti comparirà
né se ti comparirà.

393
00:24:37,225 --> 00:24:40,061
Funziona come le slot machine a Las Vegas.

394
00:24:40,145 --> 00:24:42,230
Non basta che usi il prodotto
consapevolmente,

395
00:24:42,314 --> 00:24:44,024
voglio entrarti nel cervello

396
00:24:44,107 --> 00:24:47,652
e impiantare dentro di te
un'abitudine inconscia,

397
00:24:47,736 --> 00:24:50,864
per programmarti
a un livello più profondo.

398
00:24:50,947 --> 00:24:52,115
Non te ne accorgi.

399
00:24:52,491 --> 00:24:54,034
Un certo James Marshall...

400
00:24:54,117 --> 00:24:56,286
<i>Ogni volta che lo vedi sul tavolo</i>

401
00:24:56,369 --> 00:25:01,333
e lo guardi, sai che se ti allunghi,
potrebbe esserci qualcosa per te.

402
00:25:01,416 --> 00:25:06,046
Giochi alla slot per vedere cosa esce.
Non è un caso. È una tecnica ben precisa.

403
00:25:06,129 --> 00:25:11,134
Porta una pepita d'oro a un ufficiale
dell'esercito a San Francisco.

404
00:25:12,135 --> 00:25:15,388
Attenzione, la popolazione
di San Francisco era solo...

405
00:25:15,472 --> 00:25:18,016
<i>Un altro esempio sono le foto taggate.</i>

406
00:25:19,726 --> 00:25:24,064
<i>Se ricevi un'e-mail che dice</i>
<i>che un amico ti ha taggato in una foto,</i>

407
00:25:24,147 --> 00:25:28,568
<i>è chiaro che cliccherai sull'email</i>
<i>per vedere la foto.</i>

408
00:25:29,152 --> 00:25:31,821
<i>Non è una cosa</i>
<i>che decidi di ignorare così.</i>

409
00:25:32,364 --> 00:25:36,326
Sfruttano proprio la personalità umana
profondamente radicata.

410
00:25:36,409 --> 00:25:40,288
Quello che devi chiederti è:
"Perché la mail non ha già la foto?

411
00:25:40,372 --> 00:25:42,457
Sarebbe molto più facile vederla."

412
00:25:42,541 --> 00:25:45,919
Quando Facebook ha trovato
questa funzione, l'ha sfruttata al massimo

413
00:25:46,002 --> 00:25:48,505
pensando di far crescere l'attività.

414
00:25:48,588 --> 00:25:51,091
"Facciamo
che si tagghino tutto il giorno."

415
00:25:56,263 --> 00:25:58,890
BEN_W
ALMENO UNO DI NOI È FOTOGENICO

416
00:25:59,349 --> 00:26:00,475
Ha commentato.

417
00:26:00,559 --> 00:26:01,434
Bello.

418
00:26:01,935 --> 00:26:04,688
Rebecca l'ha ricevuto e sta rispondendo.

419
00:26:04,771 --> 00:26:07,566
Avvertilo che sta scrivendo,
così non lo perdiamo.

420
00:26:07,649 --> 00:26:09,150
Attivo puntini sospensivi.

421
00:26:09,234 --> 00:26:13,613
ALMENO UNO DI NOI È FOTOGENICO

422
00:26:19,452 --> 00:26:20,745
Bene, ha postato.

423
00:26:21,454 --> 00:26:24,833
Lui commenta il commento di lei
al suo commento al suo post.

424
00:26:25,041 --> 00:26:26,668
Ha smesso di scrivere.

425
00:26:26,751 --> 00:26:28,336
Completamento automatico.

426
00:26:28,420 --> 00:26:30,005
Emoticon. Le adora.

427
00:26:31,381 --> 00:26:33,758
COMPLETAMENTO AUTOMATICO
COINVOLGIMENTO

428
00:26:33,842 --> 00:26:35,260
Ha scelto il fuoco.

429
00:26:35,385 --> 00:26:36,803
Tifavo per la melanzana.

430
00:26:38,597 --> 00:26:42,726
<i>C'è tutta una disciplina</i>
<i>che si chiama</i> growth hacking.

431
00:26:42,809 --> 00:26:47,147
Ingegneri che hanno il compito
di entrare nella psicologia della gente

432
00:26:47,230 --> 00:26:48,565
per aumentare la crescita.

433
00:26:48,648 --> 00:26:50,984
Più iscrizioni, più coinvolgimento,

434
00:26:51,067 --> 00:26:52,861
più inviti di altre persone.

435
00:26:52,944 --> 00:26:57,907
Dopo tutti i test, le iterazioni eccetera,
la cosa più importante che abbiamo capito?

436
00:26:57,991 --> 00:27:00,535
Porta tutti a sette amici in dieci giorni.

437
00:27:00,619 --> 00:27:01,870
EX VP CRESCITA FACEBOOK

438
00:27:01,953 --> 00:27:02,787
Tutto qui.

439
00:27:02,871 --> 00:27:05,498
Chamath è stato Head of Growth in Facebook

440
00:27:05,582 --> 00:27:08,251
ed è molto noto
nel settore della tecnologia

441
00:27:08,335 --> 00:27:11,004
per aver aperto la strada a molte tattiche

442
00:27:11,087 --> 00:27:14,758
che sono state usate per far crescere
Facebook a una velocità incredibile,

443
00:27:14,841 --> 00:27:18,553
tattiche che sono diventate
il manuale standard della Silicon Valley.

444
00:27:18,637 --> 00:27:21,222
Sono state usate da Uber
e da altre aziende.

445
00:27:21,306 --> 00:27:27,062
Una delle cose che ha usato per primo
sono stati i test A/B scientifici

446
00:27:27,145 --> 00:27:28,480
di modifiche di funzionalità.

447
00:27:29,022 --> 00:27:30,940
Aziende come Google e Facebook

448
00:27:31,024 --> 00:27:36,821
implementavano tanti piccoli esperimenti
che facevano costantemente sugli utenti,

449
00:27:36,905 --> 00:27:39,866
e col passare del tempo,
facendo questi esperimenti

450
00:27:39,949 --> 00:27:45,288
si sviluppa il modo ottimale
per far fare agli utenti quello che vuoi.

451
00:27:45,372 --> 00:27:46,790
È manipolazione.

452
00:27:47,332 --> 00:27:49,250
Mi sento un topo da laboratorio.

453
00:27:49,834 --> 00:27:51,920
Siamo tutti topi da laboratorio.

454
00:27:52,545 --> 00:27:55,548
Non siamo cavie
per trovare la cura per il cancro.

455
00:27:55,632 --> 00:27:58,134
Non cercano di portarci dei benefici.

456
00:27:58,218 --> 00:28:02,931
Siamo zombie e vogliono che guardiamo
più annunci per fare più soldi.

457
00:28:03,556 --> 00:28:08,228
<i>Facebook ha condotto i cosiddetti</i>
<i>"esperimenti di contagio su vasta scala".</i>

458
00:28:09,145 --> 00:28:12,857
<i>Come facciamo a usare</i>
<i>messaggi subliminali sulle pagine Facebook</i>

459
00:28:13,400 --> 00:28:17,570
per convincere più persone
a votare alle elezioni di metà mandato?

460
00:28:17,987 --> 00:28:20,824
E hanno scoperto
che erano in grado di farlo.

461
00:28:20,907 --> 00:28:24,160
Una cosa che hanno concluso
è che ora sappiamo

462
00:28:24,744 --> 00:28:28,915
di poter influenzare
comportamenti ed emozioni

463
00:28:28,998 --> 00:28:32,877
senza mai allertare
la consapevolezza degli utenti.

464
00:28:33,378 --> 00:28:37,382
Non ne hanno la minima idea.

465
00:28:38,049 --> 00:28:41,970
Stiamo puntando questi motori di IA
di nuovo su noi stessi

466
00:28:42,053 --> 00:28:46,224
per decodificare
cosa stimoli le nostre risposte.

467
00:28:46,599 --> 00:28:49,018
Come se stimolassero
le cellule nervose di un ragno

468
00:28:49,102 --> 00:28:51,479
per vedere quando reagiscono le zampe.

469
00:28:51,938 --> 00:28:53,940
È una sorta di esperimento carcerario

470
00:28:54,023 --> 00:28:56,735
dove le persone si trovano
incastrate in una simulazione

471
00:28:56,818 --> 00:29:01,489
e raccogliamo i soldi e i dati derivanti
dalla loro attività per guadagnarci.

472
00:29:01,573 --> 00:29:03,616
Non ne siamo neanche consapevoli.

473
00:29:04,117 --> 00:29:07,912
Vogliamo capire come manipolarti
il più rapidamente possibile

474
00:29:07,996 --> 00:29:10,081
e poi darti una botta di dopamina.

475
00:29:10,165 --> 00:29:12,542
L'abbiamo fatto
magistralmente in Facebook.

476
00:29:12,625 --> 00:29:17,380
L'hanno fatto Instagram,
Whatsapp, Snapchat, Twitter.

477
00:29:17,464 --> 00:29:19,424
È esattamente il genere di cosa

478
00:29:19,507 --> 00:29:22,427
a cui penserebbe un hacker come me

479
00:29:22,510 --> 00:29:27,015
perché si sfrutta
una fragilità della psicologia umana.

480
00:29:27,098 --> 00:29:28,725
EX PRESIDENTE FACEBOOK

481
00:29:28,808 --> 00:29:33,438
Penso che noi, inventori e creatori...

482
00:29:33,980 --> 00:29:37,317
Sono io, è Mark, è il...

483
00:29:37,400 --> 00:29:40,570
Kevin Systrom di Instagram,
sono tutte queste persone...

484
00:29:41,154 --> 00:29:46,451
l'abbiamo capito consapevolmente
e l'abbiamo fatto lo stesso.

485
00:29:50,580 --> 00:29:53,958
Nessuno ha avuto da ridire
quando hanno inventato le bici.

486
00:29:55,043 --> 00:29:58,797
Quando tutti hanno iniziato
a girare in bici, nessuno ha detto:

487
00:29:58,880 --> 00:30:03,051
"Oddio, abbiamo rovinato la società.
Le bici influenzano le persone,

488
00:30:03,134 --> 00:30:05,303
le allontanano dai figli,

489
00:30:05,386 --> 00:30:08,723
rovinano la democrazia,
la gente non sa cosa sia vero."

490
00:30:08,807 --> 00:30:11,601
Non abbiamo detto
cose così delle biciclette.

491
00:30:12,769 --> 00:30:16,147
Se una cosa è uno strumento,
vuol dire che se ne sta lì...

492
00:30:16,731 --> 00:30:18,733
ad aspettare pazientemente.

493
00:30:19,317 --> 00:30:22,821
Se una cosa non è uno strumento,
pretende da te delle cose,

494
00:30:22,904 --> 00:30:26,533
ti seduce, ti manipola,
vuole qualcosa da te.

495
00:30:26,950 --> 00:30:30,745
Siamo passati da un ambiente tecnologico
basato sugli strumenti

496
00:30:30,829 --> 00:30:34,499
a un ambiente tecnologico
basato su dipendenza e manipolazione.

497
00:30:34,582 --> 00:30:35,708
Ecco cos'è cambiato.

498
00:30:35,792 --> 00:30:39,420
I social non sono uno strumento
che aspetta di essere usato.

499
00:30:39,504 --> 00:30:43,341
Ha i suoi scopi
e ha i suoi mezzi per perseguirli

500
00:30:43,424 --> 00:30:45,677
usando la tua psicologia contro di te.

501
00:30:48,805 --> 00:30:51,933
"Solo due settori
chiamano i loro clienti 'utilizzatori':

502
00:30:52,016 --> 00:30:53,726
le droghe illegali e il software".

503
00:30:57,564 --> 00:31:02,193
Ripensando a qualche anno fa,
ero presidente di Pinterest.

504
00:31:03,152 --> 00:31:08,366
Tornavo a casa e non riuscivo
a staccarmi dal telefono,

505
00:31:08,449 --> 00:31:12,161
anche se avevo due bambini
che avevano bisogno del mio affetto.

506
00:31:12,245 --> 00:31:17,542
Ero nello stanzino a scrivere una mail
o a volte a guardare Pinterest.

507
00:31:18,001 --> 00:31:23,381
Ho pensato: "Il classico paradosso.
Di giorno lavoro per costruire qualcosa...

508
00:31:23,840 --> 00:31:26,426
di cui poi divento vittima."

509
00:31:26,509 --> 00:31:30,096
In certi momenti,
non riuscivo a trattenermi.

510
00:31:32,307 --> 00:31:36,102
Quello che uso di più è Twitter.

511
00:31:36,728 --> 00:31:38,021
Prima era Reddit.

512
00:31:38,104 --> 00:31:42,859
Ho dovuto scrivere un software per me
per porre fine alla dipendenza da Reddit.

513
00:31:45,403 --> 00:31:47,780
Sono più dipendente dall'email.

514
00:31:47,864 --> 00:31:49,866
Sul serio. Insomma, lo sento.

515
00:31:52,577 --> 00:31:54,954
Beh, è interessante il fatto

516
00:31:55,038 --> 00:31:58,166
che pur sapendo
cosa succedeva dietro le quinte,

517
00:31:58,249 --> 00:32:01,628
comunque non riuscivo
a darmi una regolata.

518
00:32:01,711 --> 00:32:03,046
Fa un po' paura.

519
00:32:03,630 --> 00:32:07,050
Anche se so come funzionano
questi trucchi, li subisco anch'io.

520
00:32:07,133 --> 00:32:09,886
Anch'io perdo la cognizione
del tempo col cellulare.

521
00:32:12,805 --> 00:32:15,725
Controlli lo smartphone
prima di fare pipì la mattina

522
00:32:15,808 --> 00:32:17,477
o mentre fai pipì la mattina?

523
00:32:17,560 --> 00:32:19,479
Sono le uniche due possibilità.

524
00:32:19,562 --> 00:32:23,274
Ho provato con la sola forza di volontà...

525
00:32:23,358 --> 00:32:26,903
"Poso il telefono,
lascio il telefono in macchina."

526
00:32:26,986 --> 00:32:30,573
Me lo sarò detto mille volte
in mille giorni diversi:

527
00:32:30,657 --> 00:32:34,535
"Non porto il telefono in camera da letto"
e poi arrivano le nove di sera.

528
00:32:34,619 --> 00:32:37,121
"Voglio portare il telefono in camera."

529
00:32:37,956 --> 00:32:41,125
La forza di volontà
è stato il mio primo tentativo

530
00:32:41,209 --> 00:32:44,295
e il secondo è stata la forza bruta.

531
00:32:44,379 --> 00:32:49,801
<i>Vi presento la cassaforte per cucina,</i>
<i>un nuovo contenitore rivoluzionario</i>

532
00:32:49,884 --> 00:32:51,678
<i>che aiuta a combattere le tentazioni.</i>

533
00:32:51,761 --> 00:32:56,724
<i>David non deve far altro</i>
<i>che mettere le tentazioni in cassaforte.</i>

534
00:32:57,392 --> 00:33:00,561
<i>Poi, ruota la manopola</i>
<i>per impostare il timer,</i>

535
00:33:01,437 --> 00:33:04,232
<i>infine preme la manopola</i>
<i>per attivare il blocco.</i>

536
00:33:04,315 --> 00:33:05,525
<i>La cassaforte...</i>

537
00:33:05,608 --> 00:33:06,776
Noi ce l'abbiamo?

538
00:33:06,859 --> 00:33:08,569
<i>...carte di credito e cellulari.</i>

539
00:33:08,653 --> 00:33:09,654
Sì, ce l'abbiamo.

540
00:33:09,737 --> 00:33:13,866
<i>Una volta bloccata, non si apre più</i>
<i>finché il timer non arriva a zero.</i>

541
00:33:13,950 --> 00:33:17,537
Allora, il fatto è questo.
I social sono una droga.

542
00:33:17,620 --> 00:33:20,873
Insomma, abbiamo
l'urgenza biologica di base

543
00:33:20,957 --> 00:33:23,084
di connetterci con altre persone.

544
00:33:23,167 --> 00:33:28,214
Questo influisce sul rilascio di dopamina
nel circuito di gratificazione.

545
00:33:28,297 --> 00:33:32,552
Milioni di anni di evoluzione
sono alla base di questo sistema

546
00:33:32,635 --> 00:33:35,596
che ci spinge a riunirci
e vivere in comunità,

547
00:33:35,680 --> 00:33:38,016
trovare un compagno e a riprodurci.

548
00:33:38,099 --> 00:33:41,853
Non c'è dubbio
che un canale come i social,

549
00:33:41,936 --> 00:33:45,690
che ottimizza
questa connessione tra le persone,

550
00:33:45,773 --> 00:33:48,568
può potenzialmente generare dipendenze.

551
00:33:52,780 --> 00:33:54,115
Papà, piantala!

552
00:33:55,450 --> 00:33:58,453
Ho altri mille <i>snip</i>
da mandare prima di cena.

553
00:33:58,536 --> 00:33:59,537
<i>Snip?</i>

554
00:33:59,620 --> 00:34:01,080
Non so cosa sia uno <i>snip.</i>

555
00:34:01,164 --> 00:34:03,207
- Che buon odore.
- Grazie.

556
00:34:03,291 --> 00:34:05,877
Pensavo potessimo usare
tutti e cinque i sensi

557
00:34:05,960 --> 00:34:07,712
per gustarci la cena.

558
00:34:07,795 --> 00:34:11,382
Perciò, stasera non ci saranno
cellulari a tavola.

559
00:34:11,466 --> 00:34:13,301
Perciò, consegnateli.

560
00:34:13,801 --> 00:34:14,802
- Davvero?
- Sì.

561
00:34:15,928 --> 00:34:18,056
- Va bene.
- Grazie. Ben?

562
00:34:18,139 --> 00:34:19,891
Mamma, pirata dei telefoni.

563
00:34:21,100 --> 00:34:22,518
- Preso.
- Mamma!

564
00:34:22,602 --> 00:34:26,147
Staranno al sicuro qui dentro
fino a dopo cena...

565
00:34:27,273 --> 00:34:31,277
e potremo tutti rilassarci, ok?

566
00:34:47,418 --> 00:34:48,628
Posso vedere chi è?

567
00:34:54,759 --> 00:34:56,969
Vado a prendere un'altra forchetta.

568
00:34:58,304 --> 00:34:59,263
Grazie.

569
00:35:04,727 --> 00:35:06,771
Tesoro, non lo puoi aprire.

570
00:35:06,854 --> 00:35:09,440
È bloccato per un'ora, lascialo stare.

571
00:35:11,192 --> 00:35:13,361
Allora, di cosa vogliamo parlare?

572
00:35:13,444 --> 00:35:17,907
Beh, potremmo parlare dei pazzi
dell'Extreme Center che ho visto oggi.

573
00:35:17,990 --> 00:35:18,825
- Ti prego.
- Cosa?

574
00:35:18,908 --> 00:35:20,785
Non voglio parlare di politica.

575
00:35:20,868 --> 00:35:23,538
- Cos'ha che non va l'Extreme Center?
- Non ha capito.

576
00:35:23,621 --> 00:35:24,622
Dipende a chi chiedi.

577
00:35:24,705 --> 00:35:27,208
È come chiedere:
"Cos'ha che non va la propaganda?"

578
00:35:28,709 --> 00:35:29,710
Isla!

579
00:35:32,797 --> 00:35:33,756
Oh, mio Dio.

580
00:35:36,968 --> 00:35:37,802
Vuoi che...

581
00:35:41,848 --> 00:35:43,933
<i>Sono preoccupata per i miei figli.</i>

582
00:35:44,016 --> 00:35:46,686
<i>E sono preoccupata</i>
<i>per i figli degli altri.</i>

583
00:35:46,769 --> 00:35:50,189
Con tutte le competenze che ho
e tutta l'esperienza,

584
00:35:50,273 --> 00:35:54,443
litigo coi miei figli per il tempo
che passano al telefono e al computer.

585
00:35:54,527 --> 00:35:58,197
Se dico a mio figlio: "Secondo te,
quante ore passi al telefono?"

586
00:35:58,281 --> 00:36:01,075
Risponde: "Mezz'ora al massimo."

587
00:36:01,159 --> 00:36:04,871
Direi più di un'ora, un'ora e mezza.

588
00:36:04,954 --> 00:36:08,708
Le statistiche d'uso due settimane fa
dicevano tre ore e 45 minuti.

589
00:36:11,377 --> 00:36:13,754
Non credo che sia...
In media al giorno?

590
00:36:14,172 --> 00:36:15,506
Lo vado a prendere?

591
00:36:15,590 --> 00:36:19,177
Non passa giorno
che non ricordi ai miei figli

592
00:36:19,260 --> 00:36:21,762
dell'equilibrio tra piacere e dolore,

593
00:36:21,846 --> 00:36:26,267
degli stati di carenza di dopamina,
del rischio di dipendenza.

594
00:36:26,350 --> 00:36:27,894
Il momento della verità.

595
00:36:27,977 --> 00:36:29,687
Due ore, 50 minuti al giorno.

596
00:36:29,770 --> 00:36:31,772
- Vediamo.
- Oggi l'ho usato parecchio.

597
00:36:31,856 --> 00:36:33,357
- Ultimi sette giorni.
- Perciò.

598
00:36:33,441 --> 00:36:37,153
Instagram, sei ore, 13 minuti.
Ok, il mio Instagram è peggio.

599
00:36:39,572 --> 00:36:43,201
Il mio schermo è
completamente distrutto. Grazie, Cass.

600
00:36:44,327 --> 00:36:45,995
Che significa "Grazie, Cass"?

601
00:36:46,078 --> 00:36:49,290
Spaventi mamma coi cellulari
quando non è un problema.

602
00:36:49,373 --> 00:36:51,167
Non ci servono per cenare.

603
00:36:51,250 --> 00:36:53,878
Ho capito,
ma non è una tragedia. Veramente.

604
00:36:56,005 --> 00:36:58,382
Allora, non usarlo per una settimana.

605
00:37:02,261 --> 00:37:06,349
Sì, infatti. Se riesci a metterlo via
per una settimana intera...

606
00:37:07,725 --> 00:37:09,518
ti compro uno schermo nuovo.

607
00:37:10,978 --> 00:37:12,813
- A partire da adesso?
- Da ora.

608
00:37:15,274 --> 00:37:16,859
Ok. Affare fatto.

609
00:37:16,943 --> 00:37:19,111
Ok, però lo devi lasciare qui.

610
00:37:19,779 --> 00:37:21,447
Va bene, lo metto in carica.

611
00:37:22,531 --> 00:37:25,076
Sia messo agli atti che lo lascio lì.

612
00:37:27,662 --> 00:37:29,413
- Conto alla rovescia.
- Una settimana.

613
00:37:29,497 --> 00:37:30,331
Oh, mio…

614
00:37:31,457 --> 00:37:32,416
Ce la può fare?

615
00:37:33,000 --> 00:37:34,252
Non lo so, vedremo.

616
00:37:35,002 --> 00:37:36,128
Tu mangia, ok?

617
00:37:44,136 --> 00:37:45,513
Bella cena di famiglia!

618
00:37:47,682 --> 00:37:49,809
<i>Queste tecnologie</i>
<i>non sono state progettate</i>

619
00:37:49,892 --> 00:37:53,896
<i>da psicologi dell'infanzia</i>
<i>che vogliono il benessere dei bambini.</i>

620
00:37:53,980 --> 00:37:58,734
Erano mirate a realizzare algoritmi
bravi a consigliarti il prossimo video

621
00:37:58,818 --> 00:38:02,321
o a convincerti
a scattare una foto con un filtro.

622
00:38:03,072 --> 00:38:04,657
DUE MI PIACE

623
00:38:13,291 --> 00:38:15,126
SICURO DI VOLER CANCELLARE? NO

624
00:38:15,209 --> 00:38:16,127
SÌ

625
00:38:16,669 --> 00:38:20,381
<i>Non è solo il fatto che controlla</i>
<i>cosa attira la tua attenzione.</i>

626
00:38:21,173 --> 00:38:26,304
<i>Soprattutto i social iniziano a scavare</i>
<i>sempre più a fondo nel tronco encefalico</i>

627
00:38:26,387 --> 00:38:29,765
<i>e a controllare il senso</i>
<i>di autostima e identità dei ragazzi.</i>

628
00:38:29,849 --> 00:38:31,851
ABBELLISCIMI

629
00:38:42,069 --> 00:38:43,112
LILY_T
CARINA!

630
00:38:43,195 --> 00:38:44,822
SOPHIA_M
ODDIO, BELLISSIMA

631
00:38:44,905 --> 00:38:46,490
OLIVIA_B
SEI FANTASTICA

632
00:38:46,574 --> 00:38:49,118
AVA_R
PUOI INGRANDIRTI LE ORECCHIE :-)? HAHA

633
00:38:52,413 --> 00:38:55,499
<i>Ci siamo evoluti preoccupandoci</i>
<i>se gli altri della nostra tribù...</i>

634
00:38:55,583 --> 00:38:56,667
BRIANNA_S
STAI BENE!

635
00:38:56,751 --> 00:38:59,587
<i>...pensano bene di noi o no,</i>
<i>perché è importante.</i>

636
00:38:59,837 --> 00:39:04,550
Ma ci siamo evoluti per sapere
cosa pensano di noi 10.000 persone?

637
00:39:04,633 --> 00:39:10,348
Non ci siamo evoluti per assumere una dose
di approvazione sociale ogni cinque minuti

638
00:39:10,431 --> 00:39:13,142
perché non siamo proprio fatti per questo.

639
00:39:15,394 --> 00:39:19,982
<i>Organizziamo la nostra vita</i>
<i>attorno a questo senso di perfezione</i>

640
00:39:20,649 --> 00:39:25,154
<i>perché ci gratificano segnali</i>
<i>a breve termine, cuoricini, Mi piace,</i>

641
00:39:25,237 --> 00:39:28,407
e li scambiamo
per dei valori e per la verità.

642
00:39:29,825 --> 00:39:33,120
Invece, non è altro
che una popolarità falsa e fragile...

643
00:39:33,913 --> 00:39:37,458
che è a breve termine
e ti lascia ancora di più...

644
00:39:37,541 --> 00:39:39,919
con un senso di vuoto rispetto a prima.

645
00:39:41,295 --> 00:39:43,381
Ti costringe in un circolo vizioso

646
00:39:43,464 --> 00:39:47,093
in cui pensi: "Adesso
che altro devo fare? Ne ho bisogno."

647
00:39:48,135 --> 00:39:50,846
Pensate moltiplicato
per due miliardi di persone

648
00:39:50,930 --> 00:39:54,517
e a come reagiscono le persone
alle percezioni degli altri.

649
00:39:54,850 --> 00:39:56,435
È molto grave.

650
00:39:56,977 --> 00:39:58,229
È molto molto grave.

651
00:40:00,856 --> 00:40:05,069
<i>C'è stato un aumento colossale</i>
<i>di depressione e ansia</i>

652
00:40:05,152 --> 00:40:06,529
<i>negli adolescenti americani</i>

653
00:40:06,612 --> 00:40:10,950
che è iniziato proprio
tra il 2011 e il 2013.

654
00:40:11,033 --> 00:40:15,371
Il numero di ragazze adolescenti
su 100.000 in questo Paese

655
00:40:15,454 --> 00:40:19,917
ricoverate ogni anno perché si erano
tagliate o si erano fatte del male,

656
00:40:20,000 --> 00:40:23,921
era un numero piuttosto stabile
fino al 2010, 2011

657
00:40:24,004 --> 00:40:26,340
e poi inizia a salire di parecchio.

658
00:40:28,759 --> 00:40:32,346
<i>È aumentato del 62%</i>
<i>per le adolescenti più grandi.</i>

659
00:40:34,014 --> 00:40:38,310
<i>È aumentato del 189%</i>
<i>per le preadolescenti. È quasi il triplo.</i>

660
00:40:40,187 --> 00:40:43,107
<i>Ancor più raccapricciante</i>
<i>è l'andamento del suicidio.</i>

661
00:40:43,190 --> 00:40:44,900
TASSI DI SUICIDIO NEGLI USA

662
00:40:44,984 --> 00:40:47,570
<i>Le ragazze più grandi, dai 15 ai 19 anni,</i>

663
00:40:47,653 --> 00:40:51,449
<i>sono aumentate del 70%</i>
<i>rispetto al primo decennio del secolo.</i>

664
00:40:52,158 --> 00:40:55,077
<i>Le preadolescenti,</i>
<i>che hanno tassi molto bassi,</i>

665
00:40:55,161 --> 00:40:57,663
<i>sono salite del 151%.</i>

666
00:40:58,831 --> 00:41:01,709
<i>E questo andamento addita i social.</i>

667
00:41:01,792 --> 00:41:03,961
SOCIAL DISPONIBILI SUI CELLULARI

668
00:41:04,044 --> 00:41:07,214
La Generazione Z,
i ragazzi nati dopo il 1996,

669
00:41:07,298 --> 00:41:10,176
è la prima generazione nella storia

670
00:41:10,259 --> 00:41:12,636
che si è iscritta ai social alle medie.

671
00:41:15,973 --> 00:41:17,433
<i>Come passano il tempo?</i>

672
00:41:19,602 --> 00:41:22,605
<i>Tornano a casa da scuola</i>
<i>e usano i loro dispositivi.</i>

673
00:41:24,315 --> 00:41:29,195
<i>Una generazione intera è</i>
<i>più ansiosa, più fragile, più depressa.</i>

674
00:41:30,613 --> 00:41:33,282
<i>Sono molto meno sereni se corrono rischi.</i>

675
00:41:34,325 --> 00:41:37,745
<i>È scesa la percentuale</i>
<i>di chi ottiene la patente di guida.</i>

676
00:41:38,954 --> 00:41:44,251
<i>Il numero di persone che ha storie</i>
<i>o interazioni romantiche è in calo.</i>

677
00:41:47,505 --> 00:41:49,965
<i>È un vero cambiamento di una generazione.</i>

678
00:41:53,177 --> 00:41:57,306
<i>E ricordate, per ciascuna di queste,</i>
<i>per ogni ricovero ospedaliero,</i>

679
00:41:57,389 --> 00:42:00,267
<i>c'è una famiglia</i>
<i>traumatizzata e atterrita.</i>

680
00:42:00,351 --> 00:42:02,937
<i>"Oddio,</i>
<i>che sta succedendo ai nostri figli?"</i>

681
00:42:19,328 --> 00:42:21,038
<i>Per me è chiaro come il sole.</i>

682
00:42:22,873 --> 00:42:28,128
Questi servizi ammazzano le persone
e portano le persone a suicidarsi.

683
00:42:29,088 --> 00:42:33,300
Non conosco genitori che dicono:
"Ci tengo che i miei figli crescano

684
00:42:33,384 --> 00:42:36,595
sentendosi manipolati
da designer tecnologici

685
00:42:36,887 --> 00:42:39,723
che attirano la loro attenzione
distogliendogli dai compiti,

686
00:42:39,807 --> 00:42:42,977
li fanno confrontare
con standard di bellezza irrealistici."

687
00:42:43,227 --> 00:42:44,687
Non lo vuole nessuno.

688
00:42:45,104 --> 00:42:46,355
Nessuno.

689
00:42:46,438 --> 00:42:48,482
Prima c'erano delle tutele.

690
00:42:48,566 --> 00:42:52,778
Se i bambini guardavano i cartoni animati,
ci tenevamo a proteggerli.

691
00:42:52,861 --> 00:42:56,782
Dicevamo: "Questa pubblicità
non è adatta a bambini di questa età."

692
00:42:57,366 --> 00:42:58,784
Poi prendi YouTube Kids

693
00:42:58,867 --> 00:43:02,454
che divora tutta questa parte
dell'economia dell'attenzione

694
00:43:02,538 --> 00:43:04,915
e tutti i bambini
sono esposti a YouTube Kids

695
00:43:04,999 --> 00:43:07,918
e tutte queste tutele
e direttive spariscono.

696
00:43:10,296 --> 00:43:13,841
TEMPO SENZA TELEFONO

697
00:43:18,304 --> 00:43:22,141
<i>Stiamo formando e condizionando</i>
<i>tutta una nuova generazione...</i>

698
00:43:23,434 --> 00:43:29,148
<i>per cui, se ci sentiamo a disagio,</i>
<i>soli, dubbiosi o spaventati,</i>

699
00:43:29,231 --> 00:43:31,775
abbiamo un ciuccio digitale

700
00:43:32,234 --> 00:43:36,488
<i>che sta atrofizzando la nostra capacità</i>
<i>di affrontare le situazioni.</i>

701
00:43:53,964 --> 00:43:59,803
Photoshop non aveva mille ingegneri
che usavano le notifiche, gli amici e l'IA

702
00:43:59,887 --> 00:44:02,431
per prevedere
cosa ti avrebbe reso dipendente,

703
00:44:02,514 --> 00:44:05,184
ti avrebbe manipolato
o consentito agli inserzionisti

704
00:44:05,267 --> 00:44:10,689
di testare 60.000 varianti di testo
e colori per manipolare la tua mente.

705
00:44:11,148 --> 00:44:14,985
È una specie completamente nuova
di potere e influenza.

706
00:44:16,070 --> 00:44:18,906
Direi che, ripeto, i metodi utilizzati...

707
00:44:19,239 --> 00:44:22,868
per giocare sulla possibilità
di sviluppare dipendenza o condizionamento

708
00:44:22,951 --> 00:44:25,204
potrebbero essere
e sono diversi stavolta.

709
00:44:25,287 --> 00:44:28,749
Erano diversi quando sono arrivati
i giornali e la macchina da stampa.

710
00:44:28,832 --> 00:44:31,835
Erano diversi
quando è arrivata la televisione

711
00:44:31,919 --> 00:44:34,004
e c'erano tre grandi reti e...

712
00:44:34,463 --> 00:44:36,423
- All'epoca.
- Sto dicendo questo.

713
00:44:36,507 --> 00:44:38,384
L'idea è che c'è un nuovo livello

714
00:44:38,467 --> 00:44:42,054
e questo nuovo livello
è già successo tantissime volte.

715
00:44:42,137 --> 00:44:45,099
Questo è l'ultimo nuovo livello
che abbiamo visto.

716
00:44:45,182 --> 00:44:48,727
Ti raccontano che ci adatteremo,

717
00:44:48,811 --> 00:44:51,188
impareremo a convivere
con questi dispositivi,

718
00:44:51,271 --> 00:44:53,732
come è successo con tutto il resto.

719
00:44:53,816 --> 00:44:56,694
Sfugge che in questo caso
c'è qualcosa di nuovo.

720
00:44:57,569 --> 00:45:00,322
Forse la cosa più pericolosa è il fatto

721
00:45:00,406 --> 00:45:04,702
che è guidato da tecnologie
che stanno avanzando in modo esponenziale.

722
00:45:05,994 --> 00:45:09,081
Più o meno dagli anni '60 a oggi,

723
00:45:09,790 --> 00:45:13,335
la potenza di elaborazione
è aumentata di mille miliardi di volte.

724
00:45:13,794 --> 00:45:18,340
Non conosciamo altro che sia
migliorato a velocità vicine a queste.

725
00:45:18,424 --> 00:45:22,052
Le automobili sono due volte più veloci.

726
00:45:22,261 --> 00:45:25,264
E quasi tutto il resto è trascurabile.

727
00:45:25,347 --> 00:45:27,182
E la cosa forse più importante

728
00:45:27,266 --> 00:45:31,353
è che la nostra fisiologia,
il cervello non si è evoluto affatto.

729
00:45:31,854 --> 00:45:35,232
TEMPO SENZA TELEFONO

730
00:45:37,401 --> 00:45:41,488
<i>Gli esseri umani, a livello</i>
<i>di mente e corpo, a livello fisico,</i>

731
00:45:41,947 --> 00:45:43,949
<i>non cambieranno radicalmente.</i>

732
00:45:56,795 --> 00:46:00,924
<i>Con l'ingegneria genetica potremo</i>
<i>sviluppare nuovi tipi di esseri umani,</i>

733
00:46:01,008 --> 00:46:05,220
ma, realisticamente parlando,
viviamo dentro un hardware, un cervello,

734
00:46:05,304 --> 00:46:07,222
che ha milioni di anni,

735
00:46:07,306 --> 00:46:10,559
e poi c'è questo schermo,
e dalla parte opposta

736
00:46:10,642 --> 00:46:13,562
ci sono migliaia
di ingegneri e supercomputer

737
00:46:13,645 --> 00:46:16,106
che hanno obiettivi diversi dai tuoi.

738
00:46:16,190 --> 00:46:19,693
Quindi, chi vince
a questo gioco? Chi vince?

739
00:46:25,616 --> 00:46:26,700
Come mai perdiamo?

740
00:46:27,159 --> 00:46:29,828
- Non lo so.
- Ma dov'è? Non è normale.

741
00:46:29,912 --> 00:46:32,080
Troppi contenuti di amici e parenti?

742
00:46:32,164 --> 00:46:34,082
- Probabile.
- Forse è per gli annunci.

743
00:46:34,166 --> 00:46:37,795
No, qualcosa non va.
Passiamo alla modalità resurrezione.

744
00:46:39,713 --> 00:46:44,051
<i>Quando pensi all'intelligenza artificiale</i>
<i>e al fatto che rovinerà il mondo</i>

745
00:46:44,134 --> 00:46:47,221
e vedi Terminator,
Arnold Schwarzenegger...

746
00:46:47,638 --> 00:46:48,680
Tornerò.

747
00:46:48,764 --> 00:46:52,643
<i>...vedi i droni e pensi:</i>
<i>"Ammazzeremo la gente con l'IA."</i>

748
00:46:53,644 --> 00:46:59,566
Quello che sfugge è che l'IA sta
già controllando il mondo di oggi.

749
00:46:59,900 --> 00:47:03,237
Si parla di intelligenza artificiale,
ma è una metafora.

750
00:47:03,320 --> 00:47:09,451
In queste aziende come Google,
ci sono solo stanze enormi.

751
00:47:10,327 --> 00:47:13,121
<i>Alcune sottoterra, altre sott'acqua,</i>

752
00:47:13,205 --> 00:47:14,498
<i>di soli computer.</i>

753
00:47:14,581 --> 00:47:17,835
<i>Tonnellate e tonnellate</i>
<i>di computer a perdita d'occhio.</i>

754
00:47:18,460 --> 00:47:22,923
<i>Sono profondamente interconnessi</i>
<i>e gestiscono programmi complicatissimi</i>

755
00:47:23,006 --> 00:47:26,009
<i>che si scambiano continuamente</i>
<i>dati a destra e sinistra.</i>

756
00:47:26,802 --> 00:47:30,806
<i>Girano tanti programmi</i>
<i>e prodotti diversi su quelle macchine.</i>

757
00:47:31,390 --> 00:47:33,684
Alcune cose sono algoritmi semplici,

758
00:47:33,767 --> 00:47:37,521
altri sono talmente complicati
che si possono definire inteligenza.

759
00:47:40,148 --> 00:47:44,152
Mi piace dire che gli algoritmi sono
opinioni in forma di codice...

760
00:47:45,070 --> 00:47:47,656
e che gli algoritmi non sono obiettivi.

761
00:47:48,365 --> 00:47:51,785
Sono ottimizzati
secondo una certa definizione di successo.

762
00:47:52,244 --> 00:47:57,124
Perciò, se un'impresa commerciale
costruisce un algoritmo

763
00:47:57,207 --> 00:47:59,293
in base alla sua definizione di successo,

764
00:47:59,835 --> 00:48:01,503
è un interesse commerciale.

765
00:48:01,587 --> 00:48:02,921
Di solito, è profitto.

766
00:48:03,130 --> 00:48:07,384
Dai al computer l'obiettivo:
"Voglio questo risultato",

767
00:48:07,467 --> 00:48:10,262
e poi il computer stesso
impara a raggiungerlo.

768
00:48:10,345 --> 00:48:12,598
Questo s'intende
per "apprendimento automatico".

769
00:48:12,681 --> 00:48:16,977
Ogni giorno diventa più bravo a scegliere
i post giusti nell'ordine giusto,

770
00:48:17,060 --> 00:48:19,438
per farti passare sempre più tempo
con quel prodotto.

771
00:48:19,521 --> 00:48:23,901
Nessuno ha capito bene cosa fanno
per raggiungere questo obiettivo.

772
00:48:23,984 --> 00:48:28,238
L'algoritmo ha una mente propria,
quindi, anche se è scritto da qualcuno,

773
00:48:28,906 --> 00:48:30,657
è scritto in un modo

774
00:48:30,741 --> 00:48:35,037
per cui tu costruisci la macchina
e poi questa cambia da sola.

775
00:48:35,120 --> 00:48:37,873
Ci sono poche persone in queste aziende,

776
00:48:37,956 --> 00:48:40,000
Facebook, Twitter e altre...

777
00:48:40,083 --> 00:48:43,795
Poche persone capiscono
come funzionano questi sistemi,

778
00:48:43,879 --> 00:48:49,551
e neanche loro sanno fino in fondo
cosa succederà a un determinato contenuto.

779
00:48:49,968 --> 00:48:55,474
Da esseri umani, abbiamo quasi
perso il controllo su questi sistemi,

780
00:48:55,891 --> 00:48:59,603
perché sono loro a controllare
le informazioni che vediamo.

781
00:48:59,686 --> 00:49:02,439
Ci controllano
più di quanto noi controlliamo loro.

782
00:49:03,774 --> 00:49:07,319
Confrontiamolo con utenti analoghi
nella sua area geografica.

783
00:49:07,402 --> 00:49:09,571
I suoi sosia psicometrici.

784
00:49:09,655 --> 00:49:13,700
Ci sono 13.694 persone
che si comportano come lui nella sua zona.

785
00:49:13,784 --> 00:49:16,370
- Cosa va forte con loro?
- Serve una chicca

786
00:49:16,453 --> 00:49:17,704
per la resurrezione,

787
00:49:17,788 --> 00:49:22,250
dato che le solite cose non funzionano,
nemmeno la ragazza carina di scuola.

788
00:49:22,334 --> 00:49:25,253
La mia analisi mostra
che i contenuti Extreme Center

789
00:49:25,337 --> 00:49:28,256
hanno una probabilità del 62,3%
di un coinvolgimento duraturo.

790
00:49:28,340 --> 00:49:29,299
Non è male.

791
00:49:30,342 --> 00:49:32,010
Non basta come primo step.

792
00:49:32,386 --> 00:49:35,305
Abbiamo provato
le notifiche delle foto taggate,

793
00:49:35,389 --> 00:49:39,184
gli inviti, gli eventi attuali
e un messaggio diretto di Rebecca,

794
00:49:39,267 --> 00:49:42,562
ma che mi dici dell'utente 01265923010?

795
00:49:42,854 --> 00:49:44,648
Sì, gli piacevano i suoi post.

796
00:49:44,731 --> 00:49:47,776
Per mesi, praticamente tutti e poi niente.

797
00:49:47,859 --> 00:49:50,445
Prevedo una possibilità
di risurrezione del 92,3%

798
00:49:50,529 --> 00:49:52,030
con una notifica su Ana.

799
00:49:53,907 --> 00:49:55,492
NUOVA STORIA D'AMORE

800
00:49:56,410 --> 00:49:57,661
E il suo nuovo amico.

801
00:49:58,495 --> 00:50:01,498
TEMPO SENZA TELEFONO

802
00:50:24,354 --> 00:50:26,023
LA TUA EX HA UNA NUOVA STORIA!

803
00:50:26,106 --> 00:50:27,399
Non ci posso credere.

804
00:50:37,576 --> 00:50:38,785
ANA & LUIZ STANNO INSIEME

805
00:50:38,869 --> 00:50:39,703
Cosa?

806
00:50:41,621 --> 00:50:42,789
Bum! Siamo tornati!

807
00:50:42,873 --> 00:50:44,374
Si torna a fare soldi.

808
00:50:44,458 --> 00:50:46,334
E a collegarli con tutto il mondo.

809
00:50:46,418 --> 00:50:49,337
Gli faccio vedere tutte le informazioni
che potrebbero piacergli.

810
00:50:49,755 --> 00:50:53,717
Ehi, vi chiedete mai
se queste informazioni gli facciano bene?

811
00:51:17,532 --> 00:51:19,076
<i>Ti ho fatto un incantesimo</i>

812
00:51:25,040 --> 00:51:26,374
<i>Perché sei mio</i>

813
00:51:29,669 --> 00:51:32,672
NON VOTARE

814
00:51:34,508 --> 00:51:36,885
<i>Ti conviene smettere le cose che fai</i>

815
00:51:41,181 --> 00:51:42,265
<i>Non mento</i>

816
00:51:42,349 --> 00:51:44,893
TEST A/B
EXTREME CENTER

817
00:51:44,976 --> 00:51:46,686
<i>No, non mento</i>

818
00:51:49,981 --> 00:51:51,817
<i>Sai che non lo sopporto</i>

819
00:51:53,026 --> 00:51:54,611
<i>Te ne vai in giro</i>

820
00:51:55,612 --> 00:51:57,239
<i>Sai che non si fa, papà</i>

821
00:51:58,782 --> 00:52:02,077
<i>Non lo sopporto perché mi mortifichi</i>

822
00:52:06,456 --> 00:52:08,375
<i>Ti ho fatto un incantesimo</i>

823
00:52:12,379 --> 00:52:14,840
<i>Perché sei mio</i>

824
00:52:18,718 --> 00:52:19,845
<i>Sei mio</i>

825
00:52:20,929 --> 00:52:24,349
<i>Immagina di stare su Facebook...</i>

826
00:52:24,766 --> 00:52:29,312
e stai giocando
contro questa intelligenza artificiale

827
00:52:29,396 --> 00:52:31,314
che sa tutto di te,

828
00:52:31,398 --> 00:52:34,568
anticipa la tua prossima mossa
e tu non sai niente di lei,

829
00:52:34,651 --> 00:52:37,404
a parte che ci sono
video sui gatti e compleanni.

830
00:52:37,821 --> 00:52:39,656
È una lotta impari.

831
00:52:41,575 --> 00:52:43,869
Ben & Jerry, è ora di andare, bello!

832
00:52:51,126 --> 00:52:51,960
Ben?

833
00:53:02,679 --> 00:53:03,513
Ben.

834
00:53:05,182 --> 00:53:06,057
Forza.

835
00:53:07,225 --> 00:53:09,311
È ora di andare a scuola. Andiamo.

836
00:53:31,374 --> 00:53:33,543
- Come va?
- Sono emozionato.

837
00:53:33,627 --> 00:53:34,628
- Davvero?
- Sì.

838
00:53:37,380 --> 00:53:38,715
Attendevamo il momento

839
00:53:38,798 --> 00:53:42,969
in cui la tecnologia avrebbe superato
i punti di forza e l'intelligenza umana.

840
00:53:43,053 --> 00:53:47,015
Quando ci sostituirà al lavoro,
sarà più intelligente dell'uomo?

841
00:53:48,099 --> 00:53:50,644
Ma c'è un momento
che arriva molto prima...

842
00:53:50,977 --> 00:53:55,565
in cui la tecnologia supera
e sconfigge le debolezze umane.

843
00:53:57,484 --> 00:54:02,030
Questo punto che viene superato
è la radice della dipendenza,

844
00:54:02,113 --> 00:54:06,368
polarizzazione, radicalizzazione,
promozione delle offese e della vanità.

845
00:54:07,702 --> 00:54:09,913
Sta sopraffacendo la natura umana...

846
00:54:10,538 --> 00:54:13,500
ed è uno scacco matto all'umanità.

847
00:54:30,558 --> 00:54:31,434
Scusa.

848
00:54:41,736 --> 00:54:44,656
<i>Un modo in cui cerco</i>
<i>di far capire alle persone...</i>

849
00:54:45,198 --> 00:54:49,828
quanto siano sbagliati
i contenuti che arrivano da Facebook

850
00:54:49,911 --> 00:54:51,454
è pensando a Wikipedia.

851
00:54:51,538 --> 00:54:52,872
NUOVA SCHEDA

852
00:54:52,956 --> 00:54:56,251
<i>Se apri una pagina,</i>
<i>vedi la stessa cosa degli altri.</i>

853
00:54:56,626 --> 00:54:59,879
<i>È una delle poche cose online</i>
<i>che abbiamo in comune.</i>

854
00:55:00,380 --> 00:55:03,425
Immaginate per un attimo
che Wikipedia dicesse:

855
00:55:03,508 --> 00:55:07,178
"Daremo a ciascuno
una definizione personalizzata diversa

856
00:55:07,262 --> 00:55:09,472
e qualcuno ci pagherà per farlo."

857
00:55:09,556 --> 00:55:13,435
Wikipedia dovrebbe spiarti, poi calcolare

858
00:55:13,518 --> 00:55:17,188
"Cosa posso fare per far
cambiare un po' questa persona

859
00:55:17,272 --> 00:55:19,899
in nome di un interesse commerciale?"

860
00:55:19,983 --> 00:55:21,818
Poi cambierebbe la definizione.

861
00:55:22,444 --> 00:55:26,823
Te lo immagini? Non è difficile, è quello
che sta succedendo su Facebook.

862
00:55:26,906 --> 00:55:28,992
È quello che succede su YouTube.

863
00:55:29,075 --> 00:55:31,786
Se digiti su Google
"il cambiamento climatico",

864
00:55:31,870 --> 00:55:34,998
vedi risultati diversi
a seconda di dove vivi.

865
00:55:36,166 --> 00:55:38,460
In certe città,
trovi il completamento automatico

866
00:55:38,543 --> 00:55:40,462
"Il cambiamento climatico è una bufala".

867
00:55:40,545 --> 00:55:42,047
In altri casi, vedrai

868
00:55:42,130 --> 00:55:44,841
"Il cambiamento climatico
distrugge la natura."

869
00:55:44,924 --> 00:55:48,428
Non dipende da cosa sia
veramente il cambiamento climatico,

870
00:55:48,511 --> 00:55:51,097
ma dal luogo da cui effettui la ricerca

871
00:55:51,181 --> 00:55:54,100
e da quello che Google sa
dei tuoi interessi.

872
00:55:55,185 --> 00:56:00,190
Anche due amici molto vicini,
che hanno quasi lo stesso gruppo di amici,

873
00:56:00,273 --> 00:56:02,817
<i>pensano: "Se vado</i>
<i>sul news feed di Facebook,</i>

874
00:56:02,901 --> 00:56:06,738
<i>vedrò gli stessi aggiornamenti,"</i>
<i>ma non è affatto così.</i>

875
00:56:06,821 --> 00:56:08,448
<i>Vedono mondi completamente diversi</i>

876
00:56:08,531 --> 00:56:12,035
<i>basati sui computer che calcolano</i>
<i>cosa è più adatto a ciascuno.</i>

877
00:56:12,118 --> 00:56:14,245
IN ONDA

878
00:56:14,329 --> 00:56:18,416
<i>Bisogna intenderlo</i>
<i>come 2,7 miliardi di Truman Show.</i>

879
00:56:18,500 --> 00:56:21,294
Ogni persona
ha la sua realtà con i suoi...

880
00:56:22,670 --> 00:56:23,671
fatti.

881
00:56:23,755 --> 00:56:27,008
<i>Secondo lei,</i>
<i>perché Truman non è mai andato vicino</i>

882
00:56:27,092 --> 00:56:30,095
<i>a scoprire la vera natura</i>
<i>del suo mondo fino ad ora?</i>

883
00:56:31,054 --> 00:56:34,140
Accettiamo la realtà del mondo
come ci si presenta.

884
00:56:34,224 --> 00:56:35,141
È semplicissimo.

885
00:56:36,476 --> 00:56:41,064
Nel tempo, ti fai l'idea sbagliata
che siano tutti d'accordo con te,

886
00:56:41,147 --> 00:56:44,401
perché tutti quelli del feed
esprimono la tua stessa opinione.

887
00:56:44,567 --> 00:56:49,072
Una volta che finisci in questo stato,
sei facilmente raggirabile

888
00:56:49,155 --> 00:56:51,741
come potrebbe raggirarti un prestigiatore.

889
00:56:51,825 --> 00:56:55,370
Il prestigiatore ti dice:
"Scegli una carta, una qualsiasi".

890
00:56:55,453 --> 00:57:00,583
Non ti rendi conto che ha fatto in modo
che tu scelga la carta che vuole lui.

891
00:57:00,667 --> 00:57:03,169
Facebook funziona così. Ti dice:

892
00:57:03,253 --> 00:57:06,172
"Tu scegli gli amici,
tu scegli i link da seguire",

893
00:57:06,256 --> 00:57:08,716
ma sono sciocchezze,
come col prestigiatore.

894
00:57:08,800 --> 00:57:11,302
Il tuo newsfeed lo decide Facebook.

895
00:57:11,386 --> 00:57:14,514
Agiamo semplicemente
sulla base di fatti diversi.

896
00:57:14,597 --> 00:57:16,474
Se questo succede su larga scala,

897
00:57:16,558 --> 00:57:20,770
non sei più in grado di tenere conto
né di consumare informazioni

898
00:57:20,854 --> 00:57:23,690
in contrasto con la visione
del mondo che hai creato.

899
00:57:23,773 --> 00:57:28,027
Significa che non ci comportiamo
da individui obiettivi e costruttivi.

900
00:57:28,778 --> 00:57:32,449
Apri gli occhi, non credere alle bugie!

901
00:57:32,532 --> 00:57:34,826
<i>E poi volgi lo sguardo dall'altro lato</i>

902
00:57:35,243 --> 00:57:38,746
<i>e cominci a pensare:</i>
<i>"Come fanno a essere così stupidi?</i>

903
00:57:38,830 --> 00:57:42,125
Guarda le informazioni
che vedo di continuo.

904
00:57:42,208 --> 00:57:44,419
Come mai loro vedono cose diverse?"

905
00:57:44,711 --> 00:57:47,297
La risposta è:
"Non vedono le stesse cose."

906
00:57:47,380 --> 00:57:50,800
Apri gli occhi, non credere alle bugie!

907
00:57:52,093 --> 00:57:53,678
<i>Che tipi sono i repubblicani?</i>

908
00:57:53,761 --> 00:57:55,472
Gente che non ha la minima idea.

909
00:57:55,555 --> 00:57:58,933
Il Partito Democratico
è un'organizzazione criminale.

910
00:57:59,017 --> 00:58:03,188
Un enorme studio del Pew Research Center
su 10.000 adulti americani

911
00:58:03,271 --> 00:58:05,315
ci trova più divisi che mai,

912
00:58:05,398 --> 00:58:09,402
con la polarizzazione personale e politica
al livello più alto degli ultimi 20 anni.

913
00:58:11,821 --> 00:58:14,199
<i>Più di un terzo dei repubblicani dice</i>

914
00:58:14,282 --> 00:58:16,826
che i democratici sono
un pericolo nazionale,

915
00:58:16,910 --> 00:58:20,580
più di un quarto dei democratici
dice lo stesso dei repubblicani.

916
00:58:20,663 --> 00:58:24,417
Tanti dei problemi di cui parliamo,
quello della polarizzazione politica,

917
00:58:24,501 --> 00:58:28,046
si trovano in abbondanza
sulla TV via cavo.

918
00:58:28,129 --> 00:58:31,007
I media hanno lo stesso identico problema.

919
00:58:31,090 --> 00:58:35,762
Il loro modello di business è la vendita
della nostra attenzione alle pubblicità.

920
00:58:35,845 --> 00:58:39,474
Internet è solo un modo nuovo
ancora più efficace per farlo.

921
00:58:40,391 --> 00:58:44,145
<i>In YouTube, lavoravo</i>
<i>ai suggerimenti su cosa vedere.</i>

922
00:58:44,229 --> 00:58:47,148
Mi preoccupa
che un algoritmo a cui ho lavorato

923
00:58:47,232 --> 00:58:50,401
stia aumentando
la polarizzazione nella società,

924
00:58:50,485 --> 00:58:53,112
ma dal punto di vista
del tempo di visualizzazione,

925
00:58:53,196 --> 00:58:57,617
questa polarizzazione è estremamente
efficace per tenere online le persone.

926
00:58:58,701 --> 00:59:02,288
<i>Il motivo per cui gli insegnanti</i>
<i>lo insegnano è che li pagano.</i>

927
00:59:02,372 --> 00:59:04,040
<i>- È assurdo.</i>
- Ehi, Benji.

928
00:59:04,832 --> 00:59:06,292
Niente allenamenti oggi?

929
00:59:06,376 --> 00:59:08,878
Sì, ci sono, mi metto
in pari con le notizie.

930
00:59:08,962 --> 00:59:11,506
<i>Informatevi. Quello che passa</i>
<i>dall'Extreme Center...</i>

931
00:59:11,589 --> 00:59:14,592
Non definirei notizie
quello che stai guardando.

932
00:59:15,552 --> 00:59:18,721
Tu dici sempre
che è tutto un casino e anche loro.

933
00:59:19,305 --> 00:59:21,140
Questa è pura propaganda.

934
00:59:21,224 --> 00:59:24,644
<i>Nessuna delle due è vera.</i>
<i>Dipende da cosa è più logico.</i>

935
00:59:24,727 --> 00:59:28,690
Sul serio. Questa roba ti fa male.
Va' all'allenamento di calcio.

936
00:59:35,154 --> 00:59:37,490
<i>Ti dico queste cose perché mi importa.</i>

937
00:59:37,574 --> 00:59:41,077
<i>Mi importa del fatto</i>
<i>che ti stiano ingannando e non va bene.</i>

938
00:59:41,160 --> 00:59:46,833
<i>Si pensa che l'algoritmo sia progettato</i>
<i>per darti quello che vuoi, ma non è così.</i>

939
00:59:46,916 --> 00:59:52,422
L'algoritmo in realtà cerca di trovare
delle tane del Bianconiglio molto potenti

940
00:59:52,505 --> 00:59:56,217
e in particolare quella
che si avvicina di più ai tuoi interessi.

941
00:59:56,301 --> 00:59:59,262
E se inizi a guardare uno di quei video,

942
00:59:59,846 --> 01:00:02,223
te lo consiglierà di continuo.

943
01:00:02,682 --> 01:00:04,684
Nessuno vuole che accada questo,

944
01:00:04,934 --> 01:00:07,812
ma è quello che fa
il sistema dei contenuti consigliati,

945
01:00:07,895 --> 01:00:10,982
al punto che Kyrie Irving,
famoso giocatore di basket,

946
01:00:11,065 --> 01:00:13,568
ha detto che pensava
che la Terra fosse piatta,

947
01:00:13,651 --> 01:00:15,987
si è scusato dando la colpa a YouTube.

948
01:00:16,487 --> 01:00:21,326
Clicchi su YouTube e ti ritrovi
dritto nella tana del Bianconiglio.

949
01:00:21,618 --> 01:00:25,955
Quando ha detto alla radio: "Mi spiace,
non volevo ingannare la gente",

950
01:00:26,039 --> 01:00:30,251
alcuni studenti hanno detto:
"L'ha convinto chi crede sia tonda."

951
01:00:31,044 --> 01:00:33,963
La teoria della Terra piatta
è stata consigliata

952
01:00:34,047 --> 01:00:37,634
centinaia di milioni di volte
dall'algoritmo.

953
01:00:37,717 --> 01:00:43,890
È facile pensare che possa convincere
che solo qualche stupido,

954
01:00:43,973 --> 01:00:46,893
ma l'algoritmo diventa
sempre più intelligente

955
01:00:46,976 --> 01:00:50,188
e oggi convince la gente
che la Terra è piatta,

956
01:00:50,271 --> 01:00:53,816
ma domani convincerà te
di una cosa che è falsa.

957
01:00:54,317 --> 01:00:57,820
<i>Il 7 novembre</i>
<i>è nato l'hashtag "Pizzagate".</i>

958
01:00:58,237 --> 01:00:59,197
Pizzagate...

959
01:01:00,782 --> 01:01:01,658
Cavolo.

960
01:01:03,159 --> 01:01:06,913
<i>Non ho ancora capito al 100%</i>
<i>come sia successo all'inizio,</i>

961
01:01:06,996 --> 01:01:12,377
ma ordinare una pizza significava ordinare
una vittima di una tratta di esseri umani.

962
01:01:12,460 --> 01:01:15,046
Man mano che i gruppi
su Facebook crescevano,

963
01:01:15,129 --> 01:01:19,967
il motore di raccomandazione di Facebook
cominciò a suggerire agli utenti abituali

964
01:01:20,051 --> 01:01:21,761
di iscriversi ai gruppi Pizzagate.

965
01:01:21,844 --> 01:01:27,392
Se un utente era contro i vaccini
o credeva nelle scie chimiche,

966
01:01:27,475 --> 01:01:30,645
o aveva indicato
agli algoritmi di Facebook

967
01:01:30,728 --> 01:01:33,398
che tendeva a credere
a teorie del complotto,

968
01:01:33,481 --> 01:01:36,859
il motore di Facebook
gli proponeva i gruppi Pizzagate.

969
01:01:36,943 --> 01:01:41,072
<i>Alla fine, un uomo</i>
<i>si è presentato con una pistola</i>

970
01:01:41,155 --> 01:01:44,617
<i>per andare a liberare</i>
<i>i bambini dal seminterrato</i>

971
01:01:44,701 --> 01:01:47,036
<i>della pizzeria</i>
<i>che non aveva un seminterrato.</i>

972
01:01:47,120 --> 01:01:50,039
- Cosa ci facevi?
- Controllavo che non ci fosse niente.

973
01:01:50,498 --> 01:01:52,333
- Del tipo?
- Un giro di pedofilia.

974
01:01:52,417 --> 01:01:53,835
- Cosa?
- Giro di pedofilia.

975
01:01:53,918 --> 01:01:55,878
Sta parlando di Pizzagate.

976
01:01:55,962 --> 01:02:00,216
Questo è un esempio
di una teoria del complotto

977
01:02:00,299 --> 01:02:03,678
che si è diffusa su tutti i social.

978
01:02:03,761 --> 01:02:07,974
Il motore di raccomandazione del social
lo offre volutamente a persone

979
01:02:08,057 --> 01:02:10,643
che non avevano mai cercato "Pizzagate".

980
01:02:10,727 --> 01:02:12,687
LA PIZZA SU DEMOCRATICI E PEDOFILIA

981
01:02:12,770 --> 01:02:14,439
Secondo uno studio del MIT,

982
01:02:14,522 --> 01:02:19,444
le notizie false su Twitter si diffondono
sei volte più velocemente delle vere.

983
01:02:19,902 --> 01:02:24,741
Che mondo avremo se delle notizie hanno
un vantaggio di sei volte sulle altre?

984
01:02:25,283 --> 01:02:27,660
Puoi immaginare che queste cose...

985
01:02:27,744 --> 01:02:31,706
inclinano il pavimento
del comportamento umano.

986
01:02:31,789 --> 01:02:34,709
Rendono certi comportamenti
più difficili e altri più facili.

987
01:02:34,792 --> 01:02:38,796
Sei sempre libero di risalire la collina,
ma lo fanno meno persone,

988
01:02:38,880 --> 01:02:43,092
perciò, su scala sociale,
stai davvero inclinando il pavimento

989
01:02:43,176 --> 01:02:45,970
e cambiando il pensiero
e il comportamento della gente.

990
01:02:46,053 --> 01:02:52,018
Abbiamo creato un sistema
che predilige le informazioni false.

991
01:02:52,643 --> 01:02:54,437
Non perché vogliamo questo,

992
01:02:54,520 --> 01:02:58,816
ma perché le informazioni false
portano più soldi alle aziende...

993
01:02:59,400 --> 01:03:01,402
della verità. La verità è noiosa.

994
01:03:01,986 --> 01:03:04,489
È una disinformazione a scopo di lucro.

995
01:03:04,906 --> 01:03:08,159
Ci guadagni
se permetti a messaggi incontrollati...

996
01:03:08,701 --> 01:03:11,287
di arrivare a chiunque al prezzo migliore.

997
01:03:11,662 --> 01:03:13,956
<i>Per il cambiamento climatico? Sì.</i>

998
01:03:14,040 --> 01:03:16,751
<i>È una bufala. Sì, esiste.</i>
<i>È questo il punto.</i>

999
01:03:16,834 --> 01:03:20,046
<i>Più ne parlano e più ci dividono,</i>

1000
01:03:20,129 --> 01:03:22,423
<i>più hanno potere, più hanno controllo.</i>

1001
01:03:22,507 --> 01:03:25,510
<i>Facebook ha migliaia</i>
<i>di miliardi di post di notizie.</i>

1002
01:03:26,552 --> 01:03:29,180
Non può sapere cosa sia vero.

1003
01:03:29,972 --> 01:03:33,726
È per questo
che parlarne adesso è fondamentale.

1004
01:03:33,810 --> 01:03:37,021
<i>Non si sta diffondendo rapidamente</i>
<i>solo il COVID-19.</i>

1005
01:03:37,104 --> 01:03:40,191
<i>Online si fa</i>
<i>tanta disinformazione sul virus.</i>

1006
01:03:40,274 --> 01:03:43,694
<i>L'idea che bere più acqua</i>
<i>elimini il covid dall'organismo</i>

1007
01:03:43,778 --> 01:03:47,490
<i>è uno dei miti sul virus</i>
<i>che circolano sui social.</i>

1008
01:03:47,573 --> 01:03:50,451
<i>Il governo ha pianificato l'evento,</i>
<i>ha creato il virus,</i>

1009
01:03:50,868 --> 01:03:53,871
<i>ha fatto una simulazione</i>
<i>di come avrebbero reagito i Paesi.</i>

1010
01:03:53,955 --> 01:03:55,581
Il coronavirus è una bufala.

1011
01:03:56,165 --> 01:03:57,959
SARS, coronavirus.

1012
01:03:58,376 --> 01:04:01,045
Guardate la data di produzione. 2018.

1013
01:04:01,128 --> 01:04:03,798
Secondo me,
l'ha messa in giro il governo USA.

1014
01:04:04,215 --> 01:04:09,095
Nessuno è malato.
Nessuno conosce nessuno che sia malato.

1015
01:04:09,512 --> 01:04:13,015
Forse il governo sta usando
il coronavirus come scusa

1016
01:04:13,099 --> 01:04:15,643
per farci stare a casa
perché sta succedendo altro.

1017
01:04:15,726 --> 01:04:18,020
Non è il covid ad ammazzare la gente,

1018
01:04:18,104 --> 01:04:20,940
ma le radiazioni 5G che buttano fuori.

1019
01:04:21,023 --> 01:04:22,525
TORRI 5G ABBATTUTE E INCENDIATE

1020
01:04:22,608 --> 01:04:24,569
<i>Ci bombardano di dicerie.</i>

1021
01:04:25,403 --> 01:04:28,823
<i>C'è gente che fa saltare</i>
<i>le torri per la telefonia mobile.</i>

1022
01:04:28,906 --> 01:04:32,201
<i>Russia e Cina diffondono</i>
<i>dicerie e teorie del complotto.</i>

1023
01:04:32,285 --> 01:04:35,246
<i>Stamattina,</i>
<i>panico e proteste in Ucraina...</i>

1024
01:04:35,329 --> 01:04:39,375
<i>La gente non sa cosa sia vero,</i>
<i>è diventata questione di vita o di morte.</i>

1025
01:04:40,042 --> 01:04:42,628
<i>Le fonti che fanno</i>
<i>disinformazione sul virus</i>

1026
01:04:42,712 --> 01:04:45,798
hanno accumulato 52 milioni di reazioni.

1027
01:04:45,882 --> 01:04:50,094
Sta dicendo che la soluzione
di argento sarebbe efficace.

1028
01:04:50,177 --> 01:04:54,140
Diciamo che non è stata testata
su questo ceppo di coronavirus, però...

1029
01:04:54,223 --> 01:04:57,226
<i>Col COVID stiamo assistendo</i>
<i>a una versione estrema</i>

1030
01:04:57,310 --> 01:05:00,730
<i>di ciò che accade</i>
<i>nell'intero ecosistema dell'informazione.</i>

1031
01:05:01,105 --> 01:05:05,026
<i>I social amplificano</i>
<i>in misura esponenziale voci e dicerie</i>

1032
01:05:05,109 --> 01:05:09,238
<i>al punto che non capiamo cosa sia vero,</i>
<i>a prescindere da cosa ci stia a cuore.</i>

1033
01:05:26,130 --> 01:05:27,465
Sei ancora in squadra?

1034
01:05:30,468 --> 01:05:34,430
Io vado a fare uno spuntino
prima di allenarmi, se ti va di venire.

1035
01:05:37,642 --> 01:05:38,684
Lascia stare.

1036
01:05:45,066 --> 01:05:47,526
<i>Nove persone su dieci</i>
<i>sono insoddisfatte.</i>

1037
01:05:47,610 --> 01:05:50,613
<i>L'EC è come tutti i movimenti</i>
<i>politici della storia.</i>

1038
01:05:50,696 --> 01:05:54,492
<i>Ci ribelliamo e...</i>
<i>Ci ribelliamo a questo rumore.</i>

1039
01:05:54,575 --> 01:05:57,036
<i>Siete la mia gente. Mi fido di voi.</i>

1040
01:05:59,246 --> 01:06:02,583
- Il contenuto Extreme Center è geniale.
- Lo adora.

1041
01:06:02,667 --> 01:06:03,626
Vai con l'asta.

1042
01:06:04,627 --> 01:06:08,547
840 offerenti, venduto per 4,35 cent
a un produttore di armi.

1043
01:06:08,631 --> 01:06:10,800
Promuoviamo alcuni di questi eventi.

1044
01:06:10,883 --> 01:06:13,511
Raduni nella sua zona
entro il fine settimana.

1045
01:06:13,594 --> 01:06:15,179
Ho pronto un nuovo vlogger.

1046
01:06:17,890 --> 01:06:22,979
<i>Sinceramente, ti dirò,</i>
<i>sono disposto a fare qualsiasi cosa.</i>

1047
01:06:23,062 --> 01:06:24,939
<i>E intendo qualsiasi cosa.</i>

1048
01:06:32,154 --> 01:06:33,114
<i>- Iscriviti...</i>
- Ben?

1049
01:06:33,197 --> 01:06:35,908
<i>...e torna perché, fidati...</i>

1050
01:06:36,659 --> 01:06:38,869
<i>ho in serbo cose molto grosse.</i>

1051
01:06:38,953 --> 01:06:40,162
<i>Cose molto grosse.</i>

1052
01:06:40,788 --> 01:06:45,292
<i>Uno dei problemi di Facebook</i>
<i>è che, come strumento di persuasione,</i>

1053
01:06:45,793 --> 01:06:47,920
potrebbe essere
l'invenzione migliore di sempre.

1054
01:06:48,004 --> 01:06:52,508
Immagina cosa significa nelle mani
di un dittatore o di un despota.

1055
01:06:53,718 --> 01:06:57,638
Se vuoi controllare
la popolazione del tuo Paese,

1056
01:06:57,722 --> 01:07:01,308
non c'è mai stato
strumento efficace quanto Facebook.

1057
01:07:04,937 --> 01:07:07,398
<i>Tra le implicazioni più preoccupanti</i>

1058
01:07:07,481 --> 01:07:11,277
dei governi e altri malintenzionati
che usano i social come armi,

1059
01:07:11,527 --> 01:07:13,612
è che abbiano prodotto danni offline.

1060
01:07:13,696 --> 01:07:17,658
L'esempio lampante
è quello che è successo in Myanmar.

1061
01:07:17,742 --> 01:07:19,160
UFFICIO PRESIDENTE MYANMAR

1062
01:07:19,243 --> 01:07:22,913
<i>In Myanmar, se pensi a Internet,</i>
<i>in realtà pensi a Facebook.</i>

1063
01:07:22,997 --> 01:07:25,916
Spesso succede che,
se compri un cellulare,

1064
01:07:26,000 --> 01:07:31,505
il proprietario del negozio ci installa
Facebook e ti apre un account.

1065
01:07:31,589 --> 01:07:34,884
Quando ritiri il telefono,
la prima cosa che apri

1066
01:07:34,967 --> 01:07:37,303
e la sola cosa che sai usare è Facebook.

1067
01:07:38,179 --> 01:07:41,891
Una nuova indagine bomba
svela la crescente difficoltà di Facebook

1068
01:07:41,974 --> 01:07:43,809
di contrastare l'odio in Myanmar.

1069
01:07:43,893 --> 01:07:46,020
BASTA AMMAZZARE I MUSULMANI

1070
01:07:46,103 --> 01:07:49,190
Facebook ha dato
all'esercito e altri malintenzionati

1071
01:07:49,273 --> 01:07:51,776
<i>un nuovo modo</i>
<i>per manipolare l'opinione pubblica</i>

1072
01:07:51,859 --> 01:07:55,529
<i>e per istigare alla violenza</i>
<i>contro i musulmani Rohingya</i>

1073
01:07:55,613 --> 01:07:57,406
<i>con uccisioni di massa,</i>

1074
01:07:58,115 --> 01:07:59,867
<i>incendi di interi villaggi,</i>

1075
01:07:59,950 --> 01:08:03,704
<i>stupri di massa</i>
<i>e altri reati gravi contro l'umanità</i>

1076
01:08:03,788 --> 01:08:08,209
<i>che hanno portato</i>
<i>700.000 musulmani Rohingya a espatriare.</i>

1077
01:08:11,170 --> 01:08:16,550
Non che propagandisti molto motivati
non esistessero anche prima,

1078
01:08:16,634 --> 01:08:19,762
ma queste piattaforme consentono

1079
01:08:19,845 --> 01:08:23,724
di diffondere storie manipolatorie
con una facilità fenomenale

1080
01:08:23,808 --> 01:08:25,434
e senza tanti soldi.

1081
01:08:25,518 --> 01:08:27,520
Se voglio manipolare un'elezione,

1082
01:08:27,853 --> 01:08:30,564
entro in un gruppo Facebook
di teorie del complotto,

1083
01:08:30,648 --> 01:08:34,443
e trovo cento persone
che credono che la Terra sia piatta

1084
01:08:34,819 --> 01:08:37,780
e che l'allunaggio sia
una teoria del complotto,

1085
01:08:37,863 --> 01:08:41,575
e dico a Facebook: "Dammi
mille utenti che somigliano a questo."

1086
01:08:42,118 --> 01:08:46,080
<i>Facebook mi manderà</i>
<i>migliaia di utenti che gli somigliano</i>

1087
01:08:46,163 --> 01:08:49,250
<i>a cui posso proporre</i>
<i>altre teorie del complotto.</i>

1088
01:08:51,168 --> 01:08:52,962
Venduto a 3,4 cent a immagine.

1089
01:08:53,170 --> 01:08:54,922
Nuovo video EC da promuovere.

1090
01:08:55,005 --> 01:08:56,423
Pronto un altro annuncio.

1091
01:08:58,509 --> 01:09:02,138
<i>Algoritmi e politici manipolatori</i>
<i>stanno diventando bravissimi</i>

1092
01:09:02,221 --> 01:09:04,056
a capire cosa ci fa reagire,

1093
01:09:04,140 --> 01:09:08,352
a creare notizie false
che assimiliamo come se fossero vere,

1094
01:09:08,435 --> 01:09:10,813
e a confonderci
per farci credere a queste bugie.

1095
01:09:10,896 --> 01:09:14,150
Abbiamo sempre meno controllo
su chi siamo e cosa crediamo.

1096
01:09:31,458 --> 01:09:34,879
<i>...per scegliere da che parte stare,</i>
<i>ci sono bugie ovunque.</i>

1097
01:09:34,962 --> 01:09:39,967
<i>Così, possono mantenere il potere</i>
<i>e possono controllare tutto.</i>

1098
01:09:40,050 --> 01:09:44,555
<i>Possono controllare la nostra mente</i>
<i>per mantenere i loro segreti.</i>

1099
01:09:44,638 --> 01:09:46,390
METTI IN DUBBIO LA VERITÀ

1100
01:09:48,475 --> 01:09:50,895
<i>Immagina un mondo</i>
<i>in cui nessuno crede a ciò che è vero.</i>

1101
01:09:50,978 --> 01:09:53,314
I VACCINI NON SONO TAGLIA UNICA
LO PROVANO I GENI

1102
01:09:53,397 --> 01:09:55,649
<i>Tutti pensano che il governo dica bugie.</i>

1103
01:09:56,317 --> 01:09:58,444
<i>Tutto è una teoria del complotto.</i>

1104
01:09:58,527 --> 01:10:01,197
<i>"Meglio non fidarsi di nessuno,</i>
<i>odio l'altro partito."</i>

1105
01:10:01,280 --> 01:10:02,698
Andiamo in questa direzione.

1106
01:10:02,781 --> 01:10:06,160
I terremoti politici in Europa
continuano a sussultare,

1107
01:10:06,243 --> 01:10:08,412
stavolta in Italia e Spagna.

1108
01:10:08,495 --> 01:10:11,999
<i>La coalizione centrista tradizionale</i>
<i>europea ha perso la maggioranza,</i>

1109
01:10:12,082 --> 01:10:15,002
<i>guadagnano i populisti</i>
<i>di estrema destra ed estrema sinistra.</i>

1110
01:10:17,588 --> 01:10:19,048
CENTRO

1111
01:10:19,757 --> 01:10:20,591
Indietro.

1112
01:10:21,675 --> 01:10:22,509
Ok, andiamo.

1113
01:10:28,390 --> 01:10:31,268
<i>Questi account cercavano deliberatamente</i>

1114
01:10:31,352 --> 01:10:33,896
<i>di seminare</i>
<i>discordia politica a Hong Kong.</i>

1115
01:10:38,609 --> 01:10:39,610
Va bene, Ben.

1116
01:10:42,863 --> 01:10:48,410
Cosa significa essere un Paese
che si ciba solo di Facebook e di social?

1117
01:10:48,953 --> 01:10:50,871
La democrazia è crollata in fretta.

1118
01:10:50,955 --> 01:10:51,830
Sei mesi.

1119
01:10:51,914 --> 01:10:53,791
<i>Dopo questo caos a Chicago,</i>

1120
01:10:53,874 --> 01:10:57,086
<i>sconti violenti</i>
<i>tra manifestanti e sostenitori...</i>

1121
01:10:58,003 --> 01:11:01,632
<i>La democrazia sta affrontando</i>
<i>una crisi di fiducia.</i>

1122
01:11:01,715 --> 01:11:04,343
Assistiamo
a un attacco globale alla democrazia.

1123
01:11:05,135 --> 01:11:07,930
<i>La maggior parte</i>
<i>dei Paesi presi di mira sono quelli</i>

1124
01:11:08,013 --> 01:11:10,182
<i>in cui ci sono elezioni democratiche.</i>

1125
01:11:10,641 --> 01:11:12,518
<i>Sta succedendo su vasta scala.</i>

1126
01:11:12,601 --> 01:11:15,562
Gente che agisce per lo Stato
con milioni di dollari e dice:

1127
01:11:15,646 --> 01:11:18,524
"Voglio destabilizzare Kenya e Camerun.

1128
01:11:18,607 --> 01:11:20,651
L'Angola è costato poco."

1129
01:11:20,734 --> 01:11:23,362
<i>Domenica si sono svolte</i>
<i>elezioni straordinarie in Brasile.</i>

1130
01:11:23,445 --> 01:11:25,823
Con una campagna alimentata dai social.

1131
01:11:30,953 --> 01:11:33,956
<i>Noi dell'industria tech</i>
<i>abbiamo creato gli strumenti</i>

1132
01:11:34,039 --> 01:11:37,418
per destabilizzare e minare
il tessuto della società,

1133
01:11:37,501 --> 01:11:40,254
in tutti i Paesi
contemporaneamente, ovunque.

1134
01:11:40,337 --> 01:11:44,133
Si vede in Germania, Spagna,
Francia, Brasile, Australia.

1135
01:11:44,591 --> 01:11:47,219
Alcune delle nazioni
più sviluppate del mondo

1136
01:11:47,428 --> 01:11:49,221
stanno implodendo su se stesse

1137
01:11:49,305 --> 01:11:50,931
e cos'hanno in comune?

1138
01:11:51,974 --> 01:11:56,395
Col senno di poi, pensi che Facebook
abbia influenzato le elezioni del 2016?

1139
01:11:56,854 --> 01:11:58,188
Questa è difficile!

1140
01:11:58,897 --> 01:11:59,773
Sai, è...

1141
01:11:59,857 --> 01:12:01,150
MARZO 2018

1142
01:12:01,275 --> 01:12:04,653
La realtà è che erano
in gioco tante forze diverse.

1143
01:12:04,737 --> 01:12:07,865
I rappresentanti di Facebook,
Twitter e Google al Congresso

1144
01:12:07,948 --> 01:12:12,578
per un secondo giorno di testimonianze
sulle interferenze russe nelle elezioni.

1145
01:12:12,661 --> 01:12:17,291
La manipolazione da parte di terzi
non è un attacco informatico.

1146
01:12:18,500 --> 01:12:21,462
I russi non sono entrati
abusivamente in Facebook.

1147
01:12:21,545 --> 01:12:24,965
Hanno usato
gli strumenti creati da Facebook

1148
01:12:25,049 --> 01:12:27,843
per inserzionisti e utenti leciti

1149
01:12:27,926 --> 01:12:30,346
e li hanno usati per scopi scellerati.

1150
01:12:32,014 --> 01:12:33,891
È una guerra col telecomando.

1151
01:12:34,475 --> 01:12:36,602
Un Paese può manipolarne un altro

1152
01:12:36,685 --> 01:12:39,229
senza invadere i suoi confini fisici.

1153
01:12:39,605 --> 01:12:43,317
<i>Stiamo vedendo immagini violente.</i>
<i>Pare che spintonino un cassonetto.</i>

1154
01:12:43,400 --> 01:12:45,736
<i>Il problema non era per chi volevi votare.</i>

1155
01:12:46,362 --> 01:12:50,574
<i>Il punto è che si seminava</i>
<i>caos totale e discordia nella società.</i>

1156
01:12:50,657 --> 01:12:53,035
<i>È successo a Huntington Beach, a marzo...</i>

1157
01:12:53,118 --> 01:12:58,123
Diventano due fazioni
che non si ascoltano più tra di loro,

1158
01:12:58,207 --> 01:12:59,875
che non hanno fiducia reciproca.

1159
01:12:59,958 --> 01:13:02,711
<i>È una città</i>
<i>in cui l'odio è stato messo a nudo</i>

1160
01:13:02,795 --> 01:13:05,464
<i>e trasformato in violenza razziale.</i>

1161
01:13:05,547 --> 01:13:07,925
TENSIONI IN VIRGINIA
TRE MORTI IN UN GIORNO

1162
01:13:20,145 --> 01:13:20,979
Ben!

1163
01:13:21,605 --> 01:13:22,439
Cassandra!

1164
01:13:22,981 --> 01:13:23,816
- Cass!
- Ben!

1165
01:13:23,899 --> 01:13:25,484
Vieni qui!

1166
01:13:27,486 --> 01:13:31,156
Su le braccia. In ginocchio. Giù.

1167
01:13:36,120 --> 01:13:37,204
- Calma...
- Ben!

1168
01:13:37,287 --> 01:13:38,414
Ehi! Mani in alto!

1169
01:13:39,623 --> 01:13:41,291
Girati. A terra.

1170
01:13:56,682 --> 01:13:59,977
<i>Vogliamo questo sistema</i>
<i>di vendita al miglior offerente?</i>

1171
01:14:01,437 --> 01:14:05,399
<i>Che la democrazia sia in vendita</i>
<i>per entrare nelle menti che vuoi,</i>

1172
01:14:05,482 --> 01:14:09,069
<i>dare una menzogna in pasto a un popolo</i>
<i>e generare guerre culturali?</i>

1173
01:14:09,236 --> 01:14:10,237
<i>Vogliamo questo?</i>

1174
01:14:14,741 --> 01:14:16,493
<i>Siamo una nazione di persone...</i>

1175
01:14:16,952 --> 01:14:18,620
che non si parlano più.

1176
01:14:18,704 --> 01:14:19,997
SENATORE - FLORIDA

1177
01:14:20,080 --> 01:14:25,294
Persone che non sono più amiche tra loro
a causa del voto delle ultime elezioni.

1178
01:14:25,711 --> 01:14:28,422
Siamo una nazione di persone
che si sono isolate

1179
01:14:28,505 --> 01:14:31,133
a guardare solo canali
che ci danno ragione.

1180
01:14:32,259 --> 01:14:35,888
Il mio messaggio di oggi
è che il tribalismo ci sta rovinando.

1181
01:14:35,971 --> 01:14:37,347
EX SENATORE - ARIZONA

1182
01:14:37,431 --> 01:14:39,391
Sta distruggendo il nostro Paese.

1183
01:14:40,267 --> 01:14:43,103
Non è modo di agire
per adulti sani di mente.

1184
01:14:43,187 --> 01:14:45,314
Se ognuno ha diritto alla propria realtà,

1185
01:14:45,397 --> 01:14:49,401
non c'è bisogno di compromessi
o di unione tra le persone.

1186
01:14:49,485 --> 01:14:51,695
Non c'è bisogno di nessuna interazione.

1187
01:14:52,321 --> 01:14:56,617
Abbiamo bisogno
di una percezione condivisa della realtà.

1188
01:14:57,367 --> 01:14:58,994
Altrimenti, non siamo un Paese.

1189
01:14:59,578 --> 01:15:02,998
La soluzione nel lungo periodo
è costruire altri strumenti di IA

1190
01:15:03,081 --> 01:15:08,128
che trovino modelli di persone che usano
i servizi che non farebbero persone umane.

1191
01:15:08,212 --> 01:15:11,840
Permettiamo ai tecnologi
di presentarlo come problema

1192
01:15:11,924 --> 01:15:14,009
che sono attrezzati per risolvere.

1193
01:15:15,135 --> 01:15:16,470
È una bugia.

1194
01:15:17,679 --> 01:15:20,724
La gente parla di IA
come se sapesse la verità.

1195
01:15:21,683 --> 01:15:23,810
L'IA non risolverà questi problemi.

1196
01:15:24,269 --> 01:15:27,189
Non può risolvere
il problema delle notizie false.

1197
01:15:28,649 --> 01:15:30,859
Google non ha la possibilità di dire:

1198
01:15:31,109 --> 01:15:34,154
"È un complotto o la verità?"

1199
01:15:34,696 --> 01:15:36,240
Non sa cosa sia la verità.

1200
01:15:36,823 --> 01:15:40,410
Non ha un proxy per la verità
che vada oltre un clic.

1201
01:15:41,870 --> 01:15:45,123
Se non siamo d'accordo su ciò che è vero

1202
01:15:45,207 --> 01:15:47,584
o che esiste una cosa come la verità,

1203
01:15:48,293 --> 01:15:49,294
siamo fritti.

1204
01:15:49,753 --> 01:15:54,424
È il problema sotto altri problemi.
Se non siamo d'accordo su ciò che è vero,

1205
01:15:55,008 --> 01:15:57,803
non possiamo risolvere
nessuno dei nostri problemi.

1206
01:16:05,435 --> 01:16:07,729
Suggeriamogli
di seguire la squadra di football.

1207
01:16:07,813 --> 01:16:10,232
Basta aggiornamenti sportivi.
Non gli interessano.

1208
01:16:39,803 --> 01:16:42,764
<i>Tanta gente della Silicon Valley</i>
<i>condivide la teoria</i>

1209
01:16:42,848 --> 01:16:45,225
<i>che stiamo costruendo</i>
<i>un super cervello globale</i>

1210
01:16:45,309 --> 01:16:49,896
<i>e gli utenti sono neuroni intercambiabili</i>
<i>senza nessuna importanza.</i>

1211
01:16:50,230 --> 01:16:53,150
<i>Questo assoggetta le persone</i>
<i>a questo strano ruolo</i>

1212
01:16:53,233 --> 01:16:56,069
in cui sei solo un elemento informatico

1213
01:16:56,153 --> 01:16:58,905
che programmiamo
manipolando i comportamenti

1214
01:16:58,989 --> 01:17:02,367
al servizio di questo cervellone
e tu non conti niente.

1215
01:17:02,451 --> 01:17:04,911
Non ti pagano,
non ti danno riconoscimenti,

1216
01:17:04,995 --> 01:17:06,455
non decidi autonomamente.

1217
01:17:06,538 --> 01:17:09,416
Ti manipoliamo di nascosto
perché sei un nodo informatico

1218
01:17:09,499 --> 01:17:12,336
e ti programmiamo
come si programmano tutti i nodi.

1219
01:17:20,093 --> 01:17:21,094
Cavolo.

1220
01:17:21,928 --> 01:17:25,390
<i>Se pensi alla tecnologia</i>
<i>come a una minaccia esistenziale,</i>

1221
01:17:25,474 --> 01:17:28,060
è un'affermazione importante e...

1222
01:17:29,603 --> 01:17:33,982
È facile pensare nella tua testa:
"Ok, sono qui con il telefono...

1223
01:17:35,609 --> 01:17:37,235
scorro, clicco, lo uso.

1224
01:17:37,319 --> 01:17:39,196
Dov'è la minaccia esistenziale?

1225
01:17:40,280 --> 01:17:44,201
Ho il super computer dall'altra parte
dello schermo, puntato sul mio cervello,

1226
01:17:44,409 --> 01:17:47,537
mi ha fatto guardare un altro video.
Dov'è la minaccia?"

1227
01:17:54,252 --> 01:17:59,341
<i>Non è che la tecnologia</i>
<i>sia la minaccia esistenziale.</i>

1228
01:18:04,429 --> 01:18:08,850
<i>È la capacità della tecnologia</i>
<i>di tirar fuori il peggio dalla società,</i>

1229
01:18:09,559 --> 01:18:13,522
ed è il peggio della società
a essere la minaccia esistenziale.

1230
01:18:13,605 --> 01:18:15,899
SENATO DEGLI STATI UNITI

1231
01:18:18,819 --> 01:18:20,570
<i>Se la tecnologia genera...</i>

1232
01:18:21,613 --> 01:18:24,533
<i>caos di massa, offese, inciviltà,</i>

1233
01:18:24,616 --> 01:18:26,410
<i>mancanza di fiducia reciproca,</i>

1234
01:18:27,452 --> 01:18:30,414
<i>solitudine, isolamento,</i>
<i>più polarizzazione,</i>

1235
01:18:30,706 --> 01:18:33,625
<i>più manipolazione delle elezioni,</i>
<i>più populismo,</i>

1236
01:18:33,917 --> 01:18:37,546
più distrazione e incapacità
di concentrarsi su problemi reali...

1237
01:18:37,963 --> 01:18:39,214
la società è questa.

1238
01:18:40,340 --> 01:18:46,388
E adesso la società
non è capace di risanarsi

1239
01:18:46,471 --> 01:18:48,515
e sta solo precipitando nel caos.

1240
01:18:51,893 --> 01:18:54,938
Il problema riguarda tutti,
anche chi non usa questi prodotti.

1241
01:18:55,397 --> 01:18:57,524
Sono diventati Frankenstein digitali

1242
01:18:57,607 --> 01:19:00,068
che stanno plasmando
il mondo a loro immagine,

1243
01:19:00,152 --> 01:19:04,489
che sia la salute mentale dei bambini
o la politica e il discorso politico,

1244
01:19:04,573 --> 01:19:07,492
senza assumersi la responsabilità
di un dibattito pubblico.

1245
01:19:07,576 --> 01:19:10,579
- Torniamo a...
- Chi sarebbe il responsabile?

1246
01:19:10,662 --> 01:19:13,582
Per me, bisogna dare
la responsabilità alle piattaforme.

1247
01:19:13,665 --> 01:19:17,794
Se controllano le pubblicità elettorali,
devono proteggere le elezioni.

1248
01:19:17,878 --> 01:19:20,380
Se controllano la salute mentale
o i cartoni animati,

1249
01:19:20,464 --> 01:19:22,716
devono proteggere
l'intrattenimento dei bambini.

1250
01:19:23,717 --> 01:19:28,013
La gara a chi attira di più
l'attenzione della gente non finirà.

1251
01:19:28,388 --> 01:19:31,850
La tecnologia si integrerà
di più nella nostra vita, non di meno.

1252
01:19:31,933 --> 01:19:34,895
Le IA prevederanno ancora meglio
cosa ci tiene sullo schermo,

1253
01:19:34,978 --> 01:19:37,105
non il contrario.

1254
01:19:38,940 --> 01:19:42,027
Io ho 62 anni.

1255
01:19:42,110 --> 01:19:45,155
Invecchio a vista d'occhio
durante questa chiacchierata,

1256
01:19:45,238 --> 01:19:47,657
ma le dirò una cosa.

1257
01:19:48,700 --> 01:19:52,370
Probabilmente io sarò molto e sepolto
e ringrazierò di esserlo,

1258
01:19:52,454 --> 01:19:54,539
quando si realizzerà questo schifo.

1259
01:19:54,790 --> 01:19:57,584
Perché credo che...

1260
01:19:58,293 --> 01:20:00,128
questa storia mi spaventa a morte.

1261
01:20:00,921 --> 01:20:03,048
Anche lei la vede così?

1262
01:20:03,548 --> 01:20:07,010
O è una mia reazione eccessiva
a un problema che conosco poco?

1263
01:20:09,930 --> 01:20:11,598
Cosa ti preoccupa di più?

1264
01:20:15,519 --> 01:20:18,480
Secondo me, nel brevissimo periodo...

1265
01:20:19,481 --> 01:20:20,565
una guerra civile.

1266
01:20:24,444 --> 01:20:27,155
Se continueremo con questa situazione...

1267
01:20:27,989 --> 01:20:29,991
diciamo per altri 20 anni...

1268
01:20:31,117 --> 01:20:34,579
probabilmente distruggeremo
la nostra civiltà per deliberata ignoranza

1269
01:20:34,663 --> 01:20:37,958
e non saremo all'altezza della sfida
del cambiamento climatico.

1270
01:20:38,041 --> 01:20:42,087
Probabilmente sviliremo
le democrazie del mondo

1271
01:20:42,170 --> 01:20:46,132
che cadranno in una specie
di stramba disfunzione dittatoriale.

1272
01:20:46,216 --> 01:20:48,760
Probabilmente
rovineremo l'economia globale.

1273
01:20:49,177 --> 01:20:52,264
Probabilmente non sopravvivremo.

1274
01:20:52,347 --> 01:20:54,808
Secondo me, è una questione esistenziale.

1275
01:21:02,524 --> 01:21:04,985
<i>Questa è l'ultima generazione di persone</i>

1276
01:21:05,068 --> 01:21:08,572
<i>che sanno com'era prima</i>
<i>che si verificasse questa illusione?</i>

1277
01:21:11,074 --> 01:21:14,578
Come fai a svegliarti da Matrix
se non sai di starci dentro?

1278
01:21:16,872 --> 01:21:18,456
"Se sarà utopia o oblio,

1279
01:21:18,540 --> 01:21:21,668
lo deciderà una gara a staffetta
fino all'ultimo minuto..."

1280
01:21:27,382 --> 01:21:30,635
<i>Tante delle cose che diciamo</i>
<i>fanno pensare che sia...</i>

1281
01:21:31,428 --> 01:21:33,680
una visione pessimistica unilaterale.

1282
01:21:33,763 --> 01:21:38,059
Tipo: "Oddio, la tecnologia
sta rovinando il mondo e i bambini".

1283
01:21:38,143 --> 01:21:39,269
Ma non è così.

1284
01:21:40,228 --> 01:21:45,567
È una situazione ambigua perché è
contemporaneamente utopia e distopia.

1285
01:21:45,942 --> 01:21:50,447
Posso premere un tasto sul telefono
per avere una macchina tra 30 secondi

1286
01:21:50,530 --> 01:21:52,699
e andare dove devo andare.

1287
01:21:52,782 --> 01:21:55,660
Questa è magia. È fantastico.

1288
01:21:56,161 --> 01:21:57,662
Col pulsante "Mi piace",

1289
01:21:57,746 --> 01:22:01,207
volevamo solo diffondere
positività e amore nel mondo.

1290
01:22:01,374 --> 01:22:06,379
Che oggi gli adolescenti si sarebbero
depressi per pochi Mi piace

1291
01:22:06,463 --> 01:22:09,883
o che potesse causare polarizzazione
non l'avevamo immaginato.

1292
01:22:09,966 --> 01:22:12,469
Non credo che avessero cattive intenzioni.

1293
01:22:13,511 --> 01:22:15,764
È il modello di business
che ha un problema.

1294
01:22:15,847 --> 01:22:20,226
Potresti chiudere definitivamente
il servizio e distruggere quello che è,

1295
01:22:20,310 --> 01:22:24,522
azioni del valore di 20 miliardi
di dollari, ti faranno causa...

1296
01:22:24,606 --> 01:22:27,108
ma non puoi
rimettere il genio nella bottiglia.

1297
01:22:27,192 --> 01:22:30,403
Puoi fare qualche modifica,
ma alla fin fine,

1298
01:22:30,487 --> 01:22:34,199
devi aumentare i profitti e l'utilizzo
trimestre dopo trimestre.

1299
01:22:34,658 --> 01:22:37,494
Più diventa grande,
più è difficile da cambiare.

1300
01:22:38,495 --> 01:22:43,458
Io vedo un gruppo di persone
intrappolate da un modello di business,

1301
01:22:43,541 --> 01:22:46,169
da incentivi economici
e dalla pressione degli azionisti

1302
01:22:46,252 --> 01:22:48,922
che rendono quasi impossibile cambiare.

1303
01:22:49,005 --> 01:22:53,176
Dobbiamo accettare il fatto che va bene
che le aziende vogliano fare soldi.

1304
01:22:53,259 --> 01:22:56,888
Quello che non va bene è
che non ci siano regole né concorrenza

1305
01:22:56,972 --> 01:23:00,850
e che le aziende si comportino
come governi di fatto

1306
01:23:00,934 --> 01:23:03,353
e che dicano: "Ci regolamentiamo da sole."

1307
01:23:03,436 --> 01:23:05,981
Insomma, è una menzogna. È ridicolo.

1308
01:23:06,064 --> 01:23:09,150
Gli incentivi economici
fanno girare il mondo,

1309
01:23:09,234 --> 01:23:15,573
perciò la soluzione al problema deve
riorganizzare gli incentivi economici.

1310
01:23:16,074 --> 01:23:18,785
Non ci sono ragioni fiscali per cambiare.

1311
01:23:18,868 --> 01:23:21,329
Perciò ci vuole la regolamentazione.

1312
01:23:21,413 --> 01:23:24,290
Le compagnie telefoniche
hanno un sacco di dati sensibili

1313
01:23:24,374 --> 01:23:27,544
e ci sono tante leggi
che ne garantiscono un uso corretto.

1314
01:23:27,627 --> 01:23:31,506
Non c'è quasi nessuna legge
sulla privacy digitale, per esempio.

1315
01:23:31,589 --> 01:23:34,426
Potremmo tassare
la raccolta e il trattamento dei dati.

1316
01:23:34,509 --> 01:23:39,723
Così come paghi la bolletta dell'acqua
sulla base di quanta acqua usi,

1317
01:23:39,806 --> 01:23:43,226
tassi le aziende
in base ai dati che possiedono.

1318
01:23:43,309 --> 01:23:47,856
Genera un motivo fiscale
per non acquisire tutti i dati del mondo.

1319
01:23:47,939 --> 01:23:50,567
La legge è molto indietro su queste cose,

1320
01:23:50,650 --> 01:23:55,864
ma la situazione attuale
non esiste per tutelare gli utenti,

1321
01:23:55,947 --> 01:23:58,700
ma per tutelare i diritti e i privilegi

1322
01:23:58,783 --> 01:24:01,453
di questi ricchissimi giganti.

1323
01:24:02,245 --> 01:24:05,832
Dobbiamo sempre rimetterci
alle persone più ricche e potenti?

1324
01:24:05,915 --> 01:24:07,876
O arriverà il momento in cui diremo:

1325
01:24:07,959 --> 01:24:12,047
"Sapete, ci sono momenti
in cui c'è un interesse nazionale,

1326
01:24:12,130 --> 01:24:15,592
in cui gli interessi
delle persone, degli utenti,

1327
01:24:15,675 --> 01:24:17,385
è più importante

1328
01:24:18,011 --> 01:24:21,473
dei profitti di qualcuno
che è già miliardario"?

1329
01:24:21,890 --> 01:24:26,603
Questi mercati minano
la democrazia e la libertà

1330
01:24:26,686 --> 01:24:29,064
e dovrebbero essere dichiarati illegali.

1331
01:24:29,147 --> 01:24:31,524
Questa non è una proposta radicale.

1332
01:24:31,775 --> 01:24:34,194
Altri mercati sono dichiarati fuorilegge.

1333
01:24:34,277 --> 01:24:36,988
Il mercato degli organi umani.

1334
01:24:37,072 --> 01:24:39,491
Il mercato degli schiavi umani.

1335
01:24:39,949 --> 01:24:44,037
Perché hanno
conseguenze distruttive inevitabili.

1336
01:24:44,537 --> 01:24:45,830
Viviamo in un mondo

1337
01:24:45,914 --> 01:24:50,001
in cui un albero vale di più,
economicamente, da morto che da vivo,

1338
01:24:50,085 --> 01:24:53,838
in cui una balena vale
più da morta che da viva.

1339
01:24:53,922 --> 01:24:58,134
Finché l'economia funzionerà così
e le aziende non saranno regolamentate,

1340
01:24:58,218 --> 01:25:01,763
continueranno a distruggere gli alberi,
ad ammazzare balene,

1341
01:25:01,846 --> 01:25:06,101
a estrarre risorse e petrolio dalla terra,

1342
01:25:06,184 --> 01:25:08,394
pur sapendo di distruggere il pianeta

1343
01:25:08,478 --> 01:25:12,148
e di lasciare un mondo peggiore
alle generazioni future.

1344
01:25:12,232 --> 01:25:16,694
È una logica a breve termine basata
sulla religione del profitto a ogni costo,

1345
01:25:16,778 --> 01:25:20,156
come se per magia ogni azienda
che agisse nel suo interesse egoistico

1346
01:25:20,240 --> 01:25:21,950
producesse il risultato migliore.

1347
01:25:22,033 --> 01:25:24,494
Abbiamo effetti sull'ambiente
da tanto tempo.

1348
01:25:24,577 --> 01:25:27,288
La cosa spaventosa
e che, si spera, sia l'ultima goccia

1349
01:25:27,372 --> 01:25:29,207
che ci faccia svegliare come civiltà

1350
01:25:29,290 --> 01:25:31,709
e capire che si tratta
di una teoria fallace

1351
01:25:31,793 --> 01:25:35,004
è che ora siamo noi l'albero,
siamo noi la balena.

1352
01:25:35,088 --> 01:25:39,134
La nostra attenzione può essere sfruttata.
Siamo più redditizi per un'azienda

1353
01:25:39,217 --> 01:25:42,971
se passiamo il tempo a fissare
uno schermo, a fissare un annuncio,

1354
01:25:43,054 --> 01:25:45,890
che se viviamo la nostra vita
in modo soddisfacente.

1355
01:25:45,974 --> 01:25:47,559
I risultati si vedono.

1356
01:25:47,642 --> 01:25:50,687
Si vedono aziende
che usano l'intelligenza artificiale

1357
01:25:50,770 --> 01:25:53,648
per metterci nel sacco
e attirare la nostra attenzione

1358
01:25:53,731 --> 01:25:57,277
su cose che vogliono farci vedere,
piuttosto che su cose più in linea

1359
01:25:57,360 --> 01:25:59,821
coi nostri obiettivi e i nostri valori.

1360
01:26:02,991 --> 01:26:04,450
ORATORE PRINCIPALE DI OGGI

1361
01:26:05,535 --> 01:26:06,911
<i>Per me un computer è...</i>

1362
01:26:06,995 --> 01:26:10,290
lo strumento più straordinario
che abbiamo mai inventato.

1363
01:26:11,124 --> 01:26:14,002
<i>È l'equivalente di una bici</i>
<i>per la nostre mente.</i>

1364
01:26:15,503 --> 01:26:20,216
L'idea di una tecnologia umana era
il punto di partenza della Silicon Valley.

1365
01:26:21,050 --> 01:26:25,722
E l'abbiamo persa di vista
perché abbiamo dovuto fare la cosa figa,

1366
01:26:25,805 --> 01:26:27,265
invece della cosa giusta.

1367
01:26:27,348 --> 01:26:29,726
Internet era un posto stranissimo.

1368
01:26:29,809 --> 01:26:31,394
Era sperimentale.

1369
01:26:31,477 --> 01:26:34,731
Su Internet succedevano cose creative,
e succedono ancora,

1370
01:26:34,814 --> 01:26:38,610
ma sembra più
un centro commerciale gigantesco.

1371
01:26:38,693 --> 01:26:44,157
Uno pensa: "Dio, dev'essere
qualcosa di più di questo."

1372
01:26:46,743 --> 01:26:48,411
Io sono una ottimista.

1373
01:26:48,494 --> 01:26:52,540
Penso che possiamo cambiare
l'aspetto e il significato dei social.

1374
01:26:54,083 --> 01:26:57,921
Il modo in cui funziona la tecnologia
non è una legge della fisica.

1375
01:26:58,004 --> 01:27:02,175
Si tratta di scelte
fatte da esseri umani come me.

1376
01:27:02,759 --> 01:27:05,345
Gli esseri umani possono
cambiare queste tecnologie.

1377
01:27:06,971 --> 01:27:09,974
La domanda adesso è
se siamo disposti ad ammettere

1378
01:27:10,475 --> 01:27:15,438
che questi risultati negativi sono
il prodotto diretto del nostro lavoro.

1379
01:27:21,027 --> 01:27:24,864
Abbiamo costruito noi queste cose
e abbiamo la responsabilità di cambiarle.

1380
01:27:37,210 --> 01:27:42,298
<i>Il modello di estrazione dell'attenzione</i>
<i>non è modo di trattare gli esseri umani.</i>

1381
01:27:46,344 --> 01:27:48,137
Sono io oppure...

1382
01:27:49,847 --> 01:27:50,848
Povero fesso.

1383
01:27:51,432 --> 01:27:53,226
<i>Il tessuto di una società sana</i>

1384
01:27:53,309 --> 01:27:56,771
<i>dipende dall'abbandono</i>
<i>di questo modello di business dannoso.</i>

1385
01:28:04,529 --> 01:28:08,241
<i>Possiamo pretendere che questi prodotti</i>
<i>siano progettati in modo più umano.</i>

1386
01:28:09,284 --> 01:28:13,121
<i>Possiamo pretendere che non ci trattino</i>
<i>come risorse da sfruttare.</i>

1387
01:28:15,039 --> 01:28:18,710
<i>L'obiettivo potrebbe essere:</i>
<i>"Come si può migliorare il mondo?"</i>

1388
01:28:20,295 --> 01:28:23,798
<i>Nel corso della storia,</i>
<i>ogni volta che è migliorato qualcosa,</i>

1389
01:28:23,881 --> 01:28:26,342
è perché è arrivato qualcuno e ha detto:

1390
01:28:26,426 --> 01:28:29,012
"Che stupidaggine.
Possiamo fare di meglio."

1391
01:28:29,178 --> 01:28:32,557
<i>Sono i contestatori</i>
<i>quelli che portano al miglioramento.</i>

1392
01:28:33,141 --> 01:28:35,393
<i>Sono i contestatori i veri ottimisti.</i>

1393
01:28:38,313 --> 01:28:39,147
Salve.

1394
01:28:46,195 --> 01:28:48,281
Insomma, è un po' assurdo, no?

1395
01:28:48,656 --> 01:28:52,035
Il modo fondamentale
in cui sono progettate queste cose...

1396
01:28:52,827 --> 01:28:55,163
non sta andando in una bella direzione.

1397
01:28:55,246 --> 01:28:56,873
Mi riferisco a tutto.

1398
01:28:56,956 --> 01:29:00,626
Sembra assurdo dire
che dobbiamo cambiare proprio tutto,

1399
01:29:01,169 --> 01:29:03,046
ma dobbiamo fare proprio questo.

1400
01:29:04,339 --> 01:29:05,923
Secondo te, ci arriveremo?

1401
01:29:07,383 --> 01:29:08,301
Dobbiamo.

1402
01:29:21,314 --> 01:29:24,942
Mi sembra che tu sia molto ottimista.

1403
01:29:26,194 --> 01:29:27,445
Ti sembro ottimista?

1404
01:29:27,653 --> 01:29:30,114
Sì. È incredibile che tu dica questo,

1405
01:29:30,198 --> 01:29:33,409
perché ho detto:
"Ci stiamo muovendo verso la distopia.

1406
01:29:33,493 --> 01:29:37,830
Ci avviciniamo rapidamente alla distopia,
ci vorrà un miracolo per uscirne."

1407
01:29:37,914 --> 01:29:40,291
Questo miracolo è la volontà collettiva.

1408
01:29:41,000 --> 01:29:44,587
Sono ottimista
sul fatto che troveremo una soluzione,

1409
01:29:44,670 --> 01:29:47,048
ma credo che ci vorrà molto tempo,

1410
01:29:47,131 --> 01:29:50,385
perché non tutti riconoscono
che sia un problema.

1411
01:29:50,468 --> 01:29:55,890
Penso che uno dei grandi fallimenti
della tecnologia di oggi

1412
01:29:55,973 --> 01:29:58,643
è un fallimento di leadership,

1413
01:29:58,726 --> 01:30:01,979
di persone che prendano posizione
e parlino apertamente

1414
01:30:02,063 --> 01:30:05,900
non solo di quel che è andato bene,
ma di quello che non è perfetto

1415
01:30:05,983 --> 01:30:08,194
perché qualcuno realizzi
qualcosa di nuovo.

1416
01:30:08,277 --> 01:30:12,365
Alla fin fine,
questa macchina non invertirà la rotta

1417
01:30:12,448 --> 01:30:14,617
senza un'enorme pressione del pubblico.

1418
01:30:14,700 --> 01:30:18,329
Parlando di queste cose
ed esprimendo la tua opinione,

1419
01:30:18,413 --> 01:30:21,082
in certi casi
attraverso queste stesse tecnologie,

1420
01:30:21,165 --> 01:30:24,252
possiamo iniziare
a invertire la rotta e a cambiare.

1421
01:30:24,335 --> 01:30:27,004
Sembrerà strano,
ma è il mio mondo, la mia comunità.

1422
01:30:27,088 --> 01:30:29,632
Non li odio, non voglio
danneggiare Google o Facebook.

1423
01:30:29,715 --> 01:30:32,885
Voglio riformarli
in modo che non distruggano il mondo.

1424
01:30:32,969 --> 01:30:35,513
Ho disinstallato
un sacco di app dal cellulare

1425
01:30:35,596 --> 01:30:37,723
che erano solo una perdita di tempo.

1426
01:30:37,807 --> 01:30:40,685
Tutte le app dei social, delle notizie

1427
01:30:40,768 --> 01:30:42,520
e ho disattivato le notifiche

1428
01:30:42,603 --> 01:30:45,314
di quei messaggi
che mi facevano vibrare la gamba

1429
01:30:45,398 --> 01:30:48,693
per informazioni
che per me non sono importanti.

1430
01:30:48,901 --> 01:30:51,279
È il motivo per cui non porto
biscotti in tasca.

1431
01:30:51,362 --> 01:30:53,197
Riduci il numero di notifiche.

1432
01:30:53,281 --> 01:30:54,449
Disattiva le notifiche.

1433
01:30:54,532 --> 01:30:55,950
Disattivare le notifiche.

1434
01:30:56,033 --> 01:30:58,536
Io non uso più Google, ma Qwant,

1435
01:30:58,619 --> 01:31:01,497
che non salva
la cronologia delle ricerche.

1436
01:31:01,581 --> 01:31:04,459
Mai accettare
video consigliati per te su YouTube.

1437
01:31:04,542 --> 01:31:07,003
Scegli sempre.
È un altro modo per combattere.

1438
01:31:07,086 --> 01:31:12,133
Ci sono un sacco di estensioni
di Chrome che eliminano i consigli.

1439
01:31:12,216 --> 01:31:15,636
Bello che consigli una cosa
per disfare quello che hai fatto.

1440
01:31:15,720 --> 01:31:16,554
Già.

1441
01:31:16,929 --> 01:31:21,642
Prima di condividere, verifica,
valuta la fonte, fai una ricerca.

1442
01:31:21,726 --> 01:31:25,104
Se ti sembra una cosa progettata
per premere dei tasti emotivi,

1443
01:31:25,188 --> 01:31:26,314
probabilmente lo è.

1444
01:31:26,397 --> 01:31:29,025
Fondamentalmente, voti con i clic.

1445
01:31:29,108 --> 01:31:33,738
Le esche digitali generano incentivi
che alimentano questo sistema.

1446
01:31:33,863 --> 01:31:37,909
Assicurati di attingere
a tanti tipi di informazioni diverse.

1447
01:31:37,992 --> 01:31:40,995
Io seguo persone su Twitter
con cui non sono d'accordo,

1448
01:31:41,078 --> 01:31:44,207
voglio essere esposta
a punti di vista diversi.

1449
01:31:44,665 --> 01:31:49,045
Tanta gente del settore tech
non dà questi dispositivi ai figli.

1450
01:31:49,128 --> 01:31:51,255
I miei figli non usano proprio i social.

1451
01:31:51,964 --> 01:31:53,549
È una regola o è un...

1452
01:31:53,633 --> 01:31:54,509
È una regola.

1453
01:31:55,092 --> 01:31:57,845
Siamo dei fanatici.

1454
01:31:57,929 --> 01:31:59,222
Siamo pazzi

1455
01:31:59,305 --> 01:32:05,603
e non permettiamo proprio ai nostri figli
di passare del tempo allo schermo.

1456
01:32:05,686 --> 01:32:08,564
Ho elaborato tre semplici regole

1457
01:32:08,648 --> 01:32:12,610
che semplificano la vita delle famiglie
e che si basano su degli studi.

1458
01:32:12,693 --> 01:32:15,571
La prima è che i dispositivi escano
dalla stanza da letto

1459
01:32:15,655 --> 01:32:17,281
a un orario fisso ogni sera.

1460
01:32:17,365 --> 01:32:20,535
Un'ora qualsiasi, mezz'ora
prima di andare a letto, fuori.

1461
01:32:20,618 --> 01:32:24,038
La seconda regola è
niente social prima del liceo.

1462
01:32:24,121 --> 01:32:26,374
Io credo che l'età dovrebbe
essere 16 anni.

1463
01:32:26,457 --> 01:32:28,960
Le medie sono già dure,
niente fino al liceo.

1464
01:32:29,043 --> 01:32:32,964
E la terza regola è calcola
il tempo massimo con tuo figlio.

1465
01:32:33,047 --> 01:32:34,757
Se chiedi a tuo figlio:

1466
01:32:34,840 --> 01:32:37,927
"Quante ore al giorno
vuoi passare sul dispositivo,

1467
01:32:38,010 --> 01:32:39,637
secondo te quante ore vanno bene?"

1468
01:32:39,720 --> 01:32:41,597
spesso ti dice  cose ragionevoli.

1469
01:32:42,056 --> 01:32:44,642
Senti, so perfettamente

1470
01:32:44,725 --> 01:32:48,563
che non convincerò tutti
a cancellare gli account dei social,

1471
01:32:48,646 --> 01:32:50,439
ma qualcuno sì.

1472
01:32:50,523 --> 01:32:54,402
Convincere alcune persone
a cancellare l'account è importante,

1473
01:32:54,485 --> 01:32:58,406
perché questo crea lo spazio di un dialogo

1474
01:32:58,489 --> 01:33:00,908
perché voglio che ci siano
abbastanza persone

1475
01:33:00,992 --> 01:33:05,204
libere dai motori di manipolazione
che abbiano un dialogo

1476
01:33:05,288 --> 01:33:07,540
che non sia limitato
dai motori di manipolazione.

1477
01:33:07,623 --> 01:33:10,126
Perciò, fatelo! Uscite dal sistema.

1478
01:33:10,209 --> 01:33:12,712
Sì, cancella.
Abbandona queste sciocchezze.

1479
01:33:13,546 --> 01:33:16,507
Il mondo è bello.
Guarda, lì fuori è fantastico.

1480
01:33:18,467 --> 01:33:19,969
SEGUITECI SUI SOCIAL!

1481
01:33:20,052 --> 01:33:21,887
SCHERZIAMO.

1482
01:33:21,971 --> 01:33:27,476
APRIAMO UN DIALOGO PER UNA SOLUZIONE
TheSocialDilemma.com

1483
01:33:32,356 --> 01:33:34,609
Sottotitoli: Monica Paolillo


