1
00:00:31.114 --> 00:00:34,659
Why don't you go ahead?
Sit down and see if you can get comfy.

2
00:00:37.579 --> 00:00:39,789
-You good? All right.
-Yeah. 

3
00:00:39.914 --> 00:00:42,125
Um...

4
00:00:43.043 --> 00:00:44,794
Take one, marker.

5
00:00:46.796 --> 00:00:48,798
Wanna start
by introducing yourself?

6
00:00:50.467 --> 00:00:53,344
Hello, world. Bailey. Take three.

7
00:00:53.970 --> 00:00:56,347
You good?
-This is the worst part, man.

8
00:00:56.890 --> 00:00:59,517
I don't like this.

9
00:00:59.851 --> 00:01:02,228
I worked at Facebook in 2011 and 2012.

10
00:01:02.312 --> 00:01:05,190
I was one of the really early employees
at Instagram.

11
00:01:05.273 --> 00:01:08,693
I worked at, uh, Google,
uh, YouTube.

12
00:01:08.777 --> 00:01:11,696
Apple, Google, Twitter, Palm.

13
00:01:12.739 --> 00:01:15,533
I helped start Mozilla Labs
and switched over to the Firefox side.

14
00:01:15.617 --> 00:01:18,119
Are we rolling? Everybody?

15
00:01:18.203 --> 00:01:19,162
Great.

16
00:01:21.206 --> 00:01:22,624
I worked at Twitter.

17
00:01:23.041 --> 00:01:23,917
My last job there

18
00:01:24.000 --> 00:01:26,169
was the senior vice president
of engineering.

19
00:01:27.337 --> 00:01:29,255
I was the president of Pinterest.

20
00:01:29.339 --> 00:01:32,717
Before that, um,
I was the... the director of monetization

21
00:01:32.801 --> 00:01:34,260
at Facebook for five years.

22
00:01:34.344 --> 00:01:37,972
While at Twitter, I spent a number
of years running their developer platform,

23
00:01:38.056 --> 00:01:40,225
and then I became
head of consumer product.

24
00:01:40.308 --> 00:01:44,270
I was the coinventor of Google Drive,
Gmail Chat,

25
00:01:44.354 --> 00:01:46,689
Facebook Pages,
and the Facebook like button.

26
00:01:47.440 --> 00:01:50,777
Yeah. This is... This is why I spent,
like, eight months

27
00:01:50.860 --> 00:01:52,779
talking back and forth with lawyers.

28
00:01:54.072 --> 00:01:55,406
This freaks me out.

29
00:01:58.409 --> 00:01:59,702
When I was there,

30
00:01:59.786 --> 00:02:02,914
I always felt like,
fundamentally, it was a force for good.

31
00:02:03.414 --> 00:02:05,375
I don't know if I feel that way anymore.

32
00:02:05.458 --> 00:02:10,588
I left Google in June 2017, uh,
due to ethical concerns.

33
00:02:10.672 --> 00:02:14,134
And... And not just at Google
but within the industry at large.

34
00:02:14.217 --> 00:02:15,385
I'm very concerned.

35
00:02:16.636 --> 00:02:17,679
I'm very concerned.

36
00:02:19.097 --> 00:02:21,808
It's easy today to lose sight of the fact

37
00:02:21.891 --> 00:02:27,814
that these tools actually have created
some wonderful things in the world.

38
00:02:27.897 --> 00:02:31,943
They've reunited lost family members.
They've found organ donors.

39
00:02:32.026 --> 00:02:36,573
I mean, there were meaningful,
systemic changes happening

40
00:02:36.656 --> 00:02:39,159
around the world
because of these platforms

41
00:02:39.242 --> 00:02:40,285
that were positive!

42
00:02:40.827 --> 00:02:44,539
I think we were naive
about the flip side of that coin.

43
00:02:45.540 --> 00:02:48,585
Yeah, these things, you release them,
and they take on a life of their own.

44
00:02:48.668 --> 00:02:52,005
And how they're used is pretty different
than how you expected.

45
00:02:52.088 --> 00:02:56,509
Nobody, I deeply believe,
ever intended any of these consequences.

46
00:02:56.593 --> 00:02:59,554
There's no one bad guy.
No. Absolutely not.

47
00:03:01.598 --> 00:03:03,975
So, then,
what's the... what's the problem?

48
00:03:09.147 --> 00:03:11,482
Is there a problem,
and what is the problem?

49
00:03:17.614 --> 00:03:19,991
Yeah, it is hard
to give a single, succinct...

50
00:03:20.074 --> 00:03:22,118
I'm trying to touch on
many different problems.

51
00:03:22.535 --> 00:03:23,953
What is the problem?

52
00:03:35.423 --> 00:03:37,675
the so-called Big Tech names
are getting bigger.

53
00:03:37.759 --> 00:03:40,929
The entire tech industry is
under a new level of scrutiny.

54
00:03:41.012 --> 00:03:43,806
And a new study sheds light on the link

55
00:03:43.890 --> 00:03:46,142
between mental health
and social media use.

56
00:03:48.770 --> 00:03:51,397
...is going on
that gets no coverage at all.

57
00:03:51.481 --> 00:03:54,108
Tens of millions of Americans
are hopelessly addicted

58
00:03:54.192 --> 00:03:56,319
to their electronic devices.

59
00:03:56.402 --> 00:03:57,987
It's exacerbated by the fact

60
00:03:58.071 --> 00:04:00,698
that you can literally isolate yourself
now

61
00:04:00.782 --> 00:04:02,742
in a bubble, thanks to our technology.

62
00:04:02.825 --> 00:04:04,577
Fake news is becoming more advanced

63
00:04:04.661 --> 00:04:06,788
and threatening societies
around the world.

64
00:04:06.871 --> 00:04:10,250
We weren't expecting any of this
when we created Twitter over 12 years ago.

65
00:04:10.333 --> 00:04:12,502
White House officials say
they have no reason to believe

66
00:04:12.585 --> 00:04:14,754
the Russian cyberattacks will stop.

67
00:04:14.837 --> 00:04:18,132
YouTube is being forced
to concentrate on cleansing the site.

68
00:04:18.216 --> 00:04:21,552
TikTok,
if you talk to any tween out there...

69
00:04:21.636 --> 00:04:24,013
...there's no chance
they'll delete this thing...

70
00:04:24.097 --> 00:04:26,224
Hey, Isla,
can you get the table ready, please?

71
00:04:26.307 --> 00:04:28,601
There's a question
about whether social media

72
00:04:28.685 --> 00:04:29,978
is making your child depressed.

73
00:04:30.061 --> 00:04:32,105
Isla,
can you set the table, please?

74
00:04:32.188 --> 00:04:35,316
These cosmetic procedures
are becoming so popular with teens,

75
00:04:35.400 --> 00:04:37,902
plastic surgeons have coined
a new syndrome for it,

76
00:04:37.986 --> 00:04:40,822
"Snapchat dysmorphia,"
with young patients wanting surgery

77
00:04:40.905 --> 00:04:43,741
so they can look more like they do
in filtered selfies.

78
00:04:43.825 --> 00:04:45,910
Still don't see why you let her have
that thing.

79
00:04:45.994 --> 00:04:47,412
What was I supposed to do?

80
00:04:47.495 --> 00:04:49,580
I mean, every other kid
in her class had one.

81
00:04:50.164 --> 00:04:51,165
She's only 11.

82
00:04:51.249 --> 00:04:52,959
Cass, no one's forcing you to get one.

83
00:04:53.042 --> 00:04:55,086
You can stay disconnected
as long as you want.

84
00:04:55.169 --> 00:04:59,340
Hey, I'm connected without a cell phone,
okay? I'm on the Internet right now.

85
00:04:59.424 --> 00:05:03,094
Also, that isn't even actual connection.
It's just a load of sh--

86
00:05:03.177 --> 00:05:05,013
Surveillance capitalism has come to shape

87
00:05:05.096 --> 00:05:07,765
our politics and culture
in ways many people don't perceive.

88
00:05:10.184 --> 00:05:12,812
and now white supremacists
are doing the same.

89
00:05:12.895 --> 00:05:14,147
Recently in India,

90
00:05:14.230 --> 00:05:17,442
Internet lynch mobs have killed
a dozen people, including these five...

91
00:05:17.525 --> 00:05:20,361
It's not just fake news;
it's fake news with consequences.

92
00:05:20.445 --> 00:05:24,073
How do you handle an epidemic
in the age of fake news?

93
00:05:24.157 --> 00:05:26,993
Can you get the coronavirus
by eating Chinese food?

94
00:05:27.535 --> 00:05:32,540
We have gone from the information age
into the disinformation age.

95
00:05:32.623 --> 00:05:34,667
Our democracy is under assault.

96
00:05:34.751 --> 00:05:36,919
What I said was,
"I think the tools

97
00:05:37.003 --> 00:05:39,005
that have been created today are starting

98
00:05:39.088 --> 00:05:41,799
to erode the social fabric
of how society works."

99
00:05:58.566 --> 00:05:59,442
Fine.

100
00:06:00.151 --> 00:06:03,446
Aza does
welcoming remarks. We play the video.

101
00:06:04.197 --> 00:06:07,325
And then, "Ladies and gentlemen,
Tristan Harris."

102
00:06:07.408 --> 00:06:08,868
-Right.
Great.

103
00:06:08.951 --> 00:06:12,038
So, I come up, and...

104
00:06:13.831 --> 00:06:17,126
basically say, "Thank you all for coming."
Um...

105
00:06:17.919 --> 00:06:22,048
So, today, I wanna talk about a new agenda
for technology.

106
00:06:22.131 --> 00:06:25,468
And why we wanna do that
is because if you ask people,

107
00:06:25.551 --> 00:06:27,804
"What's wrong in the tech industry
right now?"

108
00:06:28.262 --> 00:06:31,641
there's a cacophony of grievances
and scandals,

109
00:06:31.724 --> 00:06:33,893
and "They stole our data."
And there's tech addiction.

110
00:06:33.976 --> 00:06:35,978
And there's fake news.
And there's polarization

111
00:06:36.062 --> 00:06:37,855
and some elections
that are getting hacked.

112
00:06:38.189 --> 00:06:41,609
But is there something
that is beneath all these problems

113
00:06:41.692 --> 00:06:44,612
that's causing all these things
to happen at once?

114
00:06:46.447 --> 00:06:48,408
-Does this feel good?
-Very good. Yeah.

115
00:06:49.033 --> 00:06:49,992
Um... 

116
00:06:50.743 --> 00:06:52,954
I'm just trying to...
Like, I want people to see...

117
00:06:53.037 --> 00:06:55,123
Like, there's a problem happening
in the tech industry,

118
00:06:55.206 --> 00:06:56,707
and it doesn't have a name,

119
00:06:56.791 --> 00:07:00,211
and it has to do with one source,
like, one...

120
00:07:05.091 --> 00:07:09,387
When you look around you,
it feels like the world is going crazy.

121
00:07:12.765 --> 00:07:15,309
You have to ask yourself, like,
"Is this normal?

122
00:07:16.102 --> 00:07:18,771
Or have we all fallen under some kind
of spell?"

123
00:07:27.989 --> 00:07:30,491
I wish more people could understand
how this works

124
00:07:30.575 --> 00:07:34,036
because it shouldn't be something
that only the tech industry knows.

125
00:07:34.120 --> 00:07:36,247
It should be something
that everybody knows.

126
00:07:41.419 --> 00:07:42,378
Bye.

127
00:07:43.629 --> 00:07:44,881
Here you go, sir.

128
00:07:47.383 --> 00:07:48,676
Hello!
Hi.

129
00:07:48.759 --> 00:07:50,678
-Tristan. Nice to meet you.
right?

130
00:07:50.761 --> 00:07:51,721
-Yes.
-Awesome. Cool.

131
00:07:53.181 --> 00:07:55,933
Tristan Harris
is a former design ethicist for Google

132
00:07:56.017 --> 00:07:59,395
and has been called the closest thing
Silicon Valley has to a conscience.

133
00:07:59.479 --> 00:08:00,730
He's asking tech

134
00:08:00.813 --> 00:08:04,192
to bring what he calls "ethical design"
to its products.

135
00:08:04.275 --> 00:08:06,903
It's rare
for a tech insider to be so blunt,

136
00:08:06.986 --> 00:08:10,114
but Tristan Harris believes
someone needs to be.

137
00:08:11.324 --> 00:08:12,700
When I was at Google,

138
00:08:12.783 --> 00:08:16,037
I was on the Gmail team,
and I just started getting burnt out

139
00:08:16.120 --> 00:08:18,372
'cause we'd had
so many conversations about...

140
00:08:19.457 --> 00:08:23,169
you know, what the inbox should look like
and what color it should be, and...

141
00:08:23.252 --> 00:08:25,880
And I, you know, felt personally addicted
to e-mail,

142
00:08:26.297 --> 00:08:27,632
and I found it fascinating

143
00:08:27.715 --> 00:08:31,511
there was no one at Gmail working
on making it less addictive.

144
00:08:31.969 --> 00:08:34,514
And I was like,
"Is anybody else thinking about this?

145
00:08:34.597 --> 00:08:36,390
I haven't heard anybody talk about this."

146
00:08:36.849 --> 00:08:39,685
-And I was feeling this frustration...

147
00:08:39.769 --> 00:08:41,229
...with the tech industry, overall,

148
00:08:41.312 --> 00:08:43,147
that we'd kind of, like, lost our way.

149
00:08:46.817 --> 00:08:49,820
You know, I really struggled
to try and figure out

150
00:08:49.904 --> 00:08:52,573
how, from the inside, we could change it.

151
00:08:55.201 --> 00:08:58,120
And that was when I decided
to make a presentation,

152
00:08:58.204 --> 00:08:59,497
kind of a call to arms.

153
00:09:00.998 --> 00:09:04,961
Every day, I went home and I worked on it
for a couple hours every single night.

154
00:09:06.170 --> 00:09:08,548
It basically just said,
you know,

155
00:09:08.631 --> 00:09:11,884
never before
in history have 50 designers--

156
00:09:12.426 --> 00:09:15,263
20- to 35-year-old white guys
in California--

157
00:09:15.888 --> 00:09:19,725
made decisions that would have an impact
on two billion people.

158
00:09:21.018 --> 00:09:24,438
Two billion people will have thoughts
that they didn't intend to have

159
00:09:24.522 --> 00:09:28,401
because a designer at Google said,
"This is how notifications work

160
00:09:28.484 --> 00:09:30,778
on that screen that you wake up to
in the morning."

161
00:09:31.195 --> 00:09:35,283
And we have a moral responsibility,
as Google, for solving this problem.

162
00:09:36.075 --> 00:09:37,743
And I sent this presentation 

163
00:09:37.827 --> 00:09:41,789
to about 15, 20 of my closest colleagues
at Google,

164
00:09:41.872 --> 00:09:44,959
and I was very nervous about it.
I wasn't sure how it was gonna land.

165
00:09:46.460 --> 00:09:48,045
When I went to work the next day,

166
00:09:48.129 --> 00:09:50,464
most of the laptops
had the presentation open.

167
00:09:52.133 --> 00:09:54,552
Later that day, there was, like,
400 simultaneous viewers,

168
00:09:54.635 --> 00:09:56,053
so it just kept growing and growing.

169
00:09:56.137 --> 00:10:00,266
I got e-mails from all around the company.
I mean, people in every department saying,

170
00:10:00.349 --> 00:10:02,852
"I totally agree."
"I see this affecting my kids."

171
00:10:02.935 --> 00:10:04,979
"I see this affecting
the people around me."

172
00:10:05.062 --> 00:10:06,939
"We have to do something about this."

173
00:10:07.481 --> 00:10:10,818
It felt like I was sort of launching
a revolution or something like that.

174
00:10:11.861 --> 00:10:15,197
Later, I found out Larry Page
had been notified about this presentation

175
00:10:15.281 --> 00:10:17,908
-in three separate meetings that day.

176
00:10:17.992 --> 00:10:20,286
And so, it created
this kind of cultural moment

177
00:10:20.870 --> 00:10:24,415
-that Google needed to take seriously.

178
00:10:26.000 --> 00:10:28,878
And then... nothing.

179
00:10:34.300 --> 00:10:36,135
Everyone in 2006...

180
00:10:37.219 --> 00:10:39,221
including all of us at Facebook,

181
00:10:39.305 --> 00:10:43,392
just had total admiration for Google
and what Google had built,

182
00:10:43.476 --> 00:10:47,396
which was this incredibly useful service

183
00:10:47.480 --> 00:10:51,442
that did, far as we could tell,
lots of goodness for the world,

184
00:10:51.525 --> 00:10:54,695
and they built
this parallel money machine.

185
00:10:55.404 --> 00:11:00,034
We had such envy for that,
and it seemed so elegant to us...

186
00:11:00.826 --> 00:11:02,161
and so perfect.

187
00:11:02.953 --> 00:11:05,289
Facebook had been around
for about two years,

188
00:11:05.373 --> 00:11:08,376
um, and I was hired to come in
and figure out

189
00:11:08.459 --> 00:11:10,586
what the business model was gonna be
for the company.

190
00:11:10.670 --> 00:11:13,422
I was the director of monetization.
The point was, like,

191
00:11:13.506 --> 00:11:17,051
"You're the person who's gonna figure out
how this thing monetizes."

192
00:11:17.134 --> 00:11:19,804
And there were a lot of people
who did a lot of the work,

193
00:11:19.887 --> 00:11:25,476
but I was clearly one of the people
who was pointing towards...

194
00:11:26.769 --> 00:11:28,562
"Well, we have to make money, A...

195
00:11:29.313 --> 00:11:33,651
and I think this advertising model
is probably the most elegant way.

196
00:11:42.243 --> 00:11:44,370
Uh-oh. What's this video Mom just sent us?

197
00:11:44.453 --> 00:11:46,747
Oh, that's from a talk show,
but that's pretty good.

198
00:11:46.831 --> 00:11:47,873
Guy's kind of a genius.

199
00:11:47.957 --> 00:11:50,584
He's talking all about deleting
social media, which you gotta do.

200
00:11:50.668 --> 00:11:52,878
I might have to start blocking
her e-mails.

201
00:11:52.962 --> 00:11:54,880
I don't even know
what she's talking about, man.

202
00:11:54.964 --> 00:11:56,090
She's worse than I am.

203
00:11:56.173 --> 00:11:58,509
-No, she only uses it for recipes.
-Right, and work.

204
00:11:58.592 --> 00:12:00,553
-And workout videos.
And to check up on us.

205
00:12:00.636 --> 00:12:03,055
And everyone else she's ever met
in her entire life.

206
00:12:04.932 --> 00:12:07,893
If you are scrolling through
your social media feed

207
00:12:07.977 --> 00:12:11,731
while you're watchin' us, you need to put
the damn phone down and listen up

208
00:12:11.814 --> 00:12:14,817
'cause our next guest has written
an incredible book

209
00:12:14.900 --> 00:12:18,112
about how much it's wrecking our lives.

210
00:12:18.195 --> 00:12:19,447
Please welcome author

211
00:12:19.530 --> 00:12:23,951
Ten Arguments for Deleting
Your Social Media Accounts Right Now...

212
00:12:24.034 --> 00:12:26,287
Uh-huh.
-...Jaron Lanier.

213
00:12:27.997 --> 00:12:31,834
Companies like Google and Facebook
are some of the wealthiest

214
00:12:31.917 --> 00:12:33,544
and most successful of all time.

215
00:12:33.711 --> 00:12:36,839
Uh, they have relatively few employees.

216
00:12:36.922 --> 00:12:41,427
They just have this giant computer
that rakes in money, right? Uh...

217
00:12:41.510 --> 00:12:42,970
Now, what are they being paid for?

218
00:12:47.308 --> 00:12:50,311
So, I've been an investor
in technology for 35 years.

219
00:12:51.020 --> 00:12:54,356
The first 50 years of Silicon Valley,
the industry made products--

220
00:12:54.440 --> 00:12:55,566
hardware, software--

221
00:12:55.649 --> 00:12:58,402
sold 'em to customers.
Nice, simple business.

222
00:12:58.486 --> 00:13:01,447
For the last ten years,
the biggest companies in Silicon Valley

223
00:13:01.530 --> 00:13:03,866
have been in the business
of selling their users.

224
00:13:03.949 --> 00:13:05,910
It's a little even trite to say now,

225
00:13:05.993 --> 00:13:09,205
but... because we don't pay
for the products that we use,

226
00:13:09.288 --> 00:13:12,166
advertisers pay
for the products that we use.

227
00:13:12.249 --> 00:13:14,210
Advertisers are the customers.

228
00:13:14.710 --> 00:13:16,086
We're the thing being sold.

229
00:13:16.170 --> 00:13:17,630
The classic saying is:

230
00:13:17.713 --> 00:13:21,592
"If you're not paying for the product,
then you are the product."

231
00:13:23.385 --> 00:13:27,223
A lot of people think, you know,
"Oh, well, Google's just a search box,

232
00:13:27.306 --> 00:13:29,850
and Facebook's just a place to see
what my friends are doing

233
00:13:29.934 --> 00:13:31,101
and see their photos."

234
00:13:31.185 --> 00:13:35,481
But what they don't realize
is they're competing for your attention.

235
00:13:36.524 --> 00:13:41,111
So, you know, Facebook, Snapchat,
Twitter, Instagram, YouTube,

236
00:13:41.195 --> 00:13:45,699
companies like this, their business model
is to keep people engaged on the screen.

237
00:13:46.283 --> 00:13:49,578
Let's figure out how to get
as much of this person's attention

238
00:13:49.662 --> 00:13:50,955
as we possibly can.

239
00:13:51.455 --> 00:13:53,374
How much time can we get you to spend?

240
00:13:53.874 --> 00:13:56,669
How much of your life can we get you
to give to us?

241
00:13:58.629 --> 00:14:01,090
When you think about
how some of these companies work,

242
00:14:01.173 --> 00:14:02,424
it starts to make sense.

243
00:14:03.050 --> 00:14:06,095
There are all these services
on the Internet that we think of as free,

244
00:14:06.178 --> 00:14:09,473
but they're not free.
They're paid for by advertisers.

245
00:14:09.557 --> 00:14:11,559
Why do advertisers pay those companies?

246
00:14:11.642 --> 00:14:14,687
They pay in exchange for showing their ads
to us.

247
00:14:14.770 --> 00:14:18,357
We're the product. Our attention
is the product being sold to advertisers.

248
00:14:18.816 --> 00:14:20,442
That's a little too simplistic.

249
00:14:20.860 --> 00:14:23,654
It's the gradual, slight,
imperceptible change

250
00:14:23.737 --> 00:14:26,574
in your own behavior and perception
that is the product.

251
00:14:27.658 --> 00:14:30,244
the product.
It's the only possible product.

252
00:14:30.327 --> 00:14:34,081
There's nothing else on the table
that could possibly be called the product.

253
00:14:34.164 --> 00:14:37,001
That's the only thing there is
for them to make money from.

254
00:14:37.668 --> 00:14:39,253
Changing what you do,

255
00:14:39.336 --> 00:14:41,714
how you think, who you are.

256
00:14:42.631 --> 00:14:45,301
It's a gradual change. It's slight.

257
00:14:45.384 --> 00:14:48,971
If you can go to somebody and you say,
"Give me $10 million,

258
00:14:49.054 --> 00:14:54,310
and I will change the world one percent
in the direction you want it to change..."

259
00:14:54.852 --> 00:14:58,188
It's the world! That can be incredible,
and that's worth a lot of money.

260
00:14:59.315 --> 00:15:00,149
Okay.

261
00:15:00.691 --> 00:15:04,570
This is what every business
has always dreamt of:

262
00:15:04.653 --> 00:15:10,910
to have a guarantee that if it places
an ad, it will be successful.

263
00:15:11.327 --> 00:15:12,786
That's their business.

264
00:15:12.870 --> 00:15:14,413
They sell certainty.

265
00:15:14.997 --> 00:15:17,625
In order to be successful
in that business,

266
00:15:17.708 --> 00:15:19,793
you have to have great predictions.

267
00:15:20.085 --> 00:15:24,173
Great predictions begin
with one imperative:

268
00:15:25.215 --> 00:15:26,926
you need a lot of data.

269
00:15:29.136 --> 00:15:31,305
Many people call this
surveillance capitalism,

270
00:15:31.639 --> 00:15:34,350
capitalism profiting
off of the infinite tracking

271
00:15:34.433 --> 00:15:38,062
of everywhere everyone goes
by large technology companies

272
00:15:38.145 --> 00:15:40,356
whose business model is to make sure

273
00:15:40.439 --> 00:15:42,858
that advertisers are as successful
as possible.

274
00:15:42.942 --> 00:15:45,569
This is a new kind of marketplace now.

275
00:15:45.653 --> 00:15:48,072
It's a marketplace
that never existed before.

276
00:15:48.822 --> 00:15:55,371
And it's a marketplace
that trades exclusively in human futures.

277
00:15:56.080 --> 00:16:01,585
Just like there are markets that trade
in pork belly futures or oil futures.

278
00:16:02.127 --> 00:16:07,591
We now have markets
that trade in human futures at scale,

279
00:16:08.175 --> 00:16:13,472
and those markets have produced
the trillions of dollars

280
00:16:14.014 --> 00:16:19,269
that have made the Internet companies
the richest companies

281
00:16:19.353 --> 00:16:22,356
in the history of humanity.

282
00:16:27.361 --> 00:16:30,990
What I want people to know
is that everything they're doing online

283
00:16:31.073 --> 00:16:34,326
being tracked,
being measured.

284
00:16:35.035 --> 00:16:39,623
Every single action you take
is carefully monitored and recorded.

285
00:16:39.707 --> 00:16:43,836
Exactly what image you stop and look at,
for how long you look at it.

286
00:16:43.919 --> 00:16:45,796
Oh, yeah, seriously,
for how long you look at it.

287
00:16:50.509 --> 00:16:52,219
They know
when people are lonely.

288
00:16:52.302 --> 00:16:53,804
They know when people are depressed.

289
00:16:53.887 --> 00:16:57,099
They know when people are looking
at photos of your ex-romantic partners.

290
00:16:57.182 --> 00:17:00,853
They know what you're doing late at night.
They know the entire thing.

291
00:17:01.270 --> 00:17:03,230
Whether you're an introvert
or an extrovert,

292
00:17:03.313 --> 00:17:06,817
or what kind of neuroses you have,
what your personality type is like.

293
00:17:08.193 --> 00:17:11,613
They have more information
about us

294
00:17:11.697 --> 00:17:14,324
than has ever been imagined
in human history.

295
00:17:14.950 --> 00:17:16,368
It is unprecedented.

296
00:17:18.579 --> 00:17:22,791
And so, all of this data that we're...
that we're just pouring out all the time

297
00:17:22.875 --> 00:17:26,754
is being fed into these systems
that have almost no human supervision

298
00:17:27.463 --> 00:17:30,883
and that are making better and better
and better and better predictions

299
00:17:30.966 --> 00:17:33,552
about what we're gonna do
and... and who we are.

300
00:17:36.305 --> 00:17:39,349
People have the misconception
it's our data being sold.

301
00:17:40.350 --> 00:17:43,187
It's not in Facebook's business interest
to give up the data.

302
00:17:45.522 --> 00:17:47,107
What do they do with that data?

303
00:17:51.070 --> 00:17:54,490
They build models
that predict our actions,

304
00:17:54.573 --> 00:17:57,618
and whoever has the best model wins.

305
00:18:02.706 --> 00:18:04,041
His scrolling speed is slowing.

306
00:18:04.124 --> 00:18:06,085
Nearing the end
of his average session length.

307
00:18:06.168 --> 00:18:07,002
Decreasing ad load.

308
00:18:07.086 --> 00:18:08,337
Pull back on friends and family.

309
00:18:09.588 --> 00:18:11,340
On the other side of the screen,

310
00:18:11.423 --> 00:18:15,469
it's almost as if they had
this avatar voodoo doll-like model of us.

311
00:18:16.845 --> 00:18:18,180
All of the things we've ever done,

312
00:18:18.263 --> 00:18:19,473
all the clicks we've ever made,

313
00:18:19.556 --> 00:18:21,642
all the videos we've watched,
all the likes,

314
00:18:21.725 --> 00:18:25,354
that all gets brought back into building
a more and more accurate model.

315
00:18:25.896 --> 00:18:27,481
The model, once you have it,

316
00:18:27.564 --> 00:18:29,858
you can predict the kinds of things
that person does.

317
00:18:29.942 --> 00:18:31,777
Right, let me just test.

318
00:18:32.569 --> 00:18:34,988
Where you'll go.
I can predict what kind of videos

319
00:18:35.072 --> 00:18:36,115
will keep you watching.

320
00:18:36.198 --> 00:18:39,159
I can predict what kinds of emotions tend
to trigger you.

321
00:18:39.243 --> 00:18:40,410
Yes, perfect.

322
00:18:41.578 --> 00:18:43,372
The most epic fails of the year.

323
00:18:48.627 --> 00:18:51,088
-Perfect. That worked.
-Following with another video.

324
00:18:51.171 --> 00:18:54,049
Beautiful. Let's squeeze in a sneaker ad
before it starts.

325
00:18:56.426 --> 00:18:58,178
At a lot
of technology companies,

326
00:18:58.262 --> 00:18:59,721
there's three main goals.

327
00:18:59.805 --> 00:19:01,348
There's the engagement goal:

328
00:19:01.431 --> 00:19:03,684
to drive up your usage,
to keep you scrolling.

329
00:19:04.601 --> 00:19:06,145
There's the growth goal:

330
00:19:06.228 --> 00:19:08,689
to keep you coming back
and inviting as many friends

331
00:19:08.772 --> 00:19:10,816
and getting them to invite more friends.

332
00:19:11.650 --> 00:19:13,152
And then there's the advertising goal:

333
00:19:13.235 --> 00:19:14,987
to make sure that,
as all that's happening,

334
00:19:15.070 --> 00:19:17,406
we're making as much money as possible
from advertising.

335
00:19:19.241 --> 00:19:21,994
Each of these goals are powered
by algorithms

336
00:19:22.077 --> 00:19:24,454
whose job is to figure out
what to show you

337
00:19:24.538 --> 00:19:26,165
to keep those numbers going up.

338
00:19:26.623 --> 00:19:29,918
We often talked about, at Facebook,
this idea

339
00:19:30.002 --> 00:19:34,006
of being able to just dial that as needed.

340
00:19:34.673 --> 00:19:38,594
And, you know, we talked
about having Mark have those dials.

341
00:19:41.305 --> 00:19:44,474
"Hey, I want more users in Korea today."

342
00:19:45.684 --> 00:19:46,602
"Turn the dial."

343
00:19:47.436 --> 00:19:49,188
"Let's dial up the ads a little bit."

344
00:19:49.980 --> 00:19:51,899
"Dial up monetization, just slightly."

345
00:19:52.858 --> 00:19:55,444
And so, that happ--

346
00:19:55.527 --> 00:19:59,239
I mean, at all of these companies,
there is that level of precision.

347
00:19:59.990 --> 00:20:02,409
-Dude, how--
-I don't know how I didn't get carded.

348
00:20:02.492 --> 00:20:05,704
-That ref just, like, sucked or something.
-You got literally all the way...

349
00:20:05.787 --> 00:20:07,956
-That's Rebecca. Go talk to her.
-I know who it is.

350
00:20:08.040 --> 00:20:10,834
-Dude, yo, go talk to her.
I'm workin' on it.

351
00:20:10.918 --> 00:20:14,171
His calendar says he's on a break
right now. We should be live.

352
00:20:14.755 --> 00:20:16,465
Want me to nudge him?

353
00:20:17.132 --> 00:20:18,050
Yeah, nudge away.

354
00:20:21.637 --> 00:20:24,181
"Your friend Tyler just joined.
Say hi with a wave."

355
00:20:26.016 --> 00:20:27,184
Come on, Ben.

356
00:20:27.267 --> 00:20:29,311
Send a wave. 

357
00:20:29.394 --> 00:20:32,606
-You're not... Go talk to her, dude.

358
00:20:38.070 --> 00:20:40,447
New link! All right, we're on. 

359
00:20:40.948 --> 00:20:46,078
Follow that up with a post
from User 079044238820, Rebecca.

360
00:20:46.161 --> 00:20:49,790
Good idea. GPS coordinates indicate
that they're in close proximity.

361
00:20:55.921 --> 00:20:57,172
He's primed for an ad.

362
00:20:57.631 --> 00:20:58,632
Auction time.

363
00:21:00.133 --> 00:21:02,803
Sold! To Deep Fade hair wax.

364
00:21:03.387 --> 00:21:07,933
We had 468 interested bidders. We sold Ben
at 3.262 cents for an impression.

365
00:21:17.109 --> 00:21:18,735
We've created a world

366
00:21:18.819 --> 00:21:21,530
in which online connection
has become primary,

367
00:21:22.072 --> 00:21:23,907
especially for younger generations.

368
00:21:23.991 --> 00:21:28,328
And yet, in that world,
any time two people connect,

369
00:21:29.162 --> 00:21:33,250
the only way it's financed
is through a sneaky third person

370
00:21:33.333 --> 00:21:35,627
who's paying to manipulate
those two people.

371
00:21:36.128 --> 00:21:39,381
So, we've created
an entire global generation of people

372
00:21:39.464 --> 00:21:44,011
who are raised within a context
where the very meaning of communication,

373
00:21:44.094 --> 00:21:47,431
the very meaning of culture,
is manipulation.

374
00:21:47.514 --> 00:21:49,641
We've put deceit and sneakiness

375
00:21:49.725 --> 00:21:52,311
at the absolute center
of everything we do.

376
00:22:05.615 --> 00:22:07,242
Grab the...
Okay.

377
00:22:07.326 --> 00:22:09,286
-Where's it help to hold it?
Great.

378
00:22:09.369 --> 00:22:10,787
Here?
Yeah.

379
00:22:10.871 --> 00:22:13,832
How does this come across on camera
if I were to do, like, this move--

380
00:22:13.915 --> 00:22:15,542
We can--
Like that?

381
00:22:15.625 --> 00:22:16,918
What?
-Yeah.

382
00:22:17.002 --> 00:22:19,004
Do that again.
-Exactly. Yeah. 

383
00:22:19.087 --> 00:22:20,589
Yeah. No, it's probably not...

384
00:22:20.672 --> 00:22:21,965
Like... yeah.

385
00:22:22.466 --> 00:22:23,884
I mean, this one is less...

386
00:22:29.681 --> 00:22:33,268
Larissa's, like,
actually freaking out over here.

387
00:22:34.728 --> 00:22:35,562
Is that good?

388
00:22:37.856 --> 00:22:41,068
I was, like, five years old
when I learned how to do magic.

389
00:22:41.151 --> 00:22:45,781
And I could fool adults,
fully-grown adults with, like, PhDs.

390
00:22:55.040 --> 00:22:57,709
Magicians were almost like
the first neuroscientists

391
00:22:57.793 --> 00:22:58,960
and psychologists.

392
00:22:59.044 --> 00:23:02,005
Like, they were the ones
who first understood

393
00:23:02.089 --> 00:23:03,382
how people's minds work.

394
00:23:04.216 --> 00:23:07,677
They just, in real time, are testing
lots and lots of stuff on people.

395
00:23:09.137 --> 00:23:11,139
A magician understands something,

396
00:23:11.223 --> 00:23:14,017
some part of your mind
that we're not aware of.

397
00:23:14.101 --> 00:23:15,936
That's what makes the illusion work.

398
00:23:16.019 --> 00:23:20,607
Doctors, lawyers, people who know
how to build 747s or nuclear missiles,

399
00:23:20.690 --> 00:23:24,361
they don't know more about
how their own mind is vulnerable.

400
00:23:24.444 --> 00:23:26,113
That's a separate discipline.

401
00:23:26.571 --> 00:23:28,990
And it's a discipline
that applies to all human beings.

402
00:23:30.909 --> 00:23:34,079
From that perspective, you can have
a very different understanding

403
00:23:34.162 --> 00:23:35,580
of what technology is doing.

404
00:23:36.873 --> 00:23:39,584
When I was
at the Stanford Persuasive Technology Lab,

405
00:23:39.668 --> 00:23:41,044
this is what we learned.

406
00:23:41.628 --> 00:23:43,463
How could you use everything we know

407
00:23:43.547 --> 00:23:45,882
about the psychology
of what persuades people

408
00:23:45.966 --> 00:23:48,385
and build that into technology?

409
00:23:48.468 --> 00:23:50,887
Now, many of you in the audience
are geniuses already.

410
00:23:50.971 --> 00:23:55,851
I think that's true, but my goal is
to turn you into a behavior-change genius.

411
00:23:56.852 --> 00:24:01,148
There are many prominent Silicon Valley
figures who went through that class--

412
00:24:01.231 --> 00:24:05,485
key growth figures at Facebook and Uber
and... and other companies--

413
00:24:05.569 --> 00:24:09,197
and learned how to make technology
more persuasive,

414
00:24:09.614 --> 00:24:10,782
Tristan being one.

415
00:24:12.284 --> 00:24:14,619
Persuasive technology
is just sort of design

416
00:24:14.703 --> 00:24:16,580
intentionally applied to the extreme,

417
00:24:16.663 --> 00:24:18,874
where we really want to modify
someone's behavior.

418
00:24:18.957 --> 00:24:20,542
We want them to take this action.

419
00:24:20.625 --> 00:24:23,336
We want them to keep doing this
with their finger.

420
00:24:23.420 --> 00:24:26,256
You pull down and you refresh,
it's gonna be a new thing at the top.

421
00:24:26.339 --> 00:24:28,508
Pull down and refresh again, it's new.
Every single time.

422
00:24:28.592 --> 00:24:33,722
Which, in psychology, we call
a positive intermittent reinforcement.

423
00:24:33.805 --> 00:24:37,142
You don't know when you're gonna get it
or if you're gonna get something,

424
00:24:37.225 --> 00:24:40,061
which operates just like the slot machines
in Vegas.

425
00:24:40.145 --> 00:24:42,230
It's not enough
that you use the product consciously,

426
00:24:42.314 --> 00:24:44,024
I wanna dig down deeper
into the brain stem

427
00:24:44.107 --> 00:24:45,817
and implant, inside of you,

428
00:24:45.901 --> 00:24:47,652
an unconscious habit

429
00:24:47.736 --> 00:24:50,864
so that you are being programmed
at a deeper level.

430
00:24:50.947 --> 00:24:52,115
You don't even realize it.

431
00:24:52.532 --> 00:24:54,034
A man, James Marshall...

432
00:24:54.117 --> 00:24:56,286
Every time you see it there
on the counter,

433
00:24:56.369 --> 00:24:59,789
and you just look at it,
and you know if you reach over,

434
00:24:59.873 --> 00:25:01,333
it just might have something for you,

435
00:25:01.416 --> 00:25:03,877
so you play that slot machine
to see what you got, right?

436
00:25:03.960 --> 00:25:06,046
That's not by accident.
That's a design technique.

437
00:25:06.129 --> 00:25:08,632
He brings a golden nugget
to an officer

438
00:25:09.841 --> 00:25:11,301
in the army in San Francisco.

439
00:25:12.219 --> 00:25:15,388
Mind you, the... the population
of San Francisco was only...

440
00:25:17.516 --> 00:25:19,643
The secret didn't last.

441
00:25:19.726 --> 00:25:21,186
So, if you get an e-mail

442
00:25:21.269 --> 00:25:24,064
that says your friend just tagged you
in a photo,

443
00:25:24.147 --> 00:25:28,568
of course you're going to click
on that e-mail and look at the photo.

444
00:25:29.152 --> 00:25:31,821
It's not something
you can just decide to ignore.

445
00:25:32.364 --> 00:25:34,157
This is deep-seated, like,

446
00:25:34.241 --> 00:25:36,326
human personality
that they're tapping into.

447
00:25:36.409 --> 00:25:38,078
What you should be asking yourself is:

448
00:25:38.161 --> 00:25:40,288
"Why doesn't that e-mail contain
the photo in it?

449
00:25:40.372 --> 00:25:42,457
It would be a lot easier
to see the photo."

450
00:25:42.541 --> 00:25:45,919
When Facebook found that feature,
they just dialed the hell out of that

451
00:25:46.002 --> 00:25:48,505
because they said, "This is gonna be
a great way to grow activity.

452
00:25:48.588 --> 00:25:51,091
Let's just get people tagging each other
in photos all day long."

453
00:25:59.349 --> 00:26:00,475
He commented.

454
00:26:00.559 --> 00:26:01,434
Nice.

455
00:26:01.935 --> 00:26:04,688
Okay, Rebecca received it,
and she is responding.

456
00:26:04.771 --> 00:26:07,566
All right, let Ben know that she's typing
so we don't lose him.

457
00:26:07.649 --> 00:26:08,733
Activating ellipsis.

458
00:26:19.953 --> 00:26:21,329
Great, she posted.

459
00:26:21.454 --> 00:26:24,249
He's commenting on her comment
about his comment on her post.

460
00:26:25.041 --> 00:26:26,418
Hold on, he stopped typing.

461
00:26:26.751 --> 00:26:27,752
Let's autofill.

462
00:26:28.420 --> 00:26:30,005
Emojis. He loves emojis.

463
00:26:33.842 --> 00:26:34,676
He went with fire.

464
00:26:38.597 --> 00:26:42,726
There's an entire discipline
and field called "growth hacking."

465
00:26:42.809 --> 00:26:47,147
Teams of engineers
whose job is to hack people's psychology

466
00:26:47.230 --> 00:26:48,565
so they can get more growth.

467
00:26:48.648 --> 00:26:50,984
They can get more user sign-ups,
more engagement.

468
00:26:51.067 --> 00:26:52,861
They can get you to invite more people.

469
00:26:52.944 --> 00:26:55,989
After all the testing, all the iterating,
all of this stuff,

470
00:26:56.072 --> 00:26:57,907
you know the single biggest thing
we realized?

471
00:26:57.991 --> 00:27:00,702
Get any individual to seven friends
in ten days.

472
00:27:01.953 --> 00:27:02,787
That was it.

473
00:27:02.871 --> 00:27:05,498
Chamath was the head of growth at Facebook
early on,

474
00:27:05.582 --> 00:27:08,251
and he's very well known
in the tech industry

475
00:27:08.335 --> 00:27:11,004
for pioneering a lot of the growth tactics

476
00:27:11.087 --> 00:27:14,758
that were used to grow Facebook
at incredible speed.

477
00:27:14.841 --> 00:27:18,553
And those growth tactics have then become
the standard playbook for Silicon Valley.

478
00:27:18.637 --> 00:27:21,222
They were used at Uber
and at a bunch of other companies.

479
00:27:21.306 --> 00:27:27,062
One of the things that he pioneered
was the use of scientific A/B testing

480
00:27:27.145 --> 00:27:28,480
of small feature changes.

481
00:27:29.022 --> 00:27:30,940
Companies like Google and Facebook

482
00:27:31.024 --> 00:27:34,569
would roll out
lots of little, tiny experiments

483
00:27:34.653 --> 00:27:36,821
that they were constantly doing on users.

484
00:27:36.905 --> 00:27:39,866
And over time,
by running these constant experiments,

485
00:27:39.949 --> 00:27:43,036
you... you develop the most optimal way

486
00:27:43.119 --> 00:27:45,288
to get users to do
what you want them to do.

487
00:27:45.372 --> 00:27:46,790
It's... It's manipulation.

488
00:27:49.834 --> 00:27:51,920
a lab rat. We're all lab rats.

489
00:27:52.545 --> 00:27:55,548
And it's not like we're lab rats
for developing a cure for cancer.

490
00:27:55.632 --> 00:27:58,134
It's not like they're trying
us.

491
00:27:58.218 --> 00:28:01,680
Right? We're just zombies,
and they want us to look at more ads

492
00:28:01.763 --> 00:28:03,181
so they can make more money.

493
00:28:03.556 --> 00:28:05,266
Facebook conducted

494
00:28:05.350 --> 00:28:08,228
what they called
"massive-scale contagion experiments."

495
00:28:08.311 --> 00:28:09,145
Okay.

496
00:28:09.229 --> 00:28:13,066
How do we use subliminal cues
on the Facebook pages

497
00:28:13.400 --> 00:28:17,654
to get more people to go vote
in the midterm elections?

498
00:28:17.987 --> 00:28:20,824
And they discovered
that they were able to do that.

499
00:28:20.907 --> 00:28:24,160
One thing they concluded
is that we now know

500
00:28:24.744 --> 00:28:28,915
we can affect real-world behavior
and emotions

501
00:28:28.998 --> 00:28:32,877
without ever triggering
the user's awareness.

502
00:28:33.378 --> 00:28:37,382
They are completely clueless.

503
00:28:38.049 --> 00:28:41,970
We're pointing these engines of AI
back at ourselves

504
00:28:42.053 --> 00:28:46,224
to reverse-engineer what elicits responses
from us.

505
00:28:47.100 --> 00:28:49,561
Almost like you're stimulating nerve cells
on a spider

506
00:28:49.644 --> 00:28:51,479
to see what causes its legs to respond.

507
00:28:51.938 --> 00:28:53,940
So, it really is
this kind of prison experiment

508
00:28:54.023 --> 00:28:56,735
where we're just, you know,
roping people into the matrix,

509
00:28:56.818 --> 00:29:00,572
and we're just harvesting all this money
and... and data from all their activity

510
00:29:00.655 --> 00:29:01,489
to profit from.

511
00:29:01.573 --> 00:29:03,450
And we're not even aware
that it's happening.

512
00:29:04.117 --> 00:29:07,912
So, we want to psychologically figure out
how to manipulate you as fast as possible

513
00:29:07.996 --> 00:29:10,081
and then give you back that dopamine hit.

514
00:29:10.165 --> 00:29:12,375
We did that brilliantly at Facebook.

515
00:29:12.625 --> 00:29:14,919
Instagram has done it.
WhatsApp has done it.

516
00:29:15.003 --> 00:29:17,380
You know, Snapchat has done it.
Twitter has done it.

517
00:29:17.464 --> 00:29:19,424
I mean, it's exactly the kind of thing

518
00:29:19.507 --> 00:29:22,427
that a... that a hacker like myself
would come up with

519
00:29:22.510 --> 00:29:27,015
because you're exploiting a vulnerability
in... in human psychology.

520
00:29:27.807 --> 00:29:29,726
And I just...
I think that we...

521
00:29:29.809 --> 00:29:33,438
you know, the inventors, creators...

522
00:29:33.980 --> 00:29:37,317
uh, you know, and it's me, it's Mark,
it's the...

523
00:29:37.400 --> 00:29:40,403
you know, Kevin Systrom at Instagram...
It's all of these people...

524
00:29:40.487 --> 00:29:46,451
um, understood this consciously,
and we did it anyway.

525
00:29:50.580 --> 00:29:53,750
No one got upset when bicycles showed up.

526
00:29:55.043 --> 00:29:58,004
Right? Like, if everyone's starting
to go around on bicycles,

527
00:29:58.087 --> 00:30:00,924
no one said,
"Oh, my God, we've just ruined society.

528
00:30:03.134 --> 00:30:05,303
They're pulling people
away from their kids.

529
00:30:05.386 --> 00:30:08,723
They're ruining the fabric of democracy.
People can't tell what's true."

530
00:30:08.807 --> 00:30:11,476
Like, we never said any of that stuff
about a bicycle.

531
00:30:12.769 --> 00:30:16,147
If something is a tool,
it genuinely is just sitting there,

532
00:30:16.731 --> 00:30:18,733
waiting patiently.

533
00:30:19.317 --> 00:30:22,821
If something is not a tool,
it's demanding things from you.

534
00:30:22.904 --> 00:30:26,533
It's seducing you. It's manipulating you.
It wants things from you.

535
00:30:26.950 --> 00:30:30,495
And we've moved away from having
a tools-based technology environment

536
00:30:31.037 --> 00:30:34,499
to an addiction- and manipulation-based
technology environment.

537
00:30:34.582 --> 00:30:35,708
That's what's changed.

538
00:30:35.792 --> 00:30:39,420
Social media isn't a tool
that's just waiting to be used.

539
00:30:39.504 --> 00:30:43,466
It has its own goals,
and it has its own means of pursuing them

540
00:30:43.550 --> 00:30:45,677
by using your psychology against you.

541
00:30:57.564 --> 00:31:00,567
Rewind a few years ago,
I was the...

542
00:31:00.650 --> 00:31:02,318
I was the president of Pinterest.

543
00:31:03.152 --> 00:31:05,113
I was coming home,

544
00:31:05.196 --> 00:31:08,366
and I couldn't get off my phone
once I got home,

545
00:31:08.449 --> 00:31:12,161
despite having two young kids
who needed my love and attention.

546
00:31:12.245 --> 00:31:15,748
I was in the pantry, you know,
typing away on an e-mail

547
00:31:15.832 --> 00:31:17,542
or sometimes looking at Pinterest.

548
00:31:18.001 --> 00:31:19,627
I thought, "God, this is classic irony.

549
00:31:19.711 --> 00:31:22,046
I am going to work during the day

550
00:31:22.130 --> 00:31:26,426
and building something
that then I am falling prey to."

551
00:31:26.509 --> 00:31:30,096
And I couldn't... I mean, some
of those moments, I couldn't help myself.

552
00:31:32.307 --> 00:31:36,102
The one
that I'm... I'm most prone to is Twitter.

553
00:31:36.185 --> 00:31:38,021
Uh, used to be Reddit.

554
00:31:38.104 --> 00:31:42,859
I actually had to write myself software
to break my addiction to reading Reddit.

555
00:31:45.403 --> 00:31:47,780
I'm probably most addicted to my e-mail.

556
00:31:47.864 --> 00:31:49,866
I mean, really. I mean, I... I feel it.

557
00:31:52.577 --> 00:31:54,954
Well, I mean, it's sort-- it's interesting

558
00:31:55.038 --> 00:31:58,166
that knowing what was going on
behind the curtain,

559
00:31:58.249 --> 00:32:01,628
I still wasn't able to control my usage.

560
00:32:01.711 --> 00:32:03,046
So, that's a little scary.

561
00:32:03.630 --> 00:32:07,050
Even knowing how these tricks work,
I'm still susceptible to them.

562
00:32:07.133 --> 00:32:09,886
I'll still pick up the phone,
and 20 minutes will disappear.

563
00:32:12.805 --> 00:32:15,725
Do you check your smartphone
before you pee in the morning

564
00:32:15.808 --> 00:32:17,477
or while you're peeing in the morning?

565
00:32:17.560 --> 00:32:19,479
'Cause those are the only two choices.

566
00:32:19.562 --> 00:32:23,274
I tried through willpower,
just pure willpower...

567
00:32:23.358 --> 00:32:26,903
"I'll put down my phone, I'll leave
my phone in the car when I get home."

568
00:32:26.986 --> 00:32:30,573
I think I told myself a thousand times,
a thousand different days,

569
00:32:30.657 --> 00:32:32,617
"I am not gonna bring my phone
to the bedroom,"

570
00:32:32.700 --> 00:32:34,535
and then 9:00 p.m. rolls around.

571
00:32:34.619 --> 00:32:37,121
"Well, I wanna bring my phone
in the bedroom."

572
00:32:39.374 --> 00:32:41,125
Willpower was kind of attempt one,

573
00:32:41.209 --> 00:32:44,295
and then attempt two was,
you know, brute force.

574
00:32:44.379 --> 00:32:48,091
Introducing the Kitchen Safe.
The Kitchen Safe is a revolutionary,

575
00:32:48.174 --> 00:32:51,678
new, time-locking container
that helps you fight temptation.

576
00:32:51.761 --> 00:32:56,724
All David has to do is place
those temptations in the Kitchen Safe.

577
00:32:57.392 --> 00:33:00,395
Next, he rotates the dial
to set the timer.

578
00:33:01.479 --> 00:33:04,232
And, finally, he presses the dial
to activate the lock.

579
00:33:04.315 --> 00:33:05,525
The Kitchen Safe is great...

580
00:33:05.608 --> 00:33:06,776
We have that, don't we?

581
00:33:06.859 --> 00:33:08,653
...video games, credit cards,
and cell phones.

582
00:33:08.736 --> 00:33:09,654
Yeah, we do.

583
00:33:09.737 --> 00:33:12,407
Once the Kitchen Safe
is locked, it cannot be opened

584
00:33:12.490 --> 00:33:13,866
until the timer reaches zero.

585
00:33:13.950 --> 00:33:15,618
So, here's the thing.

586
00:33:15.702 --> 00:33:17,537
Social media is a drug.

587
00:33:17.620 --> 00:33:20,873
I mean,
we have a basic biological imperative

588
00:33:20.957 --> 00:33:23,084
to connect with other people.

589
00:33:23.167 --> 00:33:28,214
That directly affects the release
of dopamine in the reward pathway.

590
00:33:28.297 --> 00:33:32,552
Millions of years of evolution, um,
are behind that system

591
00:33:32.635 --> 00:33:35,596
to get us to come together
and live in communities,

592
00:33:35.680 --> 00:33:38,016
to find mates, to propagate our species.

593
00:33:38.099 --> 00:33:41,853
So, there's no doubt
that a vehicle like social media,

594
00:33:41.936 --> 00:33:45,690
which optimizes this connection
between people,

595
00:33:45.773 --> 00:33:48,568
is going to have the potential
for addiction.

596
00:33:52.071 --> 00:33:54,115
-Mmm! 
-Dad, stop!

597
00:33:55.450 --> 00:33:58,453
I have, like, 1,000 more snips
to send before dinner.

598
00:33:58.536 --> 00:34:00,788
Snips?
-I don't know what a snip is.

599
00:34:00.872 --> 00:34:03,207
-Mm, that smells good, baby.
-All right. Thank you.

600
00:34:03.291 --> 00:34:05,877
I was, um, thinking we could use
all five senses

601
00:34:05.960 --> 00:34:07,712
to enjoy our dinner tonight.

602
00:34:07.795 --> 00:34:11,382
So, I decided that we're not gonna have
any cell phones at the table tonight.

603
00:34:11.466 --> 00:34:13,301
So, turn 'em in.

604
00:34:13.801 --> 00:34:14,802
-Really?
Yep.

605
00:34:15.928 --> 00:34:18,056
-All right.
-Thank you. Ben?

606
00:34:18.139 --> 00:34:20,433
-Okay.
-Mom, the phone pirate. 

607
00:34:21.100 --> 00:34:21,934
-Got it.
-Mom!

608
00:34:22.518 --> 00:34:26,147
So, they will be safe in here
until after dinner...

609
00:34:27.273 --> 00:34:30,651
-and everyone can just chill out.

610
00:34:30.735 --> 00:34:31,569
Okay?

611
00:34:47.418 --> 00:34:49,253
-Can I just see who it is?
-No.

612
00:34:54.759 --> 00:34:56,969
Just gonna go get another fork.

613
00:34:58.304 --> 00:34:59,263
Thank you.

614
00:35:04.727 --> 00:35:06,771
Honey, you can't open that.

615
00:35:06.854 --> 00:35:09,315
I locked it for an hour,
so just leave it alone.

616
00:35:11.192 --> 00:35:13,361
So, what should we talk about?

617
00:35:13.444 --> 00:35:14,695
Well, we could talk

618
00:35:14.779 --> 00:35:17,615
about the, uh, Extreme Center wackos
I drove by today.

619
00:35:17.698 --> 00:35:18,825
Please, Frank.
-What?

620
00:35:18.908 --> 00:35:20,785
I don't wanna talk about politics.

621
00:35:20.868 --> 00:35:23,538
-What's wrong with the Extreme Center?
-See? He doesn't even get it.

622
00:35:23.621 --> 00:35:24,622
It depends on who you ask.

623
00:35:24.705 --> 00:35:26,624
It's like asking,
"What's wrong with propaganda?"

624
00:35:28.709 --> 00:35:29,710
Isla!

625
00:35:32.797 --> 00:35:33,756
Oh, my God.

626
00:35:36.425 --> 00:35:38,553
Do you want me to...
Yeah.

627
00:35:41.973 --> 00:35:43,933
I... I'm worried about my kids.

628
00:35:44.016 --> 00:35:46,686
And if you have kids,
I'm worried about your kids.

629
00:35:46.769 --> 00:35:50,189
Armed with all the knowledge that I have
and all of the experience,

630
00:35:50.273 --> 00:35:52,108
I am fighting my kids about the time

631
00:35:52.191 --> 00:35:54,443
that they spend on phones
and on the computer.

632
00:35:54.527 --> 00:35:58,197
I will say to my son, "How many hours do
you think you're spending on your phone?"

633
00:35:58.281 --> 00:36:01,075
He'll be like, "It's, like, half an hour.
It's half an hour, tops."

634
00:36:01.159 --> 00:36:04,829
I'd say upwards hour, hour and a half.

635
00:36:04.912 --> 00:36:06,789
I looked at his screen report
a couple weeks ago.

636
00:36:06.873 --> 00:36:08,708
-Three hours and 45 minutes.
That...

637
00:36:11.377 --> 00:36:13,588
I don't think that's...
No. Per day, on average?

638
00:36:13.671 --> 00:36:15,506
-Yeah.
-Should I go get it right now?

639
00:36:15.590 --> 00:36:19,177
There's not a day that goes by
that I don't remind my kids

640
00:36:19.260 --> 00:36:21,762
about the pleasure-pain balance,

641
00:36:21.846 --> 00:36:24,390
about dopamine deficit states,

642
00:36:24.473 --> 00:36:26,267
about the risk of addiction.

643
00:36:26.350 --> 00:36:27,310
Moment of truth.

644
00:36:27.935 --> 00:36:29,687
Two hours, 50 minutes per day.

645
00:36:29.770 --> 00:36:31,772
-Let's see.
-Actually, I've been using a lot today.

646
00:36:31.856 --> 00:36:33,357
-Last seven days.
-That's probably why.

647
00:36:33.441 --> 00:36:37,361
Instagram, six hours, 13 minutes.
Okay, so my Instagram's worse.

648
00:36:39.572 --> 00:36:41,991
My screen's completely shattered.

649
00:36:42.200 --> 00:36:43,201
Thanks, Cass.

650
00:36:44.410 --> 00:36:45,995
What do you mean, "Thanks, Cass"?

651
00:36:46.078 --> 00:36:49,040
You keep freaking Mom out about our phones
when it's not really a problem.

652
00:36:49.373 --> 00:36:51,167
We don't need our phones to eat dinner!

653
00:36:51.250 --> 00:36:53,878
I get what you're saying.
It's just not that big a deal. It's not.

654
00:36:56.047 --> 00:36:58,382
If it's not that big a deal,
don't use it for a week.

655
00:37:01.135 --> 00:37:06,349
Yeah. Yeah, actually, if you can put
that thing away for, like, a whole week...

656
00:37:07.725 --> 00:37:09,518
I will buy you a new screen.

657
00:37:10.978 --> 00:37:12,897
-Like, starting now?
Starting now.

658
00:37:15.149 --> 00:37:16,859
-Okay. You got a deal.
Okay.

659
00:37:16.943 --> 00:37:19,111
Okay, you gotta leave it here, though,
buddy.

660
00:37:19.862 --> 00:37:21,364
All right, I'm plugging it in.

661
00:37:22.531 --> 00:37:25,076
Let the record show... I'm backing away.

662
00:37:25.159 --> 00:37:25,993
Okay.

663
00:37:27.787 --> 00:37:29,413
-You're on the clock.
One week.

664
00:37:29.497 --> 00:37:30,331
Oh, my...

665
00:37:31.457 --> 00:37:32,416
Think he can do it?

666
00:37:33.000 --> 00:37:34,252
I don't know. We'll see.

667
00:37:35.002 --> 00:37:36,128
Just eat, okay?

668
00:37:44.220 --> 00:37:45,263
Good family dinner!

669
00:37:47.682 --> 00:37:49,809
These technology products
were not designed

670
00:37:49.892 --> 00:37:53,896
by child psychologists who are trying
to protect and nurture children.

671
00:37:53.980 --> 00:37:56,148
They were just designing
to make these algorithms

672
00:37:56.232 --> 00:37:58,734
that were really good at recommending
the next video to you

673
00:37:58.818 --> 00:38:02,321
or really good at getting you
to take a photo with a filter on it.

674
00:38:16.752 --> 00:38:18,879
It's not just
that it's controlling

675
00:38:18.963 --> 00:38:20,548
where they spend their attention.

676
00:38:21.173 --> 00:38:26,304
Especially social media starts to dig
deeper and deeper down into the brain stem

677
00:38:26.387 --> 00:38:29,765
and take over kids' sense of self-worth
and identity.

678
00:38:52.371 --> 00:38:56,208
We evolved to care about
whether other people in our tribe...

679
00:38:56.751 --> 00:38:59,128
think well of us or not
'cause it matters.

680
00:38:59.837 --> 00:39:04,550
But were we evolved to be aware
of what 10,000 people think of us?

681
00:39:04.633 --> 00:39:08,763
We were not evolved
to have social approval being dosed to us

682
00:39:08.846 --> 00:39:10,348
every five minutes.

683
00:39:10.431 --> 00:39:13,142
That was not at all what we were built
to experience.

684
00:39:15.394 --> 00:39:19,982
We curate our lives
around this perceived sense of perfection

685
00:39:20.733 --> 00:39:23,527
because we get rewarded
in these short-term signals--

686
00:39:23.611 --> 00:39:25,154
hearts, likes, thumbs-up--

687
00:39:25.237 --> 00:39:28,407
and we conflate that with value,
and we conflate it with truth.

688
00:39:29.825 --> 00:39:33,120
And instead, what it really is
is fake, brittle popularity...

689
00:39:33.913 --> 00:39:37,458
that's short-term and that leaves you
even more, and admit it,

690
00:39:37.541 --> 00:39:39,919
vacant and empty before you did it.

691
00:39:41.295 --> 00:39:43,381
Because then it forces you
into this vicious cycle

692
00:39:43.464 --> 00:39:47,176
where you're like, "What's the next thing
I need to do now? 'Cause I need it back."

693
00:39:48.260 --> 00:39:50,846
Think about that compounded
by two billion people,

694
00:39:50.930 --> 00:39:54,767
and then think about how people react then
to the perceptions of others.

695
00:39:54.850 --> 00:39:56,435
It's just a... It's really bad.

696
00:39:56.977 --> 00:39:58,229
It's really, really bad.

697
00:40:00.856 --> 00:40:03,484
There has been
a gigantic increase

698
00:40:03.567 --> 00:40:06,529
in depression and anxiety
for American teenagers

699
00:40:06.612 --> 00:40:10,950
which began right around...
between 2011 and 2013.

700
00:40:11.033 --> 00:40:15,371
The number of teenage girls out of 100,000
in this country

701
00:40:15.454 --> 00:40:17,123
who were admitted to a hospital every year

702
00:40:17.206 --> 00:40:19,917
because they cut themselves
or otherwise harmed themselves,

703
00:40:20.000 --> 00:40:23,921
that number was pretty stable
until around 2010, 2011,

704
00:40:24.004 --> 00:40:25,756
and then it begins going way up.

705
00:40:28.759 --> 00:40:32,513
It's up 62 percent for older teen girls.

706
00:40:33.848 --> 00:40:38,310
It's up 189 percent for the preteen girls.
That's nearly triple.

707
00:40:40.312 --> 00:40:43,524
Even more horrifying,
we see the same pattern with suicide.

708
00:40:44.775 --> 00:40:47,570
The older teen girls, 15 to 19 years old,

709
00:40:47.653 --> 00:40:49,196
they're up 70 percent,

710
00:40:49.280 --> 00:40:51,699
compared to the first decade
of this century.

711
00:40:52.158 --> 00:40:55,077
The preteen girls,
who have very low rates to begin with,

712
00:40:55.161 --> 00:40:57,663
they are up 151 percent.

713
00:40:58.831 --> 00:41:01,709
And that pattern points to social media.

714
00:41:04.044 --> 00:41:07,214
Gen Z, the kids born after 1996 or so,

715
00:41:07.298 --> 00:41:10,342
those kids are the first generation
in history

716
00:41:10.426 --> 00:41:12,636
that got on social media in middle school.

717
00:41:15.890 --> 00:41:17,600
How do they spend their time?

718
00:41:19.727 --> 00:41:22,730
They come home from school,
and they're on their devices.

719
00:41:24.315 --> 00:41:29,195
A whole generation is more anxious,
more fragile, more depressed.

720
00:41:30.613 --> 00:41:33,282
They're much less comfortable
taking risks.

721
00:41:34.325 --> 00:41:37,536
The rates at which they get
driver's licenses have been dropping.

722
00:41:38.954 --> 00:41:41,081
The number
who have ever gone out on a date

723
00:41:41.165 --> 00:41:44,251
or had any kind of romantic interaction
is dropping rapidly.

724
00:41:47.505 --> 00:41:49,715
This is a real change in a generation.

725
00:41:53.177 --> 00:41:57,306
And remember, for every one of these,
for every hospital admission,

726
00:41:57.389 --> 00:42:00,267
there's a family that is traumatized
and horrified.

727
00:42:00.351 --> 00:42:02,353
"My God, what is happening to our kids?"

728
00:42:19.411 --> 00:42:21,413
It's plain as day to me.

729
00:42:22.873 --> 00:42:28,128
These services are killing people...
and causing people to kill themselves.

730
00:42:29.088 --> 00:42:33,300
I don't know any parent who says, "Yeah,
I really want my kids to be growing up

731
00:42:33.384 --> 00:42:36,887
feeling manipulated by tech designers, uh,

732
00:42:36.971 --> 00:42:39,723
manipulating their attention,
making it impossible to do their homework,

733
00:42:39.807 --> 00:42:42,560
making them compare themselves
to unrealistic standards of beauty."

734
00:42:42.643 --> 00:42:44,687
Like, no one wants that. 

735
00:42:45.104 --> 00:42:46,355
No one does.

736
00:42:46.438 --> 00:42:48,482
We... We used to have these protections.

737
00:42:48.566 --> 00:42:50,943
When children watched
Saturday morning cartoons,

738
00:42:51.026 --> 00:42:52,778
we cared about protecting children.

739
00:42:52.861 --> 00:42:56,574
We would say, "You can't advertise
to these age children in these ways."

740
00:42:57.366 --> 00:42:58,784
But then you take YouTube for Kids,

741
00:42:58.867 --> 00:43:02,454
and it gobbles up that entire portion
of the attention economy,

742
00:43:02.538 --> 00:43:04,915
and now all kids are exposed
to YouTube for Kids.

743
00:43:04.999 --> 00:43:07,710
And all those protections
and all those regulations are gone.

744
00:43:18.304 --> 00:43:22,141
We're training and conditioning
a whole new generation of people...

745
00:43:23.434 --> 00:43:29,148
that when we are uncomfortable or lonely
or uncertain or afraid,

746
00:43:29.231 --> 00:43:31,775
we have a digital pacifier for ourselves

747
00:43:32.234 --> 00:43:36,488
that is kind of atrophying our own ability
to deal with that.

748
00:43:53.881 --> 00:43:55,674
Photoshop didn't have
1,000 engineers

749
00:43:55.758 --> 00:43:58,969
on the other side of the screen,
using notifications, using your friends,

750
00:43:59.053 --> 00:44:02,431
using AI to predict what's gonna
perfectly addict you, or hook you,

751
00:44:02.514 --> 00:44:04,516
or manipulate you, or allow advertisers

752
00:44:04.600 --> 00:44:08,437
to test 60,000 variations
of text or colors to figure out

753
00:44:08.520 --> 00:44:11,065
what's the perfect manipulation
of your mind.

754
00:44:11.148 --> 00:44:14,985
This is a totally new species
of power and influence.

755
00:44:16.070 --> 00:44:19,156
I... I would say, again, the methods used

756
00:44:19.239 --> 00:44:22,785
to play on people's ability
to be addicted or to be influenced

757
00:44:22.868 --> 00:44:25,204
may be different this time,
and they probably are different.

758
00:44:25.287 --> 00:44:28,749
They were different when newspapers
came in and the printing press came in,

759
00:44:28.832 --> 00:44:31,835
and they were different
when television came in,

760
00:44:31.919 --> 00:44:34,004
and you had three major networks and...

761
00:44:34.463 --> 00:44:36,423
-At the time.
-At the time. That's what I'm saying.

762
00:44:36.507 --> 00:44:38,384
But I'm saying the idea
that there's a new level

763
00:44:38.467 --> 00:44:42,054
and that new level has happened
so many times before.

764
00:44:42.137 --> 00:44:45,099
I mean, this is just the latest new level
that we've seen.

765
00:44:45.182 --> 00:44:48,727
There's this narrative that, you know,
"We'll just adapt to it.

766
00:44:48.811 --> 00:44:51,188
We'll learn how to live
with these devices,

767
00:44:51.271 --> 00:44:53,732
just like we've learned how to live
with everything else."

768
00:44:53.816 --> 00:44:56,694
And what this misses
is there's something distinctly new here.

769
00:44:57.486 --> 00:45:00,155
Perhaps the most dangerous piece
of all this is the fact

770
00:45:00.239 --> 00:45:04,410
that it's driven by technology
that's advancing exponentially.

771
00:45:05.869 --> 00:45:09,081
Roughly, if you say from, like,
the 1960s to today,

772
00:45:09.873 --> 00:45:12,960
processing power has gone up
about a trillion times.

773
00:45:13.794 --> 00:45:18,340
Nothing else that we have has improved
at anything near that rate.

774
00:45:18.424 --> 00:45:22,177
Like, cars are, you know,
roughly twice as fast.

775
00:45:22.261 --> 00:45:25,013
And almost everything else is negligible.

776
00:45:25.347 --> 00:45:27,182
And perhaps most importantly,

777
00:45:27.266 --> 00:45:31,353
our human-- our physiology,
our brains have evolved not at all.

778
00:45:37.401 --> 00:45:41,488
Human beings, at a mind and body
and sort of physical level,

779
00:45:41.947 --> 00:45:43,866
are not gonna fundamentally change.

780
00:45:47.035 --> 00:45:48,954
I know, but they...

781
00:45:56.837 --> 00:46:00,924
We can do genetic engineering
and develop new kinds of human beings,

782
00:46:01.008 --> 00:46:05,220
but realistically speaking,
you're living inside of hardware, a brain,

783
00:46:05.304 --> 00:46:07,222
that was, like, millions of years old,

784
00:46:07.306 --> 00:46:10,559
and then there's this screen, and then
on the opposite side of the screen,

785
00:46:10.642 --> 00:46:13,562
there's these thousands of engineers
and supercomputers

786
00:46:13.645 --> 00:46:16,106
that have goals that are different
than your goals,

787
00:46:16.190 --> 00:46:19,693
and so, who's gonna win in that game?
Who's gonna win?

788
00:46:25.699 --> 00:46:26,617
How are we losing?

789
00:46:27.159 --> 00:46:29,828
-I don't know.
-Where is he? This is not normal.

790
00:46:29.912 --> 00:46:32,080
Did I overwhelm him
with friends and family content?

791
00:46:32.164 --> 00:46:34,082
-Probably.
-Well, maybe it was all the ads.

792
00:46:34.166 --> 00:46:37,795
No. Something's very wrong.
Let's switch to resurrection mode.

793
00:46:39.713 --> 00:46:44,051
When you think of AI,
you know, an AI's gonna ruin the world,

794
00:46:44.134 --> 00:46:47,221
and you see, like, a Terminator,
and you see Arnold Schwarzenegger.

795
00:46:47.638 --> 00:46:48,680
I'll be back.

796
00:46:48.764 --> 00:46:50,933
You see drones,
and you think, like,

797
00:46:51.016 --> 00:46:52,684
"Oh, we're gonna kill people with AI."

798
00:46:53.644 --> 00:46:59,817
And what people miss is that AI
already runs today's world right now.

799
00:46:59.900 --> 00:47:03,237
Even talking about "an AI"
is just a metaphor.

800
00:47:03.320 --> 00:47:09,451
At these companies like... like Google,
there's just massive, massive rooms,

801
00:47:10.327 --> 00:47:13,121
some of them underground,
some of them underwater,

802
00:47:13.205 --> 00:47:14,498
of just computers.

803
00:47:14.581 --> 00:47:17,835
Tons and tons of computers,
as far as the eye can see.

804
00:47:18.460 --> 00:47:20,504
They're deeply interconnected
with each other

805
00:47:20.587 --> 00:47:22,923
and running
extremely complicated programs,

806
00:47:23.006 --> 00:47:26,009
sending information back and forth
between each other all the time.

807
00:47:26.802 --> 00:47:28,595
And they'll be running
many different programs,

808
00:47:28.679 --> 00:47:31,014
many different products
on those same machines.

809
00:47:31.348 --> 00:47:33,684
Some of those things could be described
as simple algorithms,

810
00:47:33.767 --> 00:47:35,227
some could be described as algorithms

811
00:47:35.310 --> 00:47:37,521
that are so complicated,
you would call them intelligence.

812
00:47:42.651 --> 00:47:43,777
embedded in code...

813
00:47:45.070 --> 00:47:47,656
and that algorithms are not objective.

814
00:47:48.365 --> 00:47:51,577
Algorithms are optimized
to some definition of success.

815
00:47:52.244 --> 00:47:53,370
So, if you can imagine,

816
00:47:53.453 --> 00:47:57,124
if a... if a commercial enterprise builds
an algorithm

817
00:47:57.207 --> 00:47:59,293
to their definition of success,

818
00:47:59.835 --> 00:48:01,211
it's a commercial interest.

819
00:48:01.587 --> 00:48:02,671
It's usually profit.

820
00:48:03.130 --> 00:48:07,384
You are giving the computer
the goal state, "I want this outcome,"

821
00:48:07.467 --> 00:48:10,262
and then the computer itself is learning
how to do it.

822
00:48:10.345 --> 00:48:12,598
That's where the term "machine learning"
comes from.

823
00:48:12.681 --> 00:48:14,850
And so, every day, it gets slightly better

824
00:48:14.933 --> 00:48:16,977
at picking the right posts
in the right order

825
00:48:17.060 --> 00:48:19,438
so that you spend longer and longer
in that product.

826
00:48:19.521 --> 00:48:22,232
And no one really understands
what they're doing

827
00:48:22.316 --> 00:48:23,901
in order to achieve that goal.

828
00:48:23.984 --> 00:48:28,238
The algorithm has a mind of its own,
so even though a person writes it,

829
00:48:28.906 --> 00:48:30,657
it's written in a way

830
00:48:30.741 --> 00:48:35,037
that you kind of build the machine,
and then the machine changes itself.

831
00:48:35.120 --> 00:48:37,873
There's only a handful of people
at these companies,

832
00:48:37.956 --> 00:48:40,000
at Facebook and Twitter
and other companies...

833
00:48:40.083 --> 00:48:43,795
There's only a few people who understand
how those systems work,

834
00:48:43.879 --> 00:48:46,715
and even they don't necessarily
fully understand

835
00:48:46.798 --> 00:48:49,551
what's gonna happen
with a particular piece of content.

836
00:48:49.968 --> 00:48:55,474
So, as humans, we've almost lost control
over these systems.

837
00:48:55.891 --> 00:48:59,603
Because they're controlling, you know,
the information that we see,

838
00:48:59.686 --> 00:49:02,189
they're controlling us more
than we're controlling them.

839
00:49:04.816 --> 00:49:07,319
against comparables
in his geographic zone.

840
00:49:07.402 --> 00:49:09,571
His psychometric doppelgangers.

841
00:49:09.655 --> 00:49:13,700
There are 13,694 people
behaving just like him in his region.

842
00:49:13.784 --> 00:49:16,370
-What's trending with them?
-We need something actually good

843
00:49:16.453 --> 00:49:17,704
for a proper resurrection,

844
00:49:17.788 --> 00:49:19,957
given that the typical stuff
isn't working.

845
00:49:20.040 --> 00:49:21,875
Not even that cute girl from school.

846
00:49:22.334 --> 00:49:25,253
My analysis shows that going political
with Extreme Center content

847
00:49:25.337 --> 00:49:28,256
has a 62.3 percent chance
of long-term engagement.

848
00:49:28.340 --> 00:49:29,299
That's not bad.

849
00:49:29.383 --> 00:49:32,010
It's not good enough to lead with.

850
00:49:32.302 --> 00:49:35,305
Okay, okay, so we've tried notifying him
about tagged photos,

851
00:49:35.389 --> 00:49:39,017
invitations, current events,
even a direct message from Rebecca.

852
00:49:39.101 --> 00:49:42,813
But what about User 01265923010?

853
00:49:42.896 --> 00:49:44,648
Yeah, Ben loved all of her posts.

854
00:49:44.731 --> 00:49:47,776
For months and, like,
literally all of them, and then nothing.

855
00:49:47.859 --> 00:49:50,445
I calculate a 92.3 percent chance
of resurrection

856
00:49:50.529 --> 00:49:52,030
with a notification about Ana.

857
00:49:56.535 --> 00:49:57,494
And her new friend.

858
00:50:25.689 --> 00:50:27,441
Oh, you gotta be kiddin' me.

859
00:50:32.404 --> 00:50:33,613
Uh... 

860
00:50:35.657 --> 00:50:36,616
Okay.

861
00:50:38.869 --> 00:50:40,996
-What?

862
00:50:41.413 --> 00:50:42,789
Bam! We're back!

863
00:50:42.873 --> 00:50:44,374
Let's get back to making money, boys.

864
00:50:44.458 --> 00:50:46,334
Yes, and connecting Ben
with the entire world.

865
00:50:46.418 --> 00:50:49,087
I'm giving him access
to all the information he might like.

866
00:50:49.755 --> 00:50:53,717
Hey, do you guys ever wonder if, you know,
like, the feed is good for Ben?

867
00:50:57.095 --> 00:50:58,430
-No.
-No. 

868
00:51:17.491 --> 00:51:19,076
♪

869
00:51:25.040 --> 00:51:26,374
♪

870
00:51:28.627 --> 00:51:32,089
♪ Ah! ♪

871
00:51:34.508 --> 00:51:36,593
♪

872
00:51:41.181 --> 00:51:42,265
♪

873
00:51:44.976 --> 00:51:46,686
♪

874
00:51:49.981 --> 00:51:51,817
♪

875
00:51:53.026 --> 00:51:54,611
♪

876
00:51:55.612 --> 00:51:57,239
♪

877
00:51:58.782 --> 00:52:02,077
I can't stand it
♪

878
00:52:03.286 --> 00:52:04,121
♪

879
00:52:06.456 --> 00:52:08,375
♪

880
00:52:12.379 --> 00:52:14,840
♪

881
00:52:18.718 --> 00:52:19,845
♪ You're mine ♪

882
00:52:20.929 --> 00:52:24,349
So, imagine you're on Facebook...

883
00:52:24.766 --> 00:52:29,312
and you're effectively playing
against this artificial intelligence

884
00:52:29.396 --> 00:52:31,314
that knows everything about you,

885
00:52:31.398 --> 00:52:34,568
can anticipate your next move,
and you know literally nothing about it,

886
00:52:34.651 --> 00:52:37,404
except that there are cat videos
and birthdays on it.

887
00:52:37.821 --> 00:52:39,656
That's not a fair fight.

888
00:52:41.575 --> 00:52:43,869
Ben and Jerry, it's time to go, bud!

889
00:52:51.126 --> 00:52:51,960
Ben?

890
00:53:02.679 --> 00:53:04,723
Ben.
Mm.

891
00:53:05.182 --> 00:53:06,057
Come on.

892
00:53:07.225 --> 00:53:08,351
School time. 

893
00:53:08.435 --> 00:53:09,269
Let's go.

894
00:53:31.374 --> 00:53:33,627
How you doing today?
-Oh, I'm... I'm nervous.

895
00:53:33.710 --> 00:53:35,003
-Are ya?
-Yeah. 

896
00:53:39.216 --> 00:53:42,969
when technology would overwhelm
human strengths and intelligence.

897
00:53:43.053 --> 00:53:47,015
When is it gonna cross the singularity,
replace our jobs, be smarter than humans?

898
00:53:48.141 --> 00:53:50,101
But there's this much earlier moment...

899
00:53:50.977 --> 00:53:55,315
when technology exceeds
and overwhelms human weaknesses.

900
00:53:57.484 --> 00:54:01,780
This point being crossed
is at the root of addiction,

901
00:54:02.113 --> 00:54:04,741
polarization, radicalization,
outrage-ification,

902
00:54:04.824 --> 00:54:06,368
vanity-ification, the entire thing.

903
00:54:07.702 --> 00:54:09,913
This is overpowering human nature,

904
00:54:10.538 --> 00:54:13,500
and this is checkmate on humanity.

905
00:54:30.558 --> 00:54:31,851
I'm sorry. 

906
00:54:41.736 --> 00:54:44,656
One of the ways
I try to get people to understand

907
00:54:45.198 --> 00:54:49,828
just how wrong feeds from places
like Facebook are

908
00:54:49.911 --> 00:54:51,454
is to think about the Wikipedia.

909
00:54:52.956 --> 00:54:56,209
When you go to a page, you're seeing
the same thing as other people.

910
00:54:56.584 --> 00:55:00,297
So, it's one of the few things online
that we at least hold in common.

911
00:55:00.380 --> 00:55:03,425
Now, just imagine for a second
that Wikipedia said,

912
00:55:03.508 --> 00:55:07,178
"We're gonna give each person
a different customized definition,

913
00:55:07.262 --> 00:55:09,472
and we're gonna be paid by people
for that."

914
00:55:09.556 --> 00:55:13,435
So, Wikipedia would be spying on you.
Wikipedia would calculate,

915
00:55:13.518 --> 00:55:17,188
"What's the thing I can do
to get this person to change a little bit

916
00:55:17.272 --> 00:55:19,899
on behalf of some commercial interest?"
Right?

917
00:55:19.983 --> 00:55:21,818
And then it would change the entry.

918
00:55:22.444 --> 00:55:24,738
Can you imagine that?
Well, you should be able to,

919
00:55:24.821 --> 00:55:26,823
'cause that's exactly what's happening
on Facebook.

920
00:55:26.906 --> 00:55:28,992
It's exactly what's happening
in your YouTube feed.

921
00:55:29.075 --> 00:55:31,786
When you go to Google and type in
"Climate change is,"

922
00:55:31.870 --> 00:55:34,998
you're going to see different results
depending on where you live.

923
00:55:36.166 --> 00:55:38,460
In certain cities,
you're gonna see it autocomplete

924
00:55:38.543 --> 00:55:40,462
with "climate change is a hoax."

925
00:55:40.545 --> 00:55:42,088
In other cases, you're gonna see

926
00:55:42.172 --> 00:55:44,841
"climate change is causing the destruction
of nature."

927
00:55:44.924 --> 00:55:48,428
And that's a function not
of what the truth is about climate change,

928
00:55:48.511 --> 00:55:51,097
but about
where you happen to be Googling from

929
00:55:51.181 --> 00:55:54,100
and the particular things
Google knows about your interests.

930
00:55:54.851 --> 00:55:58,021
Even two friends
who are so close to each other,

931
00:55:58.104 --> 00:56:00,190
who have almost the exact same set
of friends,

932
00:56:00.273 --> 00:56:02,817
they think, you know,
"I'm going to news feeds on Facebook.

933
00:56:02.901 --> 00:56:05,403
I'll see the exact same set of updates."

934
00:56:05.487 --> 00:56:06,738
But it's not like that at all.

935
00:56:06.821 --> 00:56:08,448
They see completely different worlds

936
00:56:08.531 --> 00:56:10,575
because they're based
on these computers calculating

937
00:56:10.658 --> 00:56:12,035
what's perfect for each of them.

938
00:56:14.329 --> 00:56:18,416
The way to think about it
Truman Shows.

939
00:56:18.500 --> 00:56:21,294
Each person has their own reality,
with their own...

940
00:56:22.670 --> 00:56:23,671
facts.

941
00:56:23.755 --> 00:56:27,008
Why do you think
that, uh, Truman has never come close

942
00:56:27.092 --> 00:56:30,095
to discovering the true nature
of his world until now?

943
00:56:31.054 --> 00:56:34,140
We accept the reality of the world
with which we're presented.

944
00:56:34.224 --> 00:56:35,141
It's as simple as that.

945
00:56:36.476 --> 00:56:41,064
Over time, you have the false sense
that everyone agrees with you,

946
00:56:41.147 --> 00:56:44,067
because everyone in your news feed
sounds just like you.

947
00:56:44.567 --> 00:56:49,072
And that once you're in that state,
it turns out you're easily manipulated,

948
00:56:49.155 --> 00:56:51,741
the same way you would be manipulated
by a magician.

949
00:56:51.825 --> 00:56:55,370
A magician shows you a card trick
and says, "Pick a card, any card."

950
00:56:55.453 --> 00:56:58,164
What you don't realize
was that they've done a set-up,

951
00:56:58.456 --> 00:57:00,583
so you pick the card
they want you to pick.

952
00:57:00.667 --> 00:57:03,169
And that's how Facebook works.
Facebook sits there and says,

953
00:57:03.253 --> 00:57:06,172
"Hey, you pick your friends.
You pick the links that you follow."

954
00:57:06.256 --> 00:57:08,716
But that's all nonsense.
It's just like the magician.

955
00:57:08.800 --> 00:57:11,302
Facebook is in charge of your news feed.

956
00:57:11.386 --> 00:57:14,514
We all simply are operating
on a different set of facts.

957
00:57:14.597 --> 00:57:16,474
When that happens at scale,

958
00:57:16.558 --> 00:57:20,645
you're no longer able to reckon with
or even consume information

959
00:57:20.728 --> 00:57:23,690
that contradicts with that world view
that you've created.

960
00:57:23.773 --> 00:57:26,443
That means we aren't actually being
objective,

961
00:57:26.526 --> 00:57:28,319
constructive individuals. 

962
00:57:28.403 --> 00:57:32,449
Open up your eyes,
don't believe the lies! Open up...

963
00:57:32.532 --> 00:57:34,701
And then you look
over at the other side,

964
00:57:35.243 --> 00:57:38,746
and you start to think,
"How can those people be so stupid?

965
00:57:38.830 --> 00:57:42,125
Look at all of this information
that I'm constantly seeing.

966
00:57:42.208 --> 00:57:44,627
How are they not seeing
that same information?"

967
00:57:44.711 --> 00:57:47,297
And the answer is, "They're not seeing
that same information."

968
00:57:52.093 --> 00:57:55,472
What are Republicans like?
-People that don't have a clue.

969
00:57:55.555 --> 00:57:58,933
The Democrat Party is a crime syndicate,
not a real political party.

970
00:57:59.017 --> 00:58:03,188
A huge new Pew Research Center study
of 10,000 American adults

971
00:58:03.271 --> 00:58:05,315
finds us more divided than ever,

972
00:58:05.398 --> 00:58:09,152
with personal and political polarization
at a 20-year high.

973
00:58:11.738 --> 00:58:14,199
You have
more than a third of Republicans saying

974
00:58:14.282 --> 00:58:16,826
the Democratic Party is a threat
to the nation,

975
00:58:16.910 --> 00:58:20,580
more than a quarter of Democrats saying
the same thing about the Republicans.

976
00:58:20.663 --> 00:58:22,499
So many of the problems
that we're discussing,

977
00:58:22.582 --> 00:58:24,417
like, around political polarization

978
00:58:24.501 --> 00:58:28,046
exist in spades on cable television.

979
00:58:28.129 --> 00:58:31,007
The media has this exact same problem,

980
00:58:31.090 --> 00:58:33,343
where their business model, by and large,

981
00:58:33.426 --> 00:58:35,762
is that they're selling our attention
to advertisers.

982
00:58:35.845 --> 00:58:38,890
And the Internet is just a new,
even more efficient way to do that.

983
00:58:40.141 --> 00:58:44,145
At YouTube, I was working
on YouTube recommendations.

984
00:58:44.229 --> 00:58:47,148
It worries me that an algorithm
that I worked on

985
00:58:47.232 --> 00:58:50,401
is actually increasing polarization
in society.

986
00:58:50.485 --> 00:58:53,112
But from the point of view of watch time,

987
00:58:53.196 --> 00:58:57,617
this polarization is extremely efficient
at keeping people online.

988
00:58:58.785 --> 00:59:00,870
The only reason
these teachers are teaching this stuff

989
00:59:00.954 --> 00:59:02,288
is 'cause they're getting paid to.

990
00:59:02.372 --> 00:59:04,374
-It's absolutely absurd.
Hey, Benji.

991
00:59:04.916 --> 00:59:06,292
No soccer practice today?

992
00:59:06.376 --> 00:59:08,795
Oh, there is. I'm just catching up
on some news stuff.

993
00:59:08.878 --> 00:59:11,506
Do research. Anything
that sways from the Extreme Center--

994
00:59:11.589 --> 00:59:14,008
Wouldn't exactly call the stuff
that you're watching news.

995
00:59:15.552 --> 00:59:18,846
You're always talking about how messed up
everything is. So are they.

996
00:59:19.305 --> 00:59:21,140
But that stuff is just propaganda.

997
00:59:21.224 --> 00:59:24,060
Neither is true.
It's all about what makes sense.

998
00:59:24.769 --> 00:59:26,938
Ben, I'm serious.
That stuff is bad for you.

999
00:59:27.021 --> 00:59:29,232
-You should go to soccer practice.
Mm.

1000
00:59:35.154 --> 00:59:37,490
I share this stuff because I care.

1001
00:59:37.574 --> 00:59:41,077
I care that you are being misled,
and it's not okay. All right?

1002
00:59:41.160 --> 00:59:43,121
People think
the algorithm is designed

1003
00:59:43.204 --> 00:59:46,833
to give them what they really want,
only it's not.

1004
00:59:46.916 --> 00:59:52,589
The algorithm is actually trying to find
a few rabbit holes that are very powerful,

1005
00:59:52.672 --> 00:59:56,217
trying to find which rabbit hole
is the closest to your interest.

1006
00:59:56.301 --> 00:59:59,262
And then if you start watching
one of those videos,

1007
00:59:59.846 --> 01:00:02,223
then it will recommend it
over and over again.

1008
01:00:02.682 --> 01:00:04,934
It's not like anybody wants this
to happen.

1009
01:00:05.018 --> 01:00:07,812
It's just that this is
what the recommendation system is doing.

1010
01:00:07.895 --> 01:00:10,815
So much so that Kyrie Irving,
the famous basketball player,

1011
01:00:11.065 --> 01:00:14,235
uh, said he believed the Earth was flat,
and he apologized later

1012
01:00:14.319 --> 01:00:16,154
because he blamed it
on a YouTube rabbit hole.

1013
01:00:16.487 --> 01:00:18,656
You know, like,
you click the YouTube click

1014
01:00:18.740 --> 01:00:21,534
and it goes, like,
how deep the rabbit hole goes.

1015
01:00:21.618 --> 01:00:23,369
When he later came on to NPR to say,

1016
01:00:23.453 --> 01:00:25,955
"I'm sorry for believing this.
I didn't want to mislead people,"

1017
01:00:26.039 --> 01:00:28,291
a bunch of students in a classroom
were interviewed saying,

1018
01:00:28.374 --> 01:00:29,667
"The round-Earthers got to him."

1019
01:00:31.044 --> 01:00:33,963
The flat-Earth conspiracy theory
was recommended

1020
01:00:34.047 --> 01:00:37,634
hundreds of millions of times
by the algorithm.

1021
01:00:37.717 --> 01:00:43,890
It's easy to think that it's just
a few stupid people who get convinced,

1022
01:00:43.973 --> 01:00:46,893
but the algorithm is getting smarter
and smarter every day.

1023
01:00:46.976 --> 01:00:50,188
So, today, they are convincing the people
that the Earth is flat,

1024
01:00:50.271 --> 01:00:53,983
you
of something that's false.

1025
01:00:54.317 --> 01:00:57,820
On November 7th,
the hashtag "Pizzagate" was born.

1026
01:00:57.904 --> 01:00:59,197
Pizzagate...

1027
01:01:00.114 --> 01:01:01,449
Oh, boy.

1028
01:01:01.532 --> 01:01:02,533
Uh... 

1029
01:01:03.159 --> 01:01:06,913
I still am not 100 percent sure
how this originally came about,

1030
01:01:06.996 --> 01:01:12,377
but the idea that ordering a pizza
meant ordering a trafficked person.

1031
01:01:12.460 --> 01:01:15,046
As the groups got bigger on Facebook,

1032
01:01:15.129 --> 01:01:19,967
Facebook's recommendation engine
started suggesting to regular users

1033
01:01:20.051 --> 01:01:21,761
that they join Pizzagate groups.

1034
01:01:21.844 --> 01:01:27,392
So, if a user was, for example,
anti-vaccine or believed in chemtrails

1035
01:01:27.475 --> 01:01:30,645
or had indicated to Facebook's algorithms
in some way

1036
01:01:30.728 --> 01:01:33,398
that they were prone to belief
in conspiracy theories,

1037
01:01:33.481 --> 01:01:36,859
Facebook's recommendation engine
would serve them Pizzagate groups.

1038
01:01:36.943 --> 01:01:41,072
Eventually, this culminated in
a man showing up with a gun,

1039
01:01:41.155 --> 01:01:44,617
deciding that he was gonna go liberate
the children from the basement 

1040
01:01:44.701 --> 01:01:46,911
of the pizza place
that did not have a basement.

1041
01:01:46.994 --> 01:01:48,538
What were you doing?

1042
01:01:48.871 --> 01:01:50,498
Making sure
there was nothing there.

1043
01:01:50.581 --> 01:01:52,458
Regarding?
Pedophile ring.

1044
01:01:52.542 --> 01:01:54,293
What?
Pedophile ring.

1045
01:01:54.377 --> 01:01:55,962
He's talking about Pizzagate.

1046
01:01:56.045 --> 01:02:00,216
This is an example of a conspiracy theory

1047
01:02:00.299 --> 01:02:03,678
that was propagated
across all social networks.

1048
01:02:03.761 --> 01:02:06,097
The social network's
own recommendation engine

1049
01:02:06.180 --> 01:02:07,974
is voluntarily serving this up to people

1050
01:02:08.057 --> 01:02:10,643
who had never searched
for the term "Pizzagate" in their life.

1051
01:02:12.437 --> 01:02:14,439
There's a study, an MIT study,

1052
01:02:14.522 --> 01:02:19,819
that fake news on Twitter spreads
six times faster than true news.

1053
01:02:19.902 --> 01:02:21,863
What is that world gonna look like

1054
01:02:21.946 --> 01:02:24,741
when one has a six-times advantage
to the other one?

1055
01:02:25.283 --> 01:02:27,660
You can imagine
these things are sort of like...

1056
01:02:27.744 --> 01:02:31,706
they... they tilt the floor
of... of human behavior.

1057
01:02:31.789 --> 01:02:34,709
They make some behavior harder
and some easier.

1058
01:02:34.792 --> 01:02:37,420
And you're always free
to walk up the hill,

1059
01:02:37.503 --> 01:02:38,796
but fewer people do,

1060
01:02:38.880 --> 01:02:43,092
and so, at scale, at society's scale,
you really are just tilting the floor

1061
01:02:43.176 --> 01:02:45,970
and changing what billions of people think
and do.

1062
01:02:46.053 --> 01:02:52,018
We've created a system
that biases towards false information.

1063
01:02:52.643 --> 01:02:54,437
Not because we want to,

1064
01:02:54.520 --> 01:02:58,816
but because false information makes
the companies more money

1065
01:02:59.400 --> 01:03:01,319
than the truth. The truth is boring.

1066
01:03:01.986 --> 01:03:04,489
It's a disinformation-for-profit
business model.

1067
01:03:04.906 --> 01:03:08,159
You make money the more you allow
unregulated messages

1068
01:03:08.701 --> 01:03:11,287
to reach anyone for the best price.

1069
01:03:11.662 --> 01:03:13,956
Because climate change? Yeah.

1070
01:03:14.040 --> 01:03:16,751
It's a hoax. Yeah, it's real.
That's the point.

1071
01:03:16.834 --> 01:03:20,046
The more they talk about it
and the more they divide us,

1072
01:03:20.129 --> 01:03:22,423
the more they have the power,
the more...

1073
01:03:22.507 --> 01:03:25,468
Facebook has trillions
of these news feed posts.

1074
01:03:26.552 --> 01:03:29,180
They can't know what's real
or what's true...

1075
01:03:29.972 --> 01:03:33,726
which is why this conversation
is so critical right now.

1076
01:03:33.810 --> 01:03:37,021
It's not just COVID-19
that's spreading fast.

1077
01:03:37.104 --> 01:03:40,191
There's a flow of misinformation online
about the virus.

1078
01:03:40.274 --> 01:03:41,818
The notion
drinking water

1079
01:03:41.901 --> 01:03:43,694
will flush coronavirus from your system

1080
01:03:43.778 --> 01:03:47,490
is one of several myths about the virus
circulating on social media.

1081
01:03:47.573 --> 01:03:50,451
The government planned
this event, created the virus,

1082
01:03:50.535 --> 01:03:53,621
and had a simulation
of how the countries would react.

1083
01:03:53.955 --> 01:03:55,581
Coronavirus is a... a hoax.

1084
01:03:56.165 --> 01:03:57,959
SARS, coronavirus.

1085
01:03:58.376 --> 01:04:01,045
And look at when it was made. 2018.

1086
01:04:01.128 --> 01:04:03,798
I think the US government started
this shit.

1087
01:04:04.215 --> 01:04:09,095
Nobody is sick. Nobody is sick.
Nobody knows anybody who's sick.

1088
01:04:09.512 --> 01:04:13,015
Maybe the government is using
the coronavirus as an excuse

1089
01:04:13.099 --> 01:04:15,643
to get everyone to stay inside
because something else is happening.

1090
01:04:15.726 --> 01:04:18,020
Coronavirus is not killing people,

1091
01:04:18.104 --> 01:04:20,940
it's the 5G radiation
that they're pumping out.

1092
01:04:25.403 --> 01:04:28,823
People are blowing up
actual physical cell phone towers.

1093
01:04:28.906 --> 01:04:32,201
We see Russia and China spreading rumors
and conspiracy theories.

1094
01:04:32.285 --> 01:04:35,246
This morning,
panic and protest in Ukraine as...

1095
01:04:35.329 --> 01:04:38,916
People have no idea what's true,
and now it's a matter of life and death.

1096
01:04:39.876 --> 01:04:42,628
Those sources that are spreading
coronavirus misinformation

1097
01:04:42.712 --> 01:04:45,798
have amassed
something like 52 million engagements.

1098
01:04:45.882 --> 01:04:50,094
You're saying that silver solution
would be effective.

1099
01:04:50.177 --> 01:04:54,140
Well, let's say it hasn't been tested
on this strain of the coronavirus, but...

1100
01:04:54.223 --> 01:04:57,226
What we're seeing with COVID
is just an extreme version

1101
01:04:57.310 --> 01:05:00,521
of what's happening
across our information ecosystem.

1102
01:05:00.938 --> 01:05:05,026
Social media amplifies exponential gossip
and exponential hearsay

1103
01:05:05.109 --> 01:05:07,111
to the point
that we don't know what's true,

1104
01:05:07.194 --> 01:05:08,946
no matter what issue we care about.

1105
01:05:15.161 --> 01:05:16,579
He discovers this.

1106
01:05:19.874 --> 01:05:21,292
Ben.

1107
01:05:26.130 --> 01:05:28,257
-Are you still on the team?
Mm-hmm.

1108
01:05:30.384 --> 01:05:32,678
Okay, well,
I'm gonna get a snack before practice 

1109
01:05:32.762 --> 01:05:34,430
if you... wanna come.

1110
01:05:35.640 --> 01:05:36,515
Hm?

1111
01:05:36.974 --> 01:05:38,601
You know, never mind.

1112
01:05:45.066 --> 01:05:47,526
Nine out of ten people
are dissatisfied right now.

1113
01:05:47.610 --> 01:05:50,613
The EC is like any political movement
in history, when you think about it.

1114
01:05:50.696 --> 01:05:54,492
We are standing up, and we are...
we are standing up to this noise.

1115
01:05:54.575 --> 01:05:57,036
You are my people. I trust you guys.

1116
01:05:59.246 --> 01:06:02,583
-The Extreme Center content is brilliant.
He absolutely loves it.

1117
01:06:02.667 --> 01:06:03,626
Running an auction.

1118
01:06:04.627 --> 01:06:08,547
840 bidders. He sold for 4.35 cents
to a weapons manufacturer.

1119
01:06:08.631 --> 01:06:10,800
Let's promote some of these events.

1120
01:06:10.883 --> 01:06:13,511
Upcoming rallies in his geographic zone
later this week.

1121
01:06:13.594 --> 01:06:15,179
I've got a new vlogger lined up, too.

1122
01:06:17.765 --> 01:06:22,979
And... and, honestly, I'm telling you,
I'm willing to do whatever it takes.

1123
01:06:23.062 --> 01:06:24,939
And I mean whatever.

1124
01:06:32.154 --> 01:06:33,197
-Subscribe...
Ben?

1125
01:06:33.280 --> 01:06:35,908
...and also come back
because I'm telling you, yo...

1126
01:06:38.953 --> 01:06:40,162
Some real big things.

1127
01:06:40.788 --> 01:06:45,292
One of the problems with Facebook
is that, as a tool of persuasion,

1128
01:06:45.793 --> 01:06:47,920
it may be the greatest thing ever created.

1129
01:06:48.004 --> 01:06:52,508
Now, imagine what that means in the hands
of a dictator or an authoritarian.

1130
01:06:53.718 --> 01:06:57,638
If you want to control the population
of your country,

1131
01:06:57.722 --> 01:07:01,308
there has never been a tool
as effective as Facebook.

1132
01:07:07.481 --> 01:07:10,985
of governments and other bad actors
weaponizing social media,

1133
01:07:11.235 --> 01:07:13,612
um, is that it has led
to real, offline harm.

1134
01:07:13.696 --> 01:07:15,072
I think the most prominent example

1135
01:07:15.156 --> 01:07:17,658
that's gotten a lot of press
is what's happened in Myanmar.

1136
01:07:19.243 --> 01:07:21,203
In Myanmar,
when people think of the Internet,

1137
01:07:21.287 --> 01:07:22,913
what they are thinking about is Facebook.

1138
01:07:22.997 --> 01:07:25,916
And what often happens is
when people buy their cell phone,

1139
01:07:26.000 --> 01:07:29,920
the cell phone shop owner will actually
preload Facebook on there for them

1140
01:07:30.004 --> 01:07:31,505
and open an account for them.

1141
01:07:31.589 --> 01:07:34,884
And so when people get their phone,
the first thing they open

1142
01:07:34.967 --> 01:07:37,595
and the only thing they know how to open
is Facebook.

1143
01:07:38.179 --> 01:07:41,891
Well, a new bombshell investigation
exposes Facebook's growing struggle

1144
01:07:41.974 --> 01:07:43,809
to tackle hate speech in Myanmar.

1145
01:07:46.103 --> 01:07:49,190
Facebook really gave the military
and other bad actors

1146
01:07:49.273 --> 01:07:51,776
a new way to manipulate public opinion

1147
01:07:51.859 --> 01:07:55,529
and to help incite violence
against the Rohingya Muslims

1148
01:07:55.613 --> 01:07:57,406
that included mass killings,

1149
01:07:58.115 --> 01:07:59,867
burning of entire villages,

1150
01:07:59.950 --> 01:08:03,704
mass rape, and other serious crimes
against humanity

1151
01:08:03.788 --> 01:08:04,955
that have now led

1152
01:08:05.039 --> 01:08:08,209
to 700,000 Rohingya Muslims
having to flee the country. 

1153
01:08:11.170 --> 01:08:14,799
It's not
that highly motivated propagandists

1154
01:08:14.882 --> 01:08:16,550
haven't existed before.

1155
01:08:16.634 --> 01:08:19,762
It's that the platforms make it possible

1156
01:08:19.845 --> 01:08:23,724
to spread manipulative narratives
with phenomenal ease,

1157
01:08:23.808 --> 01:08:25,434
and without very much money.

1158
01:08:25.518 --> 01:08:27,812
If I want to manipulate an election,

1159
01:08:27.895 --> 01:08:30,564
I can now go into
a conspiracy theory group on Facebook,

1160
01:08:30.648 --> 01:08:32,233
and I can find 100 people

1161
01:08:32.316 --> 01:08:34,443
who believe
that the Earth is completely flat

1162
01:08:34.860 --> 01:08:37,780
and think it's all this conspiracy theory
that we landed on the moon,

1163
01:08:37.863 --> 01:08:41,450
and I can tell Facebook,
"Give me 1,000 users who look like that."

1164
01:08:42.118 --> 01:08:46,080
Facebook will happily send me
thousands of users that look like them

1165
01:08:46.163 --> 01:08:49,250
that I can now hit
with more conspiracy theories.

1166
01:08:53.379 --> 01:08:56,382
-New EC video to promote.
Another ad teed up.

1167
01:08:58.509 --> 01:09:00,928
Algorithms
and manipulative politicians

1168
01:09:01.011 --> 01:09:02,138
are becoming so expert

1169
01:09:02.221 --> 01:09:04,056
at learning how to trigger us,

1170
01:09:04.140 --> 01:09:08,352
getting so good at creating fake news
that we absorb as if it were reality,

1171
01:09:08.435 --> 01:09:10,813
and confusing us into believing
those lies.

1172
01:09:10.896 --> 01:09:12,606
It's as though we have
less and less control

1173
01:09:12.690 --> 01:09:14,150
over who we are and what we believe.

1174
01:09:31.375 --> 01:09:32,835
...so they can pick sides.

1175
01:09:32.918 --> 01:09:34,879
There's lies here,
and there's lies over there.

1176
01:09:34.962 --> 01:09:36,338
So they can keep the power,

1177
01:09:36.422 --> 01:09:39,967
-so they can control everything.

1178
01:09:40.050 --> 01:09:42,553
They can control our minds,

1179
01:09:42.636 --> 01:09:46,390
-so that they can keep their secrets.

1180
01:09:48.517 --> 01:09:50,895
Imagine a world
where no one believes anything true.

1181
01:09:52.897 --> 01:09:55,649
Everyone believes
the government's lying to them.

1182
01:09:56.317 --> 01:09:58,444
Everything is a conspiracy theory.

1183
01:09:58.527 --> 01:10:01,197
"I shouldn't trust anyone.
I hate the other side."

1184
01:10:01.280 --> 01:10:02,698
That's where all this is heading.

1185
01:10:02.781 --> 01:10:06,160
The political earthquakes in Europe
continue to rumble.

1186
01:10:06.243 --> 01:10:08,412
This time, in Italy and Spain.

1187
01:10:08.495 --> 01:10:11,999
Overall, Europe's traditional,
centrist coalition lost its majority

1188
01:10:12.082 --> 01:10:15,002
while far right
and far left populist parties made gains.

1189
01:10:19.757 --> 01:10:20,591
Back up.

1190
01:10:28.390 --> 01:10:31,268
These accounts
were deliberately, specifically attempting

1191
01:10:31.352 --> 01:10:34,355
-to sow political discord in Hong Kong.

1192
01:10:38.609 --> 01:10:40,361
-All right, Ben.

1193
01:10:42.863 --> 01:10:45,032
What does it look like to be a country

1194
01:10:45.115 --> 01:10:48,410
that's entire diet is Facebook
and social media?

1195
01:10:48.953 --> 01:10:50,871
Democracy crumbled quickly.

1196
01:10:50.955 --> 01:10:51,830
Six months.

1197
01:10:51.914 --> 01:10:53,791
After that chaos in Chicago,

1198
01:10:53.874 --> 01:10:57,086
violent clashes between protesters
and supporters...

1199
01:10:58.003 --> 01:11:01,632
Democracy is facing
a crisis of confidence.

1200
01:11:01.715 --> 01:11:04,343
What we're seeing is a global assault
on democracy.

1201
01:11:05.511 --> 01:11:07,930
Most of the countries
that are targeted are countries

1202
01:11:08.013 --> 01:11:09,723
that run democratic elections.

1203
01:11:10.641 --> 01:11:12,518
This is happening at scale.

1204
01:11:12.601 --> 01:11:15,562
By state actors,
by people with millions of dollars saying,

1205
01:11:15.646 --> 01:11:18,524
"I wanna destabilize Kenya.
I wanna destabilize Cameroon.

1206
01:11:18.607 --> 01:11:20,651
Oh, Angola? That only costs this much."

1207
01:11:20.734 --> 01:11:23,362
An extraordinary election
took place Sunday in Brazil.

1208
01:11:23.445 --> 01:11:25,823
With a campaign that's been powered
by social media.

1209
01:11:31.036 --> 01:11:33,956
We in the tech industry
have created the tools

1210
01:11:34.039 --> 01:11:37,418
to destabilize
and erode the fabric of society

1211
01:11:37.501 --> 01:11:40,254
in every country, all at once, everywhere.

1212
01:11:40.337 --> 01:11:44,508
You have this in Germany, Spain, France,
Brazil, Australia.

1213
01:11:44.591 --> 01:11:47,261
Some of the most "developed nations"
in the world

1214
01:11:47.344 --> 01:11:49,221
are now imploding on each other,

1215
01:11:49.305 --> 01:11:50,931
and what do they have in common?

1216
01:11:51.974 --> 01:11:52,975
Knowing what you know now,

1217
01:11:53.058 --> 01:11:56,312
do you believe Facebook impacted
the results of the 2016 election?

1218
01:11:58.897 --> 01:12:00,691
You know, it's... the...

1219
01:12:01.275 --> 01:12:04,653
the reality is, well, there
were so many different forces at play.

1220
01:12:04.737 --> 01:12:07,865
Representatives from Facebook, Twitter,
and Google are back on Capitol Hill

1221
01:12:07.948 --> 01:12:09,450
for a second day of testimony

1222
01:12:09.533 --> 01:12:12,578
about Russia's interference
in the 2016 election.

1223
01:12:12.661 --> 01:12:17,291
The manipulation
by third parties is not a hack.

1224
01:12:18.500 --> 01:12:21,462
Right? The Russians didn't hack Facebook.

1225
01:12:21.545 --> 01:12:24,965
What they did was they used the tools
that Facebook created

1226
01:12:25.049 --> 01:12:27,843
for legitimate advertisers
and legitimate users,

1227
01:12:27.926 --> 01:12:30,346
and they applied it
to a nefarious purpose.

1228
01:12:34.475 --> 01:12:36,602
One country can manipulate another one

1229
01:12:36.685 --> 01:12:39,229
without actually invading
its physical borders. 

1230
01:12:39.605 --> 01:12:42,232
We're seeing violent images.
It appears to be a dumpster

1231
01:12:42.316 --> 01:12:43,317
being pushed around...

1232
01:12:43.400 --> 01:12:46,028
But it wasn't
about who you wanted to vote for.

1233
01:12:46.362 --> 01:12:50,574
It was about sowing total chaos
and division in society.

1234
01:12:50.657 --> 01:12:53,035
Now,
this was in Huntington Beach. A march...

1235
01:12:53.118 --> 01:12:54,870
It's about making two sides

1236
01:12:54.953 --> 01:12:56,413
who couldn't hear each other anymore,

1237
01:12:56.497 --> 01:12:58,123
who didn't want to hear each other
anymore,

1238
01:12:58.207 --> 01:12:59,875
who didn't trust each other anymore.

1239
01:12:59.958 --> 01:13:03,212
This is a city
where hatred was laid bare

1240
01:13:03.295 --> 01:13:05,464
and transformed into racial violence.

1241
01:13:20.145 --> 01:13:20,979
Ben!

1242
01:13:21.605 --> 01:13:22,439
Cassandra!

1243
01:13:22.981 --> 01:13:23,816
-Cass!
-Ben!

1244
01:13:23.899 --> 01:13:25,484
Come here! Come here!

1245
01:13:27.486 --> 01:13:31,156
Arms up. Arms up.
Get down on your knees. Now, down. 

1246
01:13:36.120 --> 01:13:37,204
Calm--
-Ben!

1247
01:13:37.287 --> 01:13:38,664
Hey! Hands up!

1248
01:13:39.623 --> 01:13:41,750
Turn around. On the ground. On the ground!

1249
01:13:56.723 --> 01:14:00,018
Do we want this system for sale
to the highest bidder?

1250
01:14:01.437 --> 01:14:05,399
For democracy to be completely for sale,
where you can reach any mind you want,

1251
01:14:05.482 --> 01:14:09,069
target a lie to that specific population,
and create culture wars?

1252
01:14:09.236 --> 01:14:10,237
Do we want that?

1253
01:14:14.700 --> 01:14:16,577
We are a nation of people...

1254
01:14:16.952 --> 01:14:18,871
that no longer speak to each other.

1255
01:14:19.872 --> 01:14:23,000
We are a nation of people
who have stopped being friends with people

1256
01:14:23.083 --> 01:14:25,461
because of who they voted for
in the last election.

1257
01:14:25.878 --> 01:14:28,422
We are a nation of people
who have isolated ourselves

1258
01:14:28.505 --> 01:14:30,966
to only watch channels
that tell us that we're right.

1259
01:14:32.259 --> 01:14:36,597
My message here today is that tribalism
is ruining us.

1260
01:14:37.347 --> 01:14:39,183
It is tearing our country apart.

1261
01:14:40.267 --> 01:14:42,811
It is no way for sane adults to act.

1262
01:14:43.187 --> 01:14:45,314
If everyone's entitled to their own facts,

1263
01:14:45.397 --> 01:14:49,401
there's really no need for compromise,
no need for people to come together.

1264
01:14:49.485 --> 01:14:51,695
In fact, there's really no need
for people to interact.

1265
01:14:52.321 --> 01:14:53,530
We need to have...

1266
01:14:53.989 --> 01:14:58,410
some shared understanding of reality.
Otherwise, we aren't a country.

1267
01:14:58.952 --> 01:15:02,998
So, uh, long-term, the solution here is
to build more AI tools

1268
01:15:03.081 --> 01:15:08,128
that find patterns of people using
the services that no real person would do.

1269
01:15:08.212 --> 01:15:11,840
We are allowing the technologists
to frame this as a problem

1270
01:15:11.924 --> 01:15:13,884
that they're equipped to solve.

1271
01:15:15.135 --> 01:15:16,470
That is... That's a lie.

1272
01:15:17.679 --> 01:15:20,724
People talk about AI
as if it will know truth.

1273
01:15:21.683 --> 01:15:23,685
AI's not gonna solve these problems.

1274
01:15:24.269 --> 01:15:27,189
AI cannot solve the problem of fake news.

1275
01:15:28.649 --> 01:15:31,026
Google doesn't have the option of saying,

1276
01:15:31.109 --> 01:15:36,240
"Oh, is this conspiracy? Is this truth?"
Because they don't know what truth is.

1277
01:15:36.782 --> 01:15:37,783
They don't have a...

1278
01:15:37.908 --> 01:15:40,827
They don't have a proxy for truth
that's better than a click.

1279
01:15:41.870 --> 01:15:45,123
If we don't agree on what is true

1280
01:15:45.207 --> 01:15:47,584
or that there is such a thing as truth,

1281
01:15:48.293 --> 01:15:49,294
we're toast.

1282
01:15:49.753 --> 01:15:52,089
This is the problem
beneath other problems

1283
01:15:52.172 --> 01:15:54,424
because if we can't agree on what's true,

1284
01:15:55.092 --> 01:15:57,803
then we can't navigate
out of any of our problems.

1285
01:16:05.435 --> 01:16:07,729
We should suggest
Flat Earth Football Club.

1286
01:16:07.813 --> 01:16:10,566
Don't show him
sports updates. He doesn't engage.

1287
01:16:39.886 --> 01:16:42,764
A lot of people in Silicon Valley
subscribe to some kind of theory

1288
01:16:42.848 --> 01:16:45,142
that we're building
some global super brain,

1289
01:16:45.309 --> 01:16:48,020
and all of our users
are just interchangeable little neurons,

1290
01:16:48.103 --> 01:16:49,563
no one of which is important.

1291
01:16:50.230 --> 01:16:53,150
And it subjugates people
into this weird role

1292
01:16:53.233 --> 01:16:56,069
where you're just, like,
this little computing element

1293
01:16:56.153 --> 01:16:58,905
that we're programming
through our behavior manipulation

1294
01:16:58.989 --> 01:17:02,367
for the service of this giant brain,
and you don't matter.

1295
01:17:02.451 --> 01:17:04,911
You're not gonna get paid.
You're not gonna get acknowledged.

1296
01:17:04.995 --> 01:17:06,455
You don't have self-determination.

1297
01:17:06.538 --> 01:17:09,416
We'll sneakily just manipulate you
because you're a computing node,

1298
01:17:09.499 --> 01:17:12,336
so we need to program you 'cause that's
what you do with computing nodes.

1299
01:17:20.093 --> 01:17:21,845
Oh, man. 

1300
01:17:21.928 --> 01:17:25,390
When you think about technology
and it being an existential threat,

1301
01:17:25.474 --> 01:17:28,060
you know, that's a big claim, and...

1302
01:17:29.603 --> 01:17:33,982
it's easy to then, in your mind, think,
"Okay, so, there I am with the phone...

1303
01:17:35.609 --> 01:17:37,235
scrolling, clicking, using it.

1304
01:17:37.319 --> 01:17:39,196
Like, where's the existential threat?

1305
01:17:40.280 --> 01:17:41,615
Okay, there's the supercomputer.

1306
01:17:41.698 --> 01:17:43,950
The other side of the screen,
pointed at my brain,

1307
01:17:44.409 --> 01:17:47,537
got me to watch one more video.
Where's the existential threat?"

1308
01:17:54.252 --> 01:17:57,631
It's not
about the technology

1309
01:17:57.714 --> 01:17:59,341
being the existential threat.

1310
01:18:03.679 --> 01:18:06,264
It's the technology's ability

1311
01:18:06.348 --> 01:18:09,476
to bring out the worst in society...

1312
01:18:09.559 --> 01:18:13,522
...and the worst in society
being the existential threat.

1313
01:18:18.819 --> 01:18:20,570
If technology creates...

1314
01:18:21.697 --> 01:18:23,115
mass chaos,

1315
01:18:23.198 --> 01:18:24,533
outrage, incivility,

1316
01:18:24.616 --> 01:18:26,326
lack of trust in each other,

1317
01:18:27.452 --> 01:18:30,414
loneliness, alienation, more polarization,

1318
01:18:30.706 --> 01:18:33,333
more election hacking, more populism,

1319
01:18:33.917 --> 01:18:36,962
more distraction and inability
to focus on the real issues...

1320
01:18:37.963 --> 01:18:39,715
that's just society. 

1321
01:18:40.340 --> 01:18:46,388
And now society
is incapable of healing itself

1322
01:18:46.471 --> 01:18:48,515
and just devolving into a kind of chaos.

1323
01:18:51.977 --> 01:18:54,938
This affects everyone,
even if you don't use these products.

1324
01:18:55.397 --> 01:18:57,524
These things have become
digital Frankensteins

1325
01:18:57.607 --> 01:19:00,068
that are terraforming the world
in their image,

1326
01:19:00.152 --> 01:19:01,862
whether it's the mental health of children

1327
01:19:01.945 --> 01:19:04,489
or our politics
and our political discourse,

1328
01:19:04.573 --> 01:19:07,492
without taking responsibility
for taking over the public square.

1329
01:19:07.576 --> 01:19:10,579
-So, again, it comes back to--
-And who do you think's responsible?

1330
01:19:10.662 --> 01:19:13,582
I think we have
to have the platforms be responsible

1331
01:19:13.665 --> 01:19:15,584
for when they take over
election advertising,

1332
01:19:15.667 --> 01:19:17,794
they're responsible
for protecting elections.

1333
01:19:17.878 --> 01:19:20,380
When they take over mental health of kids
or Saturday morning,

1334
01:19:20.464 --> 01:19:22,841
they're responsible
for protecting Saturday morning.

1335
01:19:23.592 --> 01:19:27,929
The race to keep people's attention
isn't going away.

1336
01:19:28.388 --> 01:19:31,850
Our technology's gonna become
more integrated into our lives, not less.

1337
01:19:31.933 --> 01:19:34,895
The AIs are gonna get better at predicting
what keeps us on the screen,

1338
01:19:34.978 --> 01:19:37,105
not worse at predicting
what keeps us on the screen.

1339
01:19:38.940 --> 01:19:42,027
I... I am 62 years old,

1340
01:19:42.110 --> 01:19:44,821
getting older every minute,
the more this conversation goes on...

1341
01:19:48.700 --> 01:19:52,370
I'm probably gonna be dead and gone,
and I'll probably be thankful for it,

1342
01:19:52.454 --> 01:19:54,331
when all this shit comes to fruition.

1343
01:19:54.790 --> 01:19:59,586
Because... Because I think
that this scares me to death.

1344
01:20:00.754 --> 01:20:03,048
Do... Do you...
Do you see it the same way?

1345
01:20:03.548 --> 01:20:06,885
Or am I overreacting to a situation
that I don't know enough about?

1346
01:20:13.850 --> 01:20:18,480
I think,
in the... in the shortest time horizon...

1347
01:20:19.523 --> 01:20:20,524
civil war.

1348
01:20:24.444 --> 01:20:29,908
If we go down the current status quo
for, let's say, another 20 years...

1349
01:20:31.117 --> 01:20:34,579
we probably destroy our civilization
through willful ignorance.

1350
01:20:34.663 --> 01:20:37,958
We probably fail to meet the challenge
of climate change.

1351
01:20:38.041 --> 01:20:42,087
We probably degrade
the world's democracies

1352
01:20:42.170 --> 01:20:46,132
so that they fall into some sort
of bizarre autocratic dysfunction.

1353
01:20:46.216 --> 01:20:48,426
We probably ruin the global economy.

1354
01:20:48.760 --> 01:20:52,264
Uh, we probably, um, don't survive.

1355
01:20:52.347 --> 01:20:54,808
You know,
I... I really do view it as existential.

1356
01:21:05.068 --> 01:21:08,488
that are gonna know what it was like
before this illusion took place?

1357
01:21:11.074 --> 01:21:14,578
Like, how do you wake up from the matrix
when you don't know you're in the matrix?

1358
01:21:27.382 --> 01:21:30,635
A lot of what we're saying
sounds like it's just this...

1359
01:21:31.511 --> 01:21:33,680
one-sided doom and gloom.

1360
01:21:33.763 --> 01:21:36,808
Like, "Oh, my God,
technology's just ruining the world

1361
01:21:36.892 --> 01:21:38,059
and it's ruining kids,"

1362
01:21:38.143 --> 01:21:40,061
and it's like... "No." 

1363
01:21:40.228 --> 01:21:44,065
It's confusing
because it's simultaneous utopia...

1364
01:21:44.608 --> 01:21:45,567
and dystopia.

1365
01:21:45.942 --> 01:21:50,447
Like, I could hit a button on my phone,
and a car shows up in 30 seconds,

1366
01:21:50.530 --> 01:21:52,699
and I can go exactly where I need to go.

1367
01:21:52.782 --> 01:21:55,660
That is magic. That's amazing.

1368
01:21:56.161 --> 01:21:57,662
When we were making the like button,

1369
01:21:57.746 --> 01:22:01,499
our entire motivation was, "Can we spread
positivity and love in the world?"

1370
01:22:01.583 --> 01:22:05,003
The idea that, fast-forward to today,
and teens would be getting depressed

1371
01:22:05.086 --> 01:22:06,421
when they don't have enough likes,

1372
01:22:06.504 --> 01:22:08,632
or it could be leading
to political polarization

1373
01:22:08.715 --> 01:22:09,883
was nowhere on our radar.

1374
01:22:09.966 --> 01:22:12,135
I don't think these guys set out
to be evil.

1375
01:22:13.511 --> 01:22:15,764
It's just the business model
that has a problem.

1376
01:22:15.847 --> 01:22:20,226
You could shut down the service
and destroy whatever it is--

1377
01:22:20.310 --> 01:22:24,522
$20 billion of shareholder value--
and get sued and...

1378
01:22:24.606 --> 01:22:27,108
But you can't, in practice,
put the genie back in the bottle.

1379
01:22:27.192 --> 01:22:30,403
You can make some tweaks,
but at the end of the day,

1380
01:22:30.487 --> 01:22:34,032
you've gotta grow revenue and usage,
quarter over quarter. It's...

1381
01:22:34.658 --> 01:22:37,535
The bigger it gets,
the harder it is for anyone to change.

1382
01:22:38.495 --> 01:22:43,458
What I see is a bunch of people
who are trapped by a business model,

1383
01:22:43.541 --> 01:22:46,169
an economic incentive,
and shareholder pressure

1384
01:22:46.252 --> 01:22:48,922
that makes it almost impossible
to do something else.

1385
01:22:49.005 --> 01:22:50,924
I think we need to accept that it's okay

1386
01:22:51.007 --> 01:22:53,176
for companies to be focused
on making money.

1387
01:22:53.259 --> 01:22:55,637
What's not okay
is when there's no regulation, no rules,

1388
01:22:55.720 --> 01:22:56,888
and no competition,

1389
01:22:56.972 --> 01:23:00,850
and the companies are acting
as sort of de facto governments.

1390
01:23:00.934 --> 01:23:03,353
And then they're saying,
"Well, we can regulate ourselves."

1391
01:23:03.436 --> 01:23:05,981
I mean, that's just a lie.
That's just ridiculous.

1392
01:23:06.064 --> 01:23:08,650
Financial incentives kind of run
the world,

1393
01:23:08.733 --> 01:23:12,529
so any solution to this problem

1394
01:23:12.612 --> 01:23:15,573
has to realign the financial incentives.

1395
01:23:16.074 --> 01:23:18,785
There's no fiscal reason
for these companies to change.

1396
01:23:18.868 --> 01:23:21,329
And that is why I think
we need regulation.

1397
01:23:21.413 --> 01:23:24,290
The phone company
has tons of sensitive data about you,

1398
01:23:24.374 --> 01:23:27,544
and we have a lot of laws that make sure
they don't do the wrong things.

1399
01:23:27.627 --> 01:23:31,506
We have almost no laws
around digital privacy, for example.

1400
01:23:31.589 --> 01:23:34,426
We could tax data collection
and processing

1401
01:23:34.509 --> 01:23:37,554
the same way that you, for example,
pay your water bill

1402
01:23:37.637 --> 01:23:39,723
by monitoring the amount of water
that you use.

1403
01:23:39.806 --> 01:23:43,226
You tax these companies on the data assets
that they have.

1404
01:23:43.309 --> 01:23:44,769
It gives them a fiscal reason

1405
01:23:44.853 --> 01:23:47,856
to not acquire every piece of data
on the planet.

1406
01:23:47.939 --> 01:23:50,567
The law runs way behind on these things,

1407
01:23:50.650 --> 01:23:55,864
but what I know is the current situation
exists not for the protection of users,

1408
01:23:55.947 --> 01:23:58,700
but for the protection
of the rights and privileges

1409
01:23:58.783 --> 01:24:01,453
of these gigantic,
incredibly wealthy companies.

1410
01:24:02.245 --> 01:24:05,832
Are we always gonna defer to the richest,
most powerful people?

1411
01:24:05.915 --> 01:24:07,417
Or are we ever gonna say,

1412
01:24:07.959 --> 01:24:12,047
"You know, there are times
when there is a national interest.

1413
01:24:12.130 --> 01:24:15,592
There are times
when the interests of people, of users,

1414
01:24:15.675 --> 01:24:17,385
is actually more important

1415
01:24:18.011 --> 01:24:21,473
than the profits of somebody
who's already a billionaire"?

1416
01:24:21.556 --> 01:24:26,603
These markets undermine democracy,
and they undermine freedom,

1417
01:24:26.686 --> 01:24:28,521
and they should be outlawed.

1418
01:24:29.147 --> 01:24:31,816
This is not a radical proposal.

1419
01:24:31.900 --> 01:24:34,194
There are other markets that we outlaw.

1420
01:24:34.277 --> 01:24:36,988
We outlaw markets in human organs.

1421
01:24:37.072 --> 01:24:39,491
We outlaw markets in human slaves. 

1422
01:24:39.949 --> 01:24:44,037
Because they have
inevitable destructive consequences.

1423
01:24:44.537 --> 01:24:45,830
We live in a world

1424
01:24:45.914 --> 01:24:50,001
in which a tree is worth more,
financially, dead than alive,

1425
01:24:50.085 --> 01:24:53,838
in a world in which a whale
is worth more dead than alive.

1426
01:24:53.922 --> 01:24:56,341
For so long as our economy works
in that way

1427
01:24:56.424 --> 01:24:58,134
and corporations go unregulated,

1428
01:24:58.218 --> 01:25:00,678
they're going to continue
to destroy trees,

1429
01:25:00.762 --> 01:25:01,763
to kill whales,

1430
01:25:01.846 --> 01:25:06,101
to mine the earth, and to continue
to pull oil out of the ground,

1431
01:25:06.184 --> 01:25:08,394
even though we know
it is destroying the planet

1432
01:25:08.478 --> 01:25:12,148
and we know that it's going to leave
a worse world for future generations.

1433
01:25:12.232 --> 01:25:13,858
This is short-term thinking

1434
01:25:13.942 --> 01:25:16,694
based on this religion of profit
at all costs,

1435
01:25:16.778 --> 01:25:20,156
as if somehow, magically, each corporation
acting in its selfish interest

1436
01:25:20.240 --> 01:25:21,950
is going to produce the best result.

1437
01:25:22.033 --> 01:25:24,494
This has been affecting the environment
for a long time.

1438
01:25:24.577 --> 01:25:27,288
What's frightening,
and what hopefully is the last straw

1439
01:25:27.372 --> 01:25:29,207
that will make us wake up
as a civilization

1440
01:25:29.290 --> 01:25:31,709
to how flawed this theory has been
in the first place

1441
01:25:31.793 --> 01:25:35,004
is to see that now we're the tree,
we're the whale.

1442
01:25:35.088 --> 01:25:37,048
Our attention can be mined.

1443
01:25:37.132 --> 01:25:39,134
We are more profitable to a corporation

1444
01:25:39.217 --> 01:25:41,594
if we're spending time
staring at a screen,

1445
01:25:41.678 --> 01:25:42,971
staring at an ad,

1446
01:25:43.054 --> 01:25:45,890
than if we're spending that time
living our life in a rich way.

1447
01:25:45.974 --> 01:25:47,559
And so, we're seeing the results of that.

1448
01:25:47.642 --> 01:25:50,687
We're seeing corporations using
powerful artificial intelligence

1449
01:25:50.770 --> 01:25:53,648
to outsmart us and figure out
how to pull our attention

1450
01:25:53.731 --> 01:25:55,358
toward the things they want us to look at,

1451
01:25:55.441 --> 01:25:57,277
rather than the things
that are most consistent

1452
01:25:57.360 --> 01:25:59,237
with our goals and our values
and our lives.

1453
01:26:05.535 --> 01:26:06,911
What a computer is,

1454
01:26:06.995 --> 01:26:10,290
is it's the most remarkable tool
that we've ever come up with.

1455
01:26:11.124 --> 01:26:13,877
And it's the equivalent of a bicycle
for our minds.

1456
01:26:15.628 --> 01:26:20,091
The idea of humane technology,
that's where Silicon Valley got its start.

1457
01:26:21.050 --> 01:26:25,722
And we've lost sight of it
because it became the cool thing to do,

1458
01:26:25.805 --> 01:26:27,265
as opposed to the right thing to do.

1459
01:26:27.348 --> 01:26:29,726
The Internet was, like,
a weird, wacky place.

1460
01:26:29.809 --> 01:26:31,394
It was experimental.

1461
01:26:31.477 --> 01:26:34,731
Creative things happened on the Internet,
and certainly, they do still,

1462
01:26:34.814 --> 01:26:38,610
but, like, it just feels like this,
like, giant mall. 

1463
01:26:38.693 --> 01:26:42,071
You know, it's just like, "God,
there's gotta be...

1464
01:26:42.155 --> 01:26:44,157
there's gotta be more to it than that."

1465
01:26:46.659 --> 01:26:48,411
I guess I'm just an optimist.

1466
01:26:48.494 --> 01:26:52,040
'Cause I think we can change
what social media looks like and means.

1467
01:26:54.083 --> 01:26:56,711
The way the technology works
is not a law of physics.

1468
01:26:56.794 --> 01:26:57,921
It is not set in stone.

1469
01:26:58.004 --> 01:27:02,175
These are choices that human beings
like myself have been making.

1470
01:27:02.759 --> 01:27:05,345
And human beings can change
those technologies.

1471
01:27:06.971 --> 01:27:09,974
And the question now is
whether or not we're willing to admit

1472
01:27:10.475 --> 01:27:15,438
that those bad outcomes are coming
directly as a product of our work.

1473
01:27:21.027 --> 01:27:24,864
It's that we built these things,
and we have a responsibility to change it.

1474
01:27:37.085 --> 01:27:38,711
The attention extraction model

1475
01:27:38.795 --> 01:27:42,298
is not how we want to treat
human beings.

1476
01:27:45.343 --> 01:27:48,137
Is it just me or...

1477
01:27:49.722 --> 01:27:51,099
Poor sucker.

1478
01:27:51.516 --> 01:27:53,226
The fabric of a healthy society

1479
01:27:53.309 --> 01:27:56,145
depends on us getting off
this corrosive business model.

1480
01:28:04.696 --> 01:28:08,157
We can demand
that these products be designed humanely.

1481
01:28:09.409 --> 01:28:13,121
We can demand to not be treated
as an extractable resource.

1482
01:28:15.164 --> 01:28:18,334
The intention could be:
"How do we make the world better?"

1483
01:28:20.336 --> 01:28:21,504
Throughout history,

1484
01:28:21.587 --> 01:28:23,798
every single time
something's gotten better,

1485
01:28:23.881 --> 01:28:26,342
it's because somebody has come along
to say,

1486
01:28:26.426 --> 01:28:28,428
"This is stupid. We can do better."

1487
01:28:29.178 --> 01:28:32,557
Like, it's the critics
that drive improvement.

1488
01:28:33.141 --> 01:28:35,393
It's the critics
who are the true optimists.

1489
01:28:37.020 --> 01:28:39,147
Hello.

1490
01:28:42.984 --> 01:28:44,277
Um...

1491
01:28:46.195 --> 01:28:47,697
I mean, it seems kind of crazy, right?

1492
01:28:47.780 --> 01:28:51,534
It's like the fundamental way
that this stuff is designed...

1493
01:28:52.994 --> 01:28:55,163
isn't going in a good direction.

1494
01:28:55.246 --> 01:28:56,873
Like, the entire thing.

1495
01:28:56.956 --> 01:29:00,626
So, it sounds crazy to say
we need to change all that,

1496
01:29:01.169 --> 01:29:02,670
but that's what we need to do.

1497
01:29:04.297 --> 01:29:05,923
Think we're gonna get there?

1498
01:29:07.383 --> 01:29:08,301
We have to.

1499
01:29:20.646 --> 01:29:24,942
Um,
it seems like you're very optimistic.

1500
01:29:26.194 --> 01:29:27,570
-Is that how I sound?

1501
01:29:27.653 --> 01:29:28,905
Yeah, I mean...

1502
01:29:28.988 --> 01:29:31,449
I can't believe you keep saying that,
because I'm like, "Really?

1503
01:29:31.532 --> 01:29:33,409
I feel like we're headed toward dystopia.

1504
01:29:33.493 --> 01:29:35,328
I feel like we're on the fast track
to dystopia,

1505
01:29:35.411 --> 01:29:37,830
and it's gonna take a miracle
to get us out of it."

1506
01:29:37.914 --> 01:29:40,291
And that miracle is, of course,
collective will.

1507
01:29:41.000 --> 01:29:44,587
I am optimistic
that we're going to figure it out,

1508
01:29:44.670 --> 01:29:47,048
but I think it's gonna take a long time.

1509
01:29:47.131 --> 01:29:50,385
Because not everybody recognizes
that this is a problem.

1510
01:29:50.468 --> 01:29:55,890
I think one of the big failures
in technology today

1511
01:29:55.973 --> 01:29:58,643
is a real failure of leadership,

1512
01:29:58.726 --> 01:30:01,979
of, like, people coming out
and having these open conversations

1513
01:30:02.063 --> 01:30:05,900
about things that... not just
what went well, but what isn't perfect

1514
01:30:05.983 --> 01:30:08,194
so that someone can come in
and build something new.

1515
01:30:08.277 --> 01:30:10,321
At the end of the day, you know,

1516
01:30:10.405 --> 01:30:14,617
this machine isn't gonna turn around
until there's massive public pressure.

1517
01:30:14.700 --> 01:30:18,329
By having these conversations
and... and voicing your opinion,

1518
01:30:18.413 --> 01:30:21,082
in some cases
through these very technologies,

1519
01:30:21.165 --> 01:30:24,252
we can start to change the tide.
We can start to change the conversation.

1520
01:30:24.335 --> 01:30:27,004
It might sound strange,
but it's my world. It's my community.

1521
01:30:27.088 --> 01:30:29,632
I don't hate them. I don't wanna do
any harm to Google or Facebook.

1522
01:30:29.715 --> 01:30:32,885
I just want to reform them
so they don't destroy the world. You know?

1523
01:30:32.969 --> 01:30:35,513
I've uninstalled a ton of apps
from my phone

1524
01:30:35.596 --> 01:30:37,723
that I felt were just wasting my time.

1525
01:30:37.807 --> 01:30:40,685
All the social media apps,
all the news apps,

1526
01:30:40.768 --> 01:30:42,520
and I've turned off notifications

1527
01:30:42.603 --> 01:30:45,815
on anything that was vibrating my leg
with information

1528
01:30:45.898 --> 01:30:48,943
that wasn't timely and important to me
right now.

1529
01:30:49.026 --> 01:30:51,279
It's for the same reason
I don't keep cookies in my pocket.

1530
01:30:51.362 --> 01:30:53,197
Reduce the number of notifications
you get.

1531
01:30:53.281 --> 01:30:54,449
Turn off notifications.

1532
01:30:54.532 --> 01:30:55,950
Turning off all notifications.

1533
01:30:56.033 --> 01:30:58,536
I'm not using Google anymore,
I'm using Qwant,

1534
01:30:58.619 --> 01:31:01,497
which doesn't store your search history.

1535
01:31:01.581 --> 01:31:04,459
Never accept a video recommended to you
on YouTube.

1536
01:31:04.542 --> 01:31:07,003
Always choose.
That's another way to fight.

1537
01:31:07.086 --> 01:31:12,133
There are tons of Chrome extensions
that remove recommendations.

1538
01:31:12.216 --> 01:31:15,178
You're recommending
something to undo what you made.

1539
01:31:15.261 --> 01:31:16,554
Yep.

1540
01:31:16.929 --> 01:31:21,642
Before you share, fact-check,
consider the source, do that extra Google.

1541
01:31:21.726 --> 01:31:25,104
If it seems like it's something designed
to really push your emotional buttons,

1542
01:31:25.188 --> 01:31:26,314
like, it probably is.

1543
01:31:26.397 --> 01:31:29,025
Essentially, you vote with your clicks.

1544
01:31:29.108 --> 01:31:30,359
If you click on clickbait,

1545
01:31:30.443 --> 01:31:33,779
you're creating a financial incentive
that perpetuates this existing system.

1546
01:31:33.863 --> 01:31:36,949
Make sure that you get
lots of different kinds of information

1547
01:31:37.033 --> 01:31:37,909
in your own life.

1548
01:31:37.992 --> 01:31:40,995
I follow people on Twitter
that I disagree with

1549
01:31:41.078 --> 01:31:44,207
because I want to be exposed
to different points of view.

1550
01:31:44.665 --> 01:31:46,584
Notice that many people
in the tech industry

1551
01:31:46.667 --> 01:31:49,045
don't give these devices
to their own children.

1552
01:31:49.128 --> 01:31:51,047
My kids don't use social media at all.

1553
01:31:51.839 --> 01:31:53,549
Is that a rule,
or is that a...

1554
01:31:53.633 --> 01:31:54,509
That's a rule.

1555
01:31:55.092 --> 01:31:57,845
We are zealots about it.

1556
01:31:57.929 --> 01:31:59,222
We're... We're crazy.

1557
01:31:59.305 --> 01:32:05,603
And we don't let our kids have
really any screen time.

1558
01:32:05.686 --> 01:32:08,564
I've worked out
what I think are three simple rules, um,

1559
01:32:08.648 --> 01:32:12,610
that make life a lot easier for families
and that are justified by the research.

1560
01:32:12.693 --> 01:32:15,571
So, the first rule is
all devices out of the bedroom

1561
01:32:15.655 --> 01:32:17,281
at a fixed time every night.

1562
01:32:17.365 --> 01:32:20,535
Whatever the time is, half an hour
before bedtime, all devices out.

1563
01:32:20.618 --> 01:32:24,038
The second rule is no social media
until high school.

1564
01:32:24.121 --> 01:32:26,374
Personally, I think the age should be 16.

1565
01:32:26.457 --> 01:32:28,960
Middle school's hard enough.
Keep it out until high school.

1566
01:32:29.043 --> 01:32:32,964
And the third rule is
work out a time budget with your kid.

1567
01:32:33.047 --> 01:32:34,757
And if you talk with them and say,

1568
01:32:34.840 --> 01:32:37,927
"Well, how many hours a day
do you wanna spend on your device?

1569
01:32:38.010 --> 01:32:39,637
What do you think is a good amount?"

1570
01:32:39.720 --> 01:32:41,597
they'll often say
something pretty reasonable.

1571
01:32:42.056 --> 01:32:44,642
Well, look, I know perfectly well

1572
01:32:44.725 --> 01:32:48,563
that I'm not gonna get everybody
to delete their social media accounts,

1573
01:32:48.646 --> 01:32:50,439
but I think I can get a few.

1574
01:32:50.523 --> 01:32:54,402
And just getting a few people
to delete their accounts matters a lot,

1575
01:32:54.485 --> 01:32:58,406
and the reason why is that that creates
the space for a conversation

1576
01:32:58.489 --> 01:33:00,908
because I want there to be enough people
out in the society

1577
01:33:00.992 --> 01:33:05,204
who are free of the manipulation engines
to have a societal conversation

1578
01:33:05.288 --> 01:33:07,540
that isn't bounded
by the manipulation engines.

1579
01:33:07.623 --> 01:33:10,126
So, do it! Get out of the system.

1580
01:33:10.209 --> 01:33:12,503
Yeah, delete. Get off the stupid stuff.

1581
01:33:13.546 --> 01:33:16,507
The world's beautiful.
Look. Look, it's great out there.

1
00:00:19.978 --> 00:00:24,774
&lrm;（“进入凡人生活的一切强大之物
&lrm;无不具有弊端”）

2
00:00:24.858 --> 00:00:27,861
&lrm;（——索福克勒斯）

3
00:00:31.156 --> 00:00:34,659
&lrm;好 你直接开始吧？
&lrm;好 坐下 能否舒适地坐着

4
00:00:37.579 --> 00:00:38,580
&lrm;还好吗？好了

5
00:00:38.663 --> 00:00:39,497
&lrm;是

6
00:00:43.043 --> 00:00:44,419
&lrm;第一镜 打板

7
00:00:46.880 --> 00:00:48,923
&lrm;要我先从自我介绍开始吗？

8
00:00:50.467 --> 00:00:53,344
&lrm;世界你好 贝利 第三镜

9
00:00:53.970 --> 00:00:56,056
&lrm;-可以了吗？
&lrm;-这是我最讨厌的部分 兄弟

10
00:00:57.515 --> 00:00:58,516
&lrm;我不喜欢这样

11
00:00:59.851 --> 00:01:02,228
&lrm;我2011年到2012年间在脸书工作

12
00:01:02.312 --> 00:01:05,190
&lrm;我是Instagram非常早期的员工

13
00:01:05.273 --> 00:01:08,693
&lrm;我曾任职于谷歌、YouTube

14
00:01:08.777 --> 00:01:11,696
&lrm;苹果、谷歌、推特、Palm

15
00:01:12.739 --> 00:01:15,533
&lrm;我帮助创始了Mozilla Labs
&lrm;后来更多工作于火狐这边

16
00:01:15.617 --> 00:01:17,994
&lrm;在拍吗？大家…

17
00:01:18.078 --> 00:01:18,953
&lrm;很好

18
00:01:21.206 --> 00:01:26,169
&lrm;我曾在推特工作 我在推特的
&lrm;最后一份岗位 是高级副总工程师

19
00:01:27.462 --> 00:01:29,255
&lrm;我曾是Pinterest的总经理

20
00:01:29.339 --> 00:01:32,717
&lrm;在那之前 我在脸书做了五年的

21
00:01:32.801 --> 00:01:34,260
&lrm;盈利总监

22
00:01:34.344 --> 00:01:37,972
&lrm;在推特期间 我用了几年时间
&lrm;运营他们的开发者平台

23
00:01:38.056 --> 00:01:40,225
&lrm;然后我做了消费者产品部长

24
00:01:40.308 --> 00:01:44,270
&lrm;我曾合作发明
&lrm;谷歌硬盘、谷歌邮箱聊天

25
00:01:44.354 --> 00:01:46,689
&lrm;脸书网页和脸书“赞”按钮

26
00:01:47.440 --> 00:01:50,777
&lrm;对 所以我才花了八个月的时间

27
00:01:50.860 --> 00:01:52,779
&lrm;和律师反复周旋

28
00:01:54.030 --> 00:01:55,406
&lrm;真的让我很崩溃

29
00:01:58.409 --> 00:02:02,914
&lrm;我在那里任职的时候 一直觉得
&lrm;总体上 这是积极的力量

30
00:02:03.373 --> 00:02:05,375
&lrm;我现在不确定 自己是否还这样想了

31
00:02:05.458 --> 00:02:10,588
&lrm;出于对道德伦理的担心
&lrm;我于2017年6月离开谷歌

32
00:02:10.672 --> 00:02:14,134
&lrm;不仅是担心谷歌的道德伦理
&lrm;而是对整个产业

33
00:02:14.217 --> 00:02:15,385
&lrm;我很担心

34
00:02:16.719 --> 00:02:17,679
&lrm;非常担心

35
00:02:19.097 --> 00:02:21,808
&lrm;如今 人们很容易忽略一个事实

36
00:02:21.891 --> 00:02:27,814
&lrm;这些工具
&lrm;其实为世界创造了一些美好的东西

37
00:02:27.897 --> 00:02:31,943
&lrm;它们让失去联系的家人重聚
&lrm;找器官捐赠者

38
00:02:32.026 --> 00:02:35,613
&lrm;它们为整个世界带来了

39
00:02:35.697 --> 00:02:37,866
&lrm;有意义的、系统的变革

40
00:02:37.949 --> 00:02:40,201
&lrm;这是这些平台积极的一面

41
00:02:40.827 --> 00:02:44,539
&lrm;我认为我们对它的消极一面
&lrm;过度看轻了

42
00:02:45.540 --> 00:02:48,585
&lrm;对 这些东西 只要你发布
&lrm;它们自己就会存活

43
00:02:48.668 --> 00:02:52,005
&lrm;它们被使用的方式
&lrm;与你当初的预期大相径庭

44
00:02:52.088 --> 00:02:56,509
&lrm;我深信 这些负面的后果
&lrm;不是任何人刻意为之

45
00:02:56.593 --> 00:02:59,554
&lrm;没有任何一个坏人 没有 绝对没有

46
00:03:01.639 --> 00:03:03,600
&lrm;那么问题在哪里？

47
00:03:09.230 --> 00:03:11,357
&lrm;是否有问题？问题在哪里？

48
00:03:18.406 --> 00:03:20,158
&lrm;是 很难给出一个单一的、简明的…

49
00:03:20.241 --> 00:03:22,118
&lrm;我在试着谈论很多不同的问题

50
00:03:22.577 --> 00:03:23,578
&lrm;问题在哪里？

51
00:03:28.208 --> 00:03:32,253
&lrm;NETFLIX 原创纪录片

52
00:03:33.588 --> 00:03:35,340
&lrm;虽然面对越来越多的质疑

53
00:03:35.423 --> 00:03:37,675
&lrm;这些所谓的大型技术公司却越发壮大

54
00:03:37.759 --> 00:03:40,929
&lrm;整个技术产业
&lrm;正在面临全新维度的审查

55
00:03:41.012 --> 00:03:43,806
&lrm;一项新的研究初步揭示了心理健康

56
00:03:43.890 --> 00:03:46,142
&lrm;与社交媒体使用之间的联系

57
00:03:46.226 --> 00:03:48,478
&lrm;来谈谈最新的研究…

58
00:03:49.187 --> 00:03:51,397
&lrm;…的情况 根本没有保险

59
00:03:51.481 --> 00:03:54,108
&lrm;数千万美国人无望地

60
00:03:54.192 --> 00:03:56,319
&lrm;玩电子设备成瘾

61
00:03:56.402 --> 00:03:59,364
&lrm;因为技术 现在你真的能把自己
&lrm;隔离在一个泡泡内 周围都是

62
00:03:59.447 --> 00:04:00,698
&lrm;（你的朋友在照片中圈出了你）

63
00:04:00.782 --> 00:04:02,742
&lrm;与你观点相似的人
&lrm;瘾性就更加恶化了

64
00:04:02.825 --> 00:04:04,577
&lrm;虚假新闻变得更发达了

65
00:04:04.661 --> 00:04:06,788
&lrm;威胁着全世界的社会

66
00:04:06.871 --> 00:04:10,333
&lrm;我们12年多以前创造推特的时候
&lrm;根本没有想到这些

67
00:04:10.416 --> 00:04:12,502
&lrm;官方说 他们没有理由相信

68
00:04:12.585 --> 00:04:14,754
&lrm;俄罗斯网络攻击会停止

69
00:04:14.837 --> 00:04:18,132
&lrm;YouTube被迫专注于清理网站

70
00:04:18.216 --> 00:04:21,552
&lrm;如果你和十几岁的孩子去聊

71
00:04:21.636 --> 00:04:24,013
&lrm;他们是绝对不可能删除抖音的…

72
00:04:24.097 --> 00:04:26,349
&lrm;喂 艾拉 可以帮忙摆桌子吗？

73
00:04:26.432 --> 00:04:27,517
&lrm;有一个严肃的问题

74
00:04:27.600 --> 00:04:29,978
&lrm;社交媒体是否让您的孩子抑郁

75
00:04:30.061 --> 00:04:32,105
&lrm;艾拉 可以帮忙摆桌子吗？

76
00:04:32.188 --> 00:04:35,316
&lrm;整容在青少年中已经十分受欢迎

77
00:04:35.400 --> 00:04:37,902
&lrm;整容医生甚至造出了一种新病征

78
00:04:37.986 --> 00:04:40,822
&lrm;“图片分享畸形征”
&lrm;指的是年轻的患者想做整容手术

79
00:04:40.905 --> 00:04:43,741
&lrm;让自己看上去
&lrm;更接近加了滤镜的自拍中的样子

80
00:04:43.825 --> 00:04:45,910
&lrm;我还是不明白
&lrm;你为什么让她用那东西

81
00:04:45.994 --> 00:04:47,537
&lrm;我能怎么办？

82
00:04:47.620 --> 00:04:49,580
&lrm;我是说 她们班上的其他孩子全都有

83
00:04:50.164 --> 00:04:51,165
&lrm;她才11岁

84
00:04:51.249 --> 00:04:52,959
&lrm;卡桑 没人强迫你用

85
00:04:53.042 --> 00:04:55,086
&lrm;你想和别人切断联系多久 都随你

86
00:04:55.169 --> 00:04:59,340
&lrm;喂 我没有手机也不会和别人
&lrm;切断联系 好吗？我现在就在网上

87
00:04:59.424 --> 00:05:03,094
&lrm;而且 这根本不是实际的联系
&lrm;全都是没用的…

88
00:05:03.177 --> 00:05:06,514
&lrm;监视资本主义
&lrm;已经形成了我们的政治和文化

89
00:05:06.597 --> 00:05:08,308
&lrm;而很多人根本没有察觉

90
00:05:08.391 --> 00:05:10,101
&lrm;伊斯兰国煽动网上的关注者

91
00:05:10.184 --> 00:05:12,812
&lrm;现在 白人至上主义也在这样做

92
00:05:12.895 --> 00:05:14,147
&lrm;最近在印度

93
00:05:14.230 --> 00:05:17,442
&lrm;网络暴民害死了十几个人
&lrm;包括这五个…

94
00:05:17.525 --> 00:05:20,361
&lrm;虚假新闻不只是虚假新闻
&lrm;是有后果的

95
00:05:20.445 --> 00:05:24,073
&lrm;在虚假新闻的时代
&lrm;你要怎么解决传染病？

96
00:05:24.157 --> 00:05:26,993
&lrm;吃中餐会感染新冠病毒吗？

97
00:05:27.535 --> 00:05:32,540
&lrm;我们已经从信息时代
&lrm;过渡到了虚假信息时代

98
00:05:32.623 --> 00:05:34,667
&lrm;我们的民主受到了攻击

99
00:05:34.751 --> 00:05:39,005
&lrm;我说的是：“我认为如今
&lrm;创造出的工具正在开始

100
00:05:39.088 --> 00:05:41,799
&lrm;侵蚀社会正常运转的社交纽带”

101
00:06:00.151 --> 00:06:03,446
&lrm;阿莎愿意接受评论 我们播放视频

102
00:06:04.197 --> 00:06:07,325
&lrm;然后说 “女士们先生们
&lrm;我是特里斯坦·哈里斯”

103
00:06:07.408 --> 00:06:08,826
&lrm;-好
&lrm;-很好

104
00:06:08.951 --> 00:06:12,038
&lrm;就是说 我上来 然后…

105
00:06:12.121 --> 00:06:13,748
&lrm;（人道 技术的新议程）

106
00:06:13.831 --> 00:06:16,042
&lrm;你就说“欢迎各位的到来”

107
00:06:17.919 --> 00:06:22,048
&lrm;今天 我想聊聊技术的一个新议程

108
00:06:22.131 --> 00:06:25,468
&lrm;以及我们为什么要这样做
&lrm;因为如果你问人们

109
00:06:25.551 --> 00:06:27,804
&lrm;“如今的技术产业怎么了？”

110
00:06:28.346 --> 00:06:31,641
&lrm;有一种不满和丑闻的杂音

111
00:06:31.724 --> 00:06:33,893
&lrm;“他们盗用了我们的数据”
&lrm;还有技术成瘾问题

112
00:06:33.976 --> 00:06:35,978
&lrm;有虚假新闻问题 有两极分化问题

113
00:06:36.062 --> 00:06:37,688
&lrm;有些竞选过程被黑客操控的问题

114
00:06:38.189 --> 00:06:41,609
&lrm;但是这些问题的背后
&lrm;是否有一个原因

115
00:06:41.692 --> 00:06:44,654
&lrm;导致这些问题在同时发生？

116
00:06:46.447 --> 00:06:48,408
&lrm;-感觉还行吗？
&lrm;-非常好 好

117
00:06:50.827 --> 00:06:52,954
&lrm;我只是想… 我想让人们看到…

118
00:06:53.037 --> 00:06:55,206
&lrm;在技术产业 正面临着一个问题

119
00:06:55.289 --> 00:07:00,211
&lrm;这个问题连名字都没有
&lrm;这个问题有一个源头…

120
00:07:05.091 --> 00:07:09,387
&lrm;环顾你身边
&lrm;感觉这个世界在逐渐疯狂

121
00:07:12.765 --> 00:07:15,143
&lrm;你要问自己 这是正常的吗？

122
00:07:16.102 --> 00:07:18,771
&lrm;还是我们都中了什么魔咒？

123
00:07:22.316 --> 00:07:25,153
&lrm;（特里斯坦·哈里斯
&lrm;谷歌前设计道德伦理学家）

124
00:07:25.236 --> 00:07:27,905
&lrm;（人道技术中心 合作创始人）

125
00:07:27.989 --> 00:07:30,491
&lrm;我希望更多的人能够理解它的原理

126
00:07:30.575 --> 00:07:34,036
&lrm;因为它不应该
&lrm;只被技术产业的业内知道

127
00:07:34.120 --> 00:07:36,289
&lrm;应该让所有人都知道

128
00:07:47.383 --> 00:07:48,301
&lrm;-你好！
&lrm;-嗨！

129
00:07:48.843 --> 00:07:50,595
&lrm;-特里斯坦 幸会
&lrm;-特里斯坦？

130
00:07:50.678 --> 00:07:51,721
&lrm;-对
&lrm;-太好了 好

131
00:07:53.181 --> 00:07:55,933
&lrm;特里斯坦·哈里斯
&lrm;是谷歌前设计道德伦理学家

132
00:07:56.017 --> 00:07:59,353
&lrm;被称为硅谷最接近良知的人物

133
00:07:59.437 --> 00:08:00,730
&lrm;他呼吁技术产业

134
00:08:00.813 --> 00:08:04,192
&lrm;在产品中引进
&lrm;被他称为“道德伦理设计”的要素

135
00:08:04.275 --> 00:08:06,903
&lrm;搞技术的业内人士
&lrm;极少如此直言不讳

136
00:08:06.986 --> 00:08:10,114
&lrm;特里斯坦·哈里斯相信
&lrm;总有人要这样

137
00:08:11.324 --> 00:08:12,700
&lrm;我在谷歌工作的时候

138
00:08:12.783 --> 00:08:16,037
&lrm;我在谷歌邮箱团队
&lrm;我就开始觉得很疲惫

139
00:08:16.120 --> 00:08:18,372
&lrm;因为我们讨论了很多…

140
00:08:19.457 --> 00:08:23,169
&lrm;收件箱应该长什么样
&lrm;应该是什么颜色

141
00:08:23.252 --> 00:08:25,880
&lrm;我自己感觉对邮件成瘾

142
00:08:26.297 --> 00:08:27,632
&lrm;我觉得有趣的是

143
00:08:27.715 --> 00:08:31,511
&lrm;在谷歌邮箱工作的人
&lrm;没有一个想把它做得不那么致瘾

144
00:08:31.969 --> 00:08:34,514
&lrm;我想：“别人想过这个问题吗？

145
00:08:34.597 --> 00:08:36,390
&lrm;我 没听谁谈论过这个问题”

146
00:08:36.849 --> 00:08:41,229
&lrm;我对技术产业整体感到沮丧

147
00:08:41.312 --> 00:08:43,147
&lrm;感觉我们有点迷路了

148
00:08:46.817 --> 00:08:49,820
&lrm;我真的很努力地去尝试 想办法

149
00:08:49.904 --> 00:08:52,573
&lrm;怎样能从行业内部改变这个问题

150
00:08:55.201 --> 00:08:59,497
&lrm;就在这个时候 我决定做一次展示
&lrm;算是号召大家吧

151
00:09:00.998 --> 00:09:04,961
&lrm;每天我回到家 每一个晚上
&lrm;都要花几个小时去做这件事

152
00:09:06.170 --> 00:09:11,884
&lrm;我的呼吁是 历史上从来没有过50个

153
00:09:12.426 --> 00:09:15,263
&lrm;20到35岁之间的加州白人设计师

154
00:09:15.888 --> 00:09:19,725
&lrm;做出一个能影响20亿人的决定

155
00:09:21.018 --> 00:09:24,438
&lrm;20亿人将会拥有
&lrm;他们从来不曾预料的想法

156
00:09:24.522 --> 00:09:28,401
&lrm;只因为一个谷歌的设计师说
&lrm;“你每天早上醒来

157
00:09:28.484 --> 00:09:30,778
&lrm;屏幕上的通知就是这样工作的”

158
00:09:30.861 --> 00:09:35,283
&lrm;我们作为谷歌
&lrm;有解决这个问题的道德责任

159
00:09:36.075 --> 00:09:37,743
&lrm;我把这个展示

160
00:09:37.827 --> 00:09:41,789
&lrm;发给了在谷歌
&lrm;与我关系最近的15到20个同事

161
00:09:41.872 --> 00:09:44,959
&lrm;我很紧张 我不知道他们会怎样想

162
00:09:46.460 --> 00:09:48,045
&lrm;我第二天去上班的时候

163
00:09:48.129 --> 00:09:50,464
&lrm;多数的电脑上都开着这个展示

164
00:09:50.548 --> 00:09:52,049
&lrm;（注意）

165
00:09:52.133 --> 00:09:54,552
&lrm;那天下午 有400个人同时观看

166
00:09:54.635 --> 00:09:56,053
&lrm;看到的人越来越多

167
00:09:56.137 --> 00:09:58,097
&lrm;我收到整个公司同事发来的各种邮件

168
00:09:58.180 --> 00:10:00,266
&lrm;每一个部门的人都说

169
00:10:00.349 --> 00:10:02,852
&lrm;“我太同意了
&lrm;我看到这个问题正在影响我的孩子

170
00:10:02.935 --> 00:10:06,856
&lrm;我看到这个问题正在影响我身边的人
&lrm;我们应该做点什么 来解决这个问题”

171
00:10:07.481 --> 00:10:10,818
&lrm;我感觉自己
&lrm;好像开启了一场革命之类的

172
00:10:11.861 --> 00:10:15,197
&lrm;后来 我才知道莱利·佩吉
&lrm;那一天在三个不同会议

173
00:10:15.281 --> 00:10:17,116
&lrm;都被人告知这个展示的存在

174
00:10:17.950 --> 00:10:20,369
&lrm;于是这个展示
&lrm;创造了这个文化性的时刻

175
00:10:20.870 --> 00:10:23,205
&lrm;谷歌需要认真对待

176
00:10:26.000 --> 00:10:28,794
&lrm;然后…杳无音讯了

177
00:10:34.300 --> 00:10:36,135
&lrm;2006年 所有人…

178
00:10:37.219 --> 00:10:39,221
&lrm;包括我们在脸书的所有人

179
00:10:39.305 --> 00:10:43,392
&lrm;超级羡慕谷歌
&lrm;羡慕谷歌所创建的一切

180
00:10:43.476 --> 00:10:47,396
&lrm;超级实用的服务

181
00:10:47.480 --> 00:10:51,442
&lrm;据我们当时所知
&lrm;为世界带来了很多好处

182
00:10:51.525 --> 00:10:54,695
&lrm;他们建立了一个平行的造钱机器

183
00:10:55.404 --> 00:11:00,034
&lrm;我们超级羡慕嫉妒谷歌
&lrm;在我们看来太优雅了…

184
00:11:00.826 --> 00:11:02,161
&lrm;太完美了

185
00:11:02.953 --> 00:11:05,122
&lrm;脸书当时才成立大概两年

186
00:11:05.873 --> 00:11:08,376
&lrm;我被雇到脸书 去找出

187
00:11:08.459 --> 00:11:10,586
&lrm;公司未来要走怎样的商业模式

188
00:11:10.670 --> 00:11:13,422
&lrm;我曾是盈利总监 大概意思就是

189
00:11:13.506 --> 00:11:17,051
&lrm;“你是要去想出
&lrm;这个东西怎样盈利的人”

190
00:11:17.134 --> 00:11:19,804
&lrm;当时很多人做了很多工作

191
00:11:19.887 --> 00:11:25,476
&lrm;但我明显是其中一个指向…

192
00:11:26.769 --> 00:11:28,437
&lrm;首先 我们必须要赚钱

193
00:11:29.313 --> 00:11:33,651
&lrm;我认为这个广告模式
&lrm;可能是最优雅的方式

194
00:11:42.993 --> 00:11:44,453
&lrm;妈妈刚给我们发的什么视频？

195
00:11:44.537 --> 00:11:47,873
&lrm;一个脱口秀 不过挺不错的
&lrm;那个人还算是个天才

196
00:11:47.957 --> 00:11:50,584
&lrm;他在谈论删除社交媒体
&lrm;你们真应该这样做

197
00:11:50.668 --> 00:11:52,878
&lrm;我可能要开始屏蔽她的邮件了

198
00:11:52.962 --> 00:11:56,090
&lrm;讲真 我都不知道她在说什么
&lrm;天啊 她还不如我

199
00:11:56.173 --> 00:11:58,592
&lrm;-不 她只用来找菜谱
&lrm;-对 还有工作

200
00:11:58.676 --> 00:12:00,511
&lrm;-还有健身视频
&lrm;-还看我们在做什么

201
00:12:00.594 --> 00:12:03,013
&lrm;还看她这辈子遇到过的每一个人
&lrm;在做什么

202
00:12:04.932 --> 00:12:07,893
&lrm;如果你一边往下划着
&lrm;你的社交媒体推送

203
00:12:07.977 --> 00:12:11,731
&lrm;一边看着我们
&lrm;你需要把你该死的手机放下 听好

204
00:12:11.814 --> 00:12:14,817
&lrm;因为我们的下一位嘉宾
&lrm;写了一本优秀的书

205
00:12:14.900 --> 00:12:18,112
&lrm;书的内容是社交媒体
&lrm;多大程度上破坏了我们的生活

206
00:12:18.195 --> 00:12:24,452
&lrm;掌声有请《立刻删除
&lrm;你社交媒体的十个论点》作者

207
00:12:24.535 --> 00:12:25,786
&lrm;贾伦·拉尼尔

208
00:12:27.997 --> 00:12:31,834
&lrm;谷歌、脸书这样的公司是有史以来

209
00:12:31.917 --> 00:12:33,544
&lrm;最富有、最成功的几个公司

210
00:12:34.295 --> 00:12:36,839
&lrm;他们的员工数量相对较少

211
00:12:36.922 --> 00:12:40,468
&lrm;他们只有一个大电脑 在那里摇钱

212
00:12:41.510 --> 00:12:45,222
&lrm;问题是 别人为什么给他们钱呢？
&lrm;这是一个非常重要的问题

213
00:12:47.308 --> 00:12:49,977
&lrm;我做了35年的技术产业投资者

214
00:12:51.020 --> 00:12:54,356
&lrm;硅谷的前50年 行业制造产品…

215
00:12:54.440 --> 00:12:58,402
&lrm;硬件、软件 卖给顾客
&lrm;简单良好的商业模式

216
00:12:58.486 --> 00:13:01,447
&lrm;过去十年 硅谷最大的公司

217
00:13:01.530 --> 00:13:03,866
&lrm;一直涉足贩卖他们用户的勾当

218
00:13:03.949 --> 00:13:05,910
&lrm;现在这样说 有点陈词滥调

219
00:13:05.993 --> 00:13:09,205
&lrm;但因为我们不为使用这些产品付钱

220
00:13:09.288 --> 00:13:12,166
&lrm;广告商为我们使用的产品付钱

221
00:13:12.249 --> 00:13:14,084
&lrm;广告商是顾客

222
00:13:14.710 --> 00:13:16,086
&lrm;我们是被销售的商品

223
00:13:16.170 --> 00:13:17,630
&lrm;经典的说法是

224
00:13:17.713 --> 00:13:21,592
&lrm;“如果你没有花钱买产品
&lrm;那你就是被卖的产品”

225
00:13:21.675 --> 00:13:23,302
&lrm;（你就是被卖的产品）

226
00:13:23.385 --> 00:13:27,223
&lrm;很多人想：“谷歌只是一个搜索框

227
00:13:27.306 --> 00:13:29,850
&lrm;脸书只是一个看我朋友们在做什么

228
00:13:29.934 --> 00:13:31,101
&lrm;看他们照片的地方”

229
00:13:31.185 --> 00:13:35,481
&lrm;但他们没有意识到的是
&lrm;他们在竞争你的关注

230
00:13:36.524 --> 00:13:41,111
&lrm;脸书、阅后即焚图片分享、推特
&lrm;Instagram、YouTube

231
00:13:41.195 --> 00:13:45,282
&lrm;这种公司 他们的商业模式
&lrm;是让人们的注意力持续吸引在屏幕上

232
00:13:46.283 --> 00:13:49,578
&lrm;我们来想办法 怎样尽最大可能

233
00:13:49.662 --> 00:13:50,955
&lrm;获得这个人的注意力

234
00:13:51.455 --> 00:13:53,374
&lrm;我们能让你在上面花多少时间？

235
00:13:53.874 --> 00:13:56,669
&lrm;我们能让你给我们分出
&lrm;你人生的多少时间？

236
00:13:58.712 --> 00:14:01,090
&lrm;当你去想 这些公司是怎样运作的

237
00:14:01.173 --> 00:14:02,424
&lrm;就能开始想通了

238
00:14:03.050 --> 00:14:06,095
&lrm;网络上有过各种服务
&lrm;我们都认为是免费的

239
00:14:06.178 --> 00:14:09,473
&lrm;但它们并不是免费的
&lrm;是广告商在付钱

240
00:14:09.557 --> 00:14:11,559
&lrm;广告商为什么给这些公司付钱？

241
00:14:11.642 --> 00:14:14,687
&lrm;它们付钱 交换给你展示广告

242
00:14:14.770 --> 00:14:18,357
&lrm;我们是产品 我们的关注
&lrm;就是卖给广告商的产品

243
00:14:18.816 --> 00:14:20,442
&lrm;这样说 过于简单化了

244
00:14:20.526 --> 00:14:23,654
&lrm;产品其实是我们行为和认知的

245
00:14:23.737 --> 00:14:26,282
&lrm;逐渐的、一点一点的
&lrm;我们未察觉到的变化

246
00:14:26.365 --> 00:14:27,575
&lrm;（行为和认知的 变化）

247
00:14:27.658 --> 00:14:30,244
&lrm;这才是产品 是唯一可能的产品

248
00:14:30.327 --> 00:14:34,081
&lrm;这其中 没有任何东西
&lrm;能再被称为产品了

249
00:14:34.164 --> 00:14:37,251
&lrm;这是他们能拿来赚钱的唯一东西

250
00:14:37.668 --> 00:14:39,253
&lrm;改变你做的事

251
00:14:39.336 --> 00:14:41,714
&lrm;你的思维模式 改变你这个人

252
00:14:42.631 --> 00:14:45,301
&lrm;这是一种逐渐的变化 非常轻微

253
00:14:45.384 --> 00:14:48,971
&lrm;如果你去找一个人
&lrm;你说：“给我一千万美元

254
00:14:49.054 --> 00:14:54,310
&lrm;我会让世界往你希望的方向改变1%…”

255
00:14:54.894 --> 00:14:58,188
&lrm;是整个世界！这就很神奇 值很多钱

256
00:14:59.315 --> 00:15:00,149
&lrm;好

257
00:15:00.691 --> 00:15:04,570
&lrm;这是每种商业都一直梦想的

258
00:15:04.653 --> 00:15:10,910
&lrm;就是投放一个广告
&lrm;有一定能够成功的保证

259
00:15:11.327 --> 00:15:13,996
&lrm;这就是他们的生意
&lrm;他们卖的是确定性

260
00:15:14.079 --> 00:15:14,914
&lrm;（确定性）

261
00:15:14.997 --> 00:15:17,625
&lrm;为了在这个生意中成功

262
00:15:17.708 --> 00:15:19,585
&lrm;你必须要有优秀的预判能力

263
00:15:19.668 --> 00:15:20,544
&lrm;（优秀的预判能力）

264
00:15:20.628 --> 00:15:24,173
&lrm;优秀的预判能力始于一个必要条件

265
00:15:25.215 --> 00:15:26,926
&lrm;你需要很多数据

266
00:15:27.009 --> 00:15:29,053
&lrm;（数据）

267
00:15:29.136 --> 00:15:31,555
&lrm;很多人把它称作监视资本主义

268
00:15:31.639 --> 00:15:34,350
&lrm;资本主义利用大型技术公司
&lrm;对每个人去的每一个地方

269
00:15:34.433 --> 00:15:38,062
&lrm;进行无限追踪获利

270
00:15:38.145 --> 00:15:40,356
&lrm;大型技术公司的商业模式

271
00:15:40.439 --> 00:15:42,858
&lrm;是保证广告商能尽最大可能成功

272
00:15:42.942 --> 00:15:45,569
&lrm;这是现在的一种新市场

273
00:15:45.653 --> 00:15:48,072
&lrm;这种市场 以前从未出现过

274
00:15:48.822 --> 00:15:55,371
&lrm;这个市场交易的 只有人类期货

275
00:15:56.080 --> 00:16:01,585
&lrm;就像交易五花肉期货
&lrm;和石油期货的市场

276
00:16:02.127 --> 00:16:07,591
&lrm;我们现在有了
&lrm;交易大范围人类期货的市场

277
00:16:08.175 --> 00:16:13,472
&lrm;这些市场创造了万亿美元

278
00:16:14.014 --> 00:16:19,269
&lrm;让网络公司成为了人类历史上

279
00:16:19.353 --> 00:16:22,356
&lrm;最富有的公司

280
00:16:27.444 --> 00:16:31,073
&lrm;我想让人们知道的是
&lrm;他们在网上做的一切

281
00:16:31.156 --> 00:16:34,326
&lrm;都被监控着 被追踪着 被评估着

282
00:16:35.035 --> 00:16:39,623
&lrm;你所做出的每一个行为
&lrm;都被小心翼翼地监控着、记录着

283
00:16:39.707 --> 00:16:43,836
&lrm;具体到你停在哪一张图片上看了
&lrm;你看了多久

284
00:16:43.919 --> 00:16:45,796
&lrm;是的 真的 看了多久都记录了

285
00:16:45.879 --> 00:16:47,548
&lrm;（纳维亚 参与时间）

286
00:16:47.631 --> 00:16:49,341
&lrm;（瑞恩 参与时间）

287
00:16:49.425 --> 00:16:50,426
&lrm;（雷恩 参与时间）

288
00:16:50.509 --> 00:16:53,804
&lrm;人们孤独的时候 他们知道
&lrm;人们抑郁的时候 他们知道

289
00:16:53.887 --> 00:16:57,099
&lrm;人们看前任爱侣的时候 他们知道

290
00:16:57.182 --> 00:17:00,853
&lrm;你深夜在做什么 他们知道
&lrm;他们全都知道

291
00:17:01.270 --> 00:17:03,230
&lrm;你是内向还是外向

292
00:17:03.313 --> 00:17:06,817
&lrm;你的神经哪种类型
&lrm;你的性格是哪种类型

293
00:17:08.193 --> 00:17:11,613
&lrm;他们所掌握的我们的信息

294
00:17:11.697 --> 00:17:14,324
&lrm;超越人类历史上所有的想象

295
00:17:14.950 --> 00:17:16,368
&lrm;这是史无前例的

296
00:17:18.579 --> 00:17:22,791
&lrm;所有这些我们不经意间
&lrm;不断流露出的数据

297
00:17:22.875 --> 00:17:26,754
&lrm;都被输入到这些系统中
&lrm;几乎不用人类看管

298
00:17:27.463 --> 00:17:30,883
&lrm;会做出越来越好的预判

299
00:17:30.966 --> 00:17:33,552
&lrm;预判出我们要做什么
&lrm;我们是怎样的人

300
00:17:34.887 --> 00:17:36,346
&lrm;（为您推荐）

301
00:17:36.430 --> 00:17:39,558
&lrm;很多人有一种误解 认为被卖掉的
&lrm;是我们的数据

302
00:17:40.350 --> 00:17:43,187
&lrm;脸书的商业兴趣
&lrm;肯定不是放掉这些数据

303
00:17:45.522 --> 00:17:47,107
&lrm;他们用这些数据做什么呢？

304
00:17:51.070 --> 00:17:54,490
&lrm;他们做出预判我们行为的模型

305
00:17:54.573 --> 00:17:57,618
&lrm;拥有最优秀模型的公司就赢了

306
00:18:02.706 --> 00:18:04,041
&lrm;他向下滑网页的速度慢

307
00:18:04.124 --> 00:18:07,002
&lrm;接近他平均阅读一屏时间长度的末尾
&lrm;减少广告加载

308
00:18:07.086 --> 00:18:08,337
&lrm;把朋友和家人弄回来

309
00:18:09.671 --> 00:18:11,340
&lrm;在屏幕的另一端

310
00:18:11.423 --> 00:18:15,469
&lrm;他们就好像拥有一个
&lrm;我们的巫毒娃娃化身一样

311
00:18:16.845 --> 00:18:18,180
&lrm;我们做过的所有事情

312
00:18:18.263 --> 00:18:19,473
&lrm;点击过的每一个地方

313
00:18:19.556 --> 00:18:21,642
&lrm;我们看过的所有视频
&lrm;点赞过的所有内容

314
00:18:21.725 --> 00:18:25,354
&lrm;这些数据都会被返回去
&lrm;用来建造一个越来越精准的模型

315
00:18:25.896 --> 00:18:27,481
&lrm;一旦有了这个模型

316
00:18:27.564 --> 00:18:29,858
&lrm;就能预判这个人做怎样的事

317
00:18:29.942 --> 00:18:31,777
&lrm;好 让我测试一下

318
00:18:32.569 --> 00:18:33,487
&lrm;你将要去哪里

319
00:18:33.570 --> 00:18:36,115
&lrm;我能预判出
&lrm;你会继续看什么样的视频

320
00:18:36.198 --> 00:18:39,159
&lrm;我能预判
&lrm;什么样的情感更能让你产生共鸣

321
00:18:39.243 --> 00:18:40,410
&lrm;好 完美

322
00:18:41.578 --> 00:18:42,788
&lrm;年度最悲壮失败

323
00:18:43.747 --> 00:18:44,665
&lrm;（悲壮失败）

324
00:18:48.627 --> 00:18:51,088
&lrm;-完美 有效果
&lrm;-接着另一个视频

325
00:18:51.171 --> 00:18:54,049
&lrm;漂亮 在它开始之前
&lrm;我们插进去一个运动鞋广告

326
00:18:56.510 --> 00:18:59,721
&lrm;很多这种技术公司有三个主要目标

327
00:18:59.805 --> 00:19:03,517
&lrm;有一个参与度目标
&lrm;增加你的使用 让你一直滑动屏幕

328
00:19:04.601 --> 00:19:06,145
&lrm;有一个增长目标

329
00:19:06.228 --> 00:19:08,647
&lrm;让你不断回来 尽可能多地邀请朋友

330
00:19:08.730 --> 00:19:10,732
&lrm;让他们再邀请更多的朋友

331
00:19:11.650 --> 00:19:14,987
&lrm;还有一个广告目标
&lrm;确保一切按照预期发展

332
00:19:15.070 --> 00:19:17,406
&lrm;我们尽量多地从广告上挣钱

333
00:19:19.366 --> 00:19:21,994
&lrm;每一个目标都由一个算法驱动

334
00:19:22.077 --> 00:19:24,454
&lrm;算法的作用是找出 给你展示什么

335
00:19:24.538 --> 00:19:26,165
&lrm;让数据上涨

336
00:19:26.623 --> 00:19:29,918
&lrm;我们在脸书 经常聊到这个想法

337
00:19:30.002 --> 00:19:34,006
&lrm;能够按照我们的需要调控

338
00:19:34.673 --> 00:19:38,594
&lrm;我们聊过 让马克来调控

339
00:19:41.305 --> 00:19:44,474
&lrm;“喂 我今天想让韩国的用户增加”

340
00:19:45.684 --> 00:19:46,602
&lrm;开始调控

341
00:19:47.436 --> 00:19:49,188
&lrm;“我们调控提高一点广告”

342
00:19:49.980 --> 00:19:51,732
&lrm;“调控提高一点盈利”

343
00:19:52.858 --> 00:19:55,444
&lrm;所以说…

344
00:19:55.527 --> 00:19:59,239
&lrm;所有这些公司
&lrm;都能做到这种程度的精准

345
00:19:59.990 --> 00:20:02,409
&lrm;-兄弟 怎么…
&lrm;-我不知道我怎么没有得到黄牌罚下

346
00:20:02.492 --> 00:20:05,704
&lrm;-那个裁判真是逊
&lrm;-真的是一直…

347
00:20:05.787 --> 00:20:07,956
&lrm;-那是瑞贝卡 去和她说话
&lrm;-我知道那是谁

348
00:20:08.040 --> 00:20:10,834
&lrm;-兄弟 去啊 去跟她说话
&lrm;-我正在努力

349
00:20:10.918 --> 00:20:14,171
&lrm;他的日历上说 他正在休假
&lrm;我们应该实时操作 

350
00:20:15.255 --> 00:20:16,465
&lrm;要我给他发一个窗口抖动吗？

351
00:20:17.132 --> 00:20:18,050
&lrm;好 抖吧

352
00:20:21.720 --> 00:20:24,181
&lrm;“您的好友泰勒刚刚加入了
&lrm;去挥手打个招呼吧”

353
00:20:26.016 --> 00:20:27,184
&lrm;快啊 兄弟

354
00:20:27.267 --> 00:20:28,769
&lrm;发一个挥手

355
00:20:29.394 --> 00:20:31,647
&lrm;你都没有… 去和她说话 兄弟

356
00:20:31.730 --> 00:20:34,900
&lrm;您的好友泰勒刚刚加入了！
&lrm;挥手打个招呼吧

357
00:20:36.902 --> 00:20:37,986
&lrm;（联系人网络）

358
00:20:38.070 --> 00:20:40,447
&lrm;新联系人！好 连上了

359
00:20:40.948 --> 00:20:46,078
&lrm;接下来推送
&lrm;用户079044238820瑞贝卡的发帖

360
00:20:46.161 --> 00:20:49,790
&lrm;好主意 卫星定位坐标显示
&lrm;他们距离很近

361
00:20:52.167 --> 00:20:55,837
&lrm;（瑞贝卡 找到了我的灵魂伴侣
&lrm;#闺蜜#呲溜呲溜#好朋友）

362
00:20:55.921 --> 00:20:57,172
&lrm;他容易受到广告影响

363
00:20:57.631 --> 00:20:58,632
&lrm;拍卖时间

364
00:20:58.715 --> 00:21:00,050
&lrm;（广告预览 深度衰落发蜡）

365
00:21:00.133 --> 00:21:02,803
&lrm;卖了！给深度衰落发蜡

366
00:21:03.387 --> 00:21:07,933
&lrm;我们有468个感兴趣的竞标人
&lrm;我们以3.262分卖给本 换来他的印象

367
00:21:17.109 --> 00:21:21,530
&lrm;我们创造了一个世界
&lrm;这个世界中 在线联系变成了主体

368
00:21:22.072 --> 00:21:23,907
&lrm;尤其是对年轻一代

369
00:21:23.991 --> 00:21:28,328
&lrm;然而在这个世界 每次两个人联系

370
00:21:29.162 --> 00:21:33,250
&lrm;唯一能提供经济支持的
&lrm;是通过一个鬼祟的第三方

371
00:21:33.333 --> 00:21:35,627
&lrm;有人给第三方钱 去操纵这两个人

372
00:21:36.128 --> 00:21:39,381
&lrm;所以 我们创造了全球的一整代人

373
00:21:39.464 --> 00:21:44,011
&lrm;他们成长的背景中 交流的意义

374
00:21:44.094 --> 00:21:47,431
&lrm;文化的意义 就是操纵

375
00:21:47.514 --> 00:21:49,725
&lrm;我们所做的每一件事的中心

376
00:21:49.808 --> 00:21:52,311
&lrm;都加入了欺骗和鬼祟

377
00:21:56.356 --> 00:22:01,445
&lrm;（“任何足够先进的技术
&lrm;都极其类似于魔术”）

378
00:22:01.528 --> 00:22:05,657
&lrm;（——亚瑟·C·克拉克）

379
00:22:05.741 --> 00:22:07,242
&lrm;-拿起另一个…
&lrm;-好

380
00:22:07.326 --> 00:22:09,369
&lrm;-放在哪里才有用？
&lrm;-这样很好

381
00:22:09.453 --> 00:22:10,620
&lrm;-这里？
&lrm;-好

382
00:22:10.704 --> 00:22:13,707
&lrm;这会怎样出现在摄影机中
&lrm;如果我要做…

383
00:22:13.790 --> 00:22:15,459
&lrm;-其实 我们可以…
&lrm;-就这样？

384
00:22:15.542 --> 00:22:16,835
&lrm;-什么？
&lrm;-对

385
00:22:16.918 --> 00:22:18,462
&lrm;-再来一次？
&lrm;-没错 好

386
00:22:19.046 --> 00:22:20,589
&lrm;对 不是 可能不是…

387
00:22:20.672 --> 00:22:21,965
&lrm;这样… 对

388
00:22:22.466 --> 00:22:23,884
&lrm;这个就稍微没那么…

389
00:22:31.016 --> 00:22:33,268
&lrm;克里斯在那边已经烦死了

390
00:22:34.728 --> 00:22:35,562
&lrm;可以了吗？

391
00:22:35.645 --> 00:22:37,773
&lrm;（魔术！）

392
00:22:37.856 --> 00:22:41,068
&lrm;我从五岁开始学习变魔术

393
00:22:41.151 --> 00:22:45,781
&lrm;我可以骗过成年人
&lrm;有博士学位的完全成熟的成年人

394
00:22:55.040 --> 00:22:57,709
&lrm;魔术师几乎像是最早期的神经学家

395
00:22:57.793 --> 00:22:58,960
&lrm;和心理学家

396
00:22:59.044 --> 00:23:02,005
&lrm;他们是最先明白

397
00:23:02.089 --> 00:23:03,382
&lrm;人们思想工作原理的人

398
00:23:04.216 --> 00:23:07,677
&lrm;他们在人们身上
&lrm;实时测试着很多很多的东西

399
00:23:09.137 --> 00:23:11,139
&lrm;魔术师懂一些事

400
00:23:11.223 --> 00:23:14,017
&lrm;你思想中
&lrm;你自己都没意识到的某一部分

401
00:23:14.101 --> 00:23:15,936
&lrm;这是让幻觉起作用的关键

402
00:23:16.019 --> 00:23:20,607
&lrm;医生、律师
&lrm;知道怎样构造747飞机或者核弹的人

403
00:23:20.690 --> 00:23:24,361
&lrm;他们并不会比别人更了解
&lrm;自己的思想有多么脆弱

404
00:23:24.444 --> 00:23:26,113
&lrm;因为这是一个完全不用的学科领域

405
00:23:26.571 --> 00:23:28,990
&lrm;这个学科领域 对所有人类都适用

406
00:23:29.074 --> 00:23:30,909
&lrm;（斯坦福大学）

407
00:23:30.992 --> 00:23:34,079
&lrm;从这个角度来说
&lrm;你就能对技术做了什么

408
00:23:34.162 --> 00:23:35,580
&lrm;有一个不同的理解

409
00:23:36.873 --> 00:23:41,044
&lrm;我在斯坦福劝服技术实验室的时候
&lrm;这就是我们所学到的

410
00:23:41.628 --> 00:23:43,463
&lrm;怎样利用我们知道的一切心理学知识

411
00:23:43.547 --> 00:23:45,882
&lrm;什么东西能劝服人们

412
00:23:45.966 --> 00:23:48,385
&lrm;把这个运用到技术中？

413
00:23:48.468 --> 00:23:50,887
&lrm;在座观众中的很多人 已经是天才了

414
00:23:50.971 --> 00:23:55,851
&lrm;我认为这是事实 但我的目标是
&lrm;让你们变成行为改变的天才

415
00:23:56.852 --> 00:24:01,148
&lrm;很多著名的硅谷人物
&lrm;都上过这个课

416
00:24:01.231 --> 00:24:05,485
&lrm;脸书、优步和其他公司的
&lrm;业绩增长关键人物

417
00:24:05.569 --> 00:24:09,197
&lrm;学习怎样让技术更能劝服人们

418
00:24:09.614 --> 00:24:10,782
&lrm;特里斯坦就是其中一个

419
00:24:12.284 --> 00:24:14,619
&lrm;劝服性技术 可以说是极端应用的

420
00:24:14.703 --> 00:24:16,580
&lrm;刻意设计

421
00:24:16.663 --> 00:24:18,874
&lrm;我们真的想去修改一个人的行为

422
00:24:18.957 --> 00:24:20,542
&lrm;我们想让他们这样做

423
00:24:20.625 --> 00:24:23,336
&lrm;我们想让他们继续用手指这样做

424
00:24:23.420 --> 00:24:26,256
&lrm;你往下拉 刷新 最上面就是新的内容

425
00:24:26.339 --> 00:24:28,508
&lrm;再下拉 再刷新 又是新的
&lrm;每一次都是

426
00:24:28.592 --> 00:24:33,722
&lrm;在心理学上 我们称为“正积极强化”

427
00:24:33.805 --> 00:24:37,142
&lrm;你不知道什么时候能刷到
&lrm;或者你是否能刷到什么

428
00:24:37.225 --> 00:24:40,061
&lrm;它的原理就像是赌城的老虎机

429
00:24:40.145 --> 00:24:42,230
&lrm;你有意识地使用产品 还远远不够

430
00:24:42.314 --> 00:24:44,024
&lrm;我想深度侵入你的大脑根部

431
00:24:44.107 --> 00:24:47,652
&lrm;在你脑中植入一个无意识的习惯

432
00:24:47.736 --> 00:24:50,864
&lrm;让你在更深的层次被编程

433
00:24:50.947 --> 00:24:52,115
&lrm;你自己都没有意识到

434
00:24:52.532 --> 00:24:54,034
&lrm;一个叫做詹姆斯·马歇尔的人

435
00:24:54.117 --> 00:24:56,286
&lrm;每一次你在看到老虎机在柜台上

436
00:24:56.369 --> 00:24:59,789
&lrm;你看一眼 你知道如果你过去

437
00:24:59.873 --> 00:25:01,333
&lrm;它可能有东西给你

438
00:25:01.416 --> 00:25:03,877
&lrm;于是你就玩了一下老虎机
&lrm;看你能得到什么 对吧？

439
00:25:03.960 --> 00:25:06,046
&lrm;这不是偶然 这是设计好的手段

440
00:25:06.129 --> 00:25:11,134
&lrm;他把一个金块
&lrm;给了旧金山军队的一个军官

441
00:25:12.219 --> 00:25:15,388
&lrm;别忘了 旧金山的人口数量
&lrm;当时只有…

442
00:25:15.472 --> 00:25:17,432
&lrm;另一个例子是照片圈人

443
00:25:19.726 --> 00:25:24,064
&lrm;如果你收到一封邮件
&lrm;说你朋友刚刚在一张照片中圈出了你

444
00:25:24.147 --> 00:25:28,568
&lrm;你当然会点击那封邮件 看一下照片

445
00:25:29.152 --> 00:25:31,821
&lrm;这不是你能选择忽略的事情

446
00:25:32.364 --> 00:25:36,326
&lrm;他们所利用的
&lrm;是根植于人类本性中的东西

447
00:25:36.409 --> 00:25:38,078
&lrm;你应该问自己的是

448
00:25:38.161 --> 00:25:40,288
&lrm;“这封邮件中
&lrm;为什么没把照片放进来？

449
00:25:40.372 --> 00:25:42,457
&lrm;这样 看照片就会容易很多 ”

450
00:25:42.541 --> 00:25:45,919
&lrm;当脸书发现这个功能之后
&lrm;他们可真是尽情调控

451
00:25:46.002 --> 00:25:48,505
&lrm;因为他们说
&lrm;“这将是增长积极性的绝好方式

452
00:25:48.588 --> 00:25:51,091
&lrm;我们让大家整天在照片中互相圈吧”

453
00:25:56.263 --> 00:25:58,890
&lrm;（本：至少我们中
&lrm;有一个人拍得很好）

454
00:25:59.349 --> 00:26:00,475
&lrm;他评论了

455
00:26:00.559 --> 00:26:01,434
&lrm;很好

456
00:26:01.935 --> 00:26:04,688
&lrm;瑞贝卡收到了 她正在回复

457
00:26:04.771 --> 00:26:07,566
&lrm;好 让本知道她在输入 别让他下线了

458
00:26:07.649 --> 00:26:08,733
&lrm;激活省略号

459
00:26:09.234 --> 00:26:13,613
&lrm;（至少我们中有一个人拍得很好
&lrm;…）

460
00:26:19.411 --> 00:26:20,745
&lrm;太好了 她发布了

461
00:26:21.454 --> 00:26:24,249
&lrm;他在评论 他给她发帖的评论的评论

462
00:26:25.041 --> 00:26:26,418
&lrm;等一下 他停止输入了

463
00:26:26.751 --> 00:26:27,752
&lrm;我们来自动填入

464
00:26:28.420 --> 00:26:30,005
&lrm;表情 他喜欢使用表情

465
00:26:31.381 --> 00:26:33,758
&lrm;（自动完成 参与度）

466
00:26:33.842 --> 00:26:34,676
&lrm;他选择了“火辣”表情

467
00:26:35.427 --> 00:26:36,803
&lrm;我以为他会选择茄子呢

468
00:26:38.597 --> 00:26:42,726
&lrm;有一整个学科
&lrm;这个领域叫做“增长量黑客学”

469
00:26:42.809 --> 00:26:47,147
&lrm;无数工程师团队
&lrm;他们的工作就是黑入人们的心理

470
00:26:47.230 --> 00:26:48,565
&lrm;让他们拥有更多的增长量

471
00:26:48.648 --> 00:26:50,984
&lrm;他们能得到更多的用户注册
&lrm;更高的参与度

472
00:26:51.067 --> 00:26:52,861
&lrm;能让你邀请更多人

473
00:26:52.944 --> 00:26:55,989
&lrm;各种测试、迭代 种种操作之后

474
00:26:56.072 --> 00:26:57,907
&lrm;知道我们发现最重要现象是什么吗？

475
00:26:57.991 --> 00:26:59,826
&lrm;让任何个体在十天内邀请七个朋友

476
00:26:59.909 --> 00:27:01,870
&lrm;（查马斯·帕里哈皮提亚
&lrm;脸书前增长副总裁）

477
00:27:01.953 --> 00:27:02,787
&lrm;就是这个

478
00:27:02.871 --> 00:27:05,498
&lrm;查马斯是脸书早期的增长负责人

479
00:27:05.582 --> 00:27:08,251
&lrm;他在技术领域非常知名

480
00:27:08.335 --> 00:27:11,004
&lrm;因为他首创了很多增长手段

481
00:27:11.087 --> 00:27:14,758
&lrm;这些手段的使用
&lrm;让脸书用户飞速增长

482
00:27:14.841 --> 00:27:18,553
&lrm;后来那些增长手段
&lrm;变成了硅谷的标准战术

483
00:27:18.637 --> 00:27:21,222
&lrm;在优步使用了
&lrm;在很多其他公司也使用了

484
00:27:21.306 --> 00:27:27,062
&lrm;他首创的一个东西
&lrm;就是对功能上的小变化

485
00:27:27.145 --> 00:27:28,480
&lrm;使用科学A/B测试

486
00:27:29.022 --> 00:27:30,940
&lrm;谷歌和脸书这种公司

487
00:27:31.024 --> 00:27:34,569
&lrm;会推出很多小实验 

488
00:27:34.653 --> 00:27:36,821
&lrm;他们不断在用户身上测试

489
00:27:36.905 --> 00:27:39,866
&lrm;随着时间发展
&lrm;不停运行这些实验之后

490
00:27:39.949 --> 00:27:43,036
&lrm;就能发展出能让用户
&lrm;做你想让他们做的事

491
00:27:43.119 --> 00:27:45,288
&lrm;的最佳方式

492
00:27:45.372 --> 00:27:46,790
&lrm;这就是操纵

493
00:27:47.332 --> 00:27:49,209
&lrm;你让我感觉自己像是实验室的小白鼠

494
00:27:49.834 --> 00:27:51,920
&lrm;你就是实验室的小白鼠
&lrm;我们所有人都是

495
00:27:52.545 --> 00:27:55,548
&lrm;我们和开发治愈癌症药物的
&lrm;实验室小白鼠又不一样

496
00:27:55.632 --> 00:27:58,134
&lrm;这些实验的最终获益人 不是我们

497
00:27:58.218 --> 00:28:01,680
&lrm;对吧？我们就像僵尸一样
&lrm;他们想让我们看更多的广告

498
00:28:01.763 --> 00:28:03,181
&lrm;让他们挣更多的钱

499
00:28:03.556 --> 00:28:08,228
&lrm;脸书做了一个实验
&lrm;他们称为“海量规模蔓延实验”

500
00:28:08.311 --> 00:28:09,145
&lrm;好吧

501
00:28:09.229 --> 00:28:12,857
&lrm;我们怎样用脸书页面上的潜意识信号

502
00:28:13.400 --> 00:28:17,570
&lrm;来让更多人在中期选举中投票？

503
00:28:17.987 --> 00:28:20,824
&lrm;他们发现 他们能做到

504
00:28:20.907 --> 00:28:24,160
&lrm;他们得出的一个结论是
&lrm;现在我们知道

505
00:28:24.744 --> 00:28:28,915
&lrm;我们能影响现实世界中的行为和情感

506
00:28:28.998 --> 00:28:32,877
&lrm;而根本不用触发用户的意识

507
00:28:33.378 --> 00:28:37,382
&lrm;他们自己完全不知道

508
00:28:38.049 --> 00:28:41,970
&lrm;我们将这些人工智能引擎
&lrm;指回到我们身上

509
00:28:42.053 --> 00:28:46,224
&lrm;来反向编程 什么能引诱我们的回应

510
00:28:47.100 --> 00:28:49,561
&lrm;就很像你在蜘蛛身上模拟神经细胞

511
00:28:49.644 --> 00:28:51,479
&lrm;来看是什么引起它的腿反应

512
00:28:51.938 --> 00:28:53,940
&lrm;就是这种监狱实验

513
00:28:54.023 --> 00:28:56,735
&lrm;我们在实验中 捆绑人们进入矩阵

514
00:28:56.818 --> 00:29:01,489
&lrm;我们从他们的行为中获取金钱和数据
&lrm;用他们的行为牟利

515
00:29:01.573 --> 00:29:03,450
&lrm;我们甚至都不知道 发生了这些

516
00:29:04.117 --> 00:29:07,912
&lrm;我们想在心理学上弄清楚
&lrm;怎样以最快的速度操纵你

517
00:29:07.996 --> 00:29:10,081
&lrm;然后返回给你让你产生兴奋的事物

518
00:29:10.165 --> 00:29:12,542
&lrm;我们在脸书做得非常出色

519
00:29:12.625 --> 00:29:14,919
&lrm;Instagram也这样做了
&lrm;WhatsApp也这样做了

520
00:29:15.003 --> 00:29:17,380
&lrm;阅后即焚图片分享也这样做了
&lrm;推特也这样做了

521
00:29:17.464 --> 00:29:19,424
&lrm;这种东西正是

522
00:29:19.507 --> 00:29:22,427
&lrm;我这种黑客能想出来的

523
00:29:22.510 --> 00:29:27,015
&lrm;因为你在利用人类心理中的脆弱挣钱

524
00:29:27.098 --> 00:29:28,725
&lrm;（希恩·帕克 脸书前总经理）

525
00:29:28.808 --> 00:29:33,438
&lrm;我只是想 我们这些发明者、创造者…

526
00:29:33.980 --> 00:29:37,317
&lrm;有我 有马克 有…

527
00:29:37.400 --> 00:29:40,403
&lrm;Instagram的凯文·斯特罗姆
&lrm;所有这些人…

528
00:29:41.154 --> 00:29:46,451
&lrm;意识里非常清楚 但我们依然利用了

529
00:29:50.580 --> 00:29:53,750
&lrm;自行车问世的时候 没有人不满

530
00:29:55.043 --> 00:29:58,004
&lrm;对吧？所有人都开始用自行车出行

531
00:29:58.087 --> 00:30:00,924
&lrm;没有人说
&lrm;“天啊 我们刚刚毁掉了社会

532
00:30:01.007 --> 00:30:03,051
&lrm;因为自行车能影响人

533
00:30:03.134 --> 00:30:05,303
&lrm;拉远了他们和孩子间的距离

534
00:30:05.386 --> 00:30:08,723
&lrm;他们在毁掉民主的结构
&lrm;人们无法判断真假了”

535
00:30:08.807 --> 00:30:11,476
&lrm;对于自行车
&lrm;我们从来没有说过这种话

536
00:30:12.769 --> 00:30:16,147
&lrm;如果一个东西是工具
&lrm;它就会忠诚地坐在那里

537
00:30:16.731 --> 00:30:18,733
&lrm;耐心等待

538
00:30:19.317 --> 00:30:22,821
&lrm;如果一个东西不是工具
&lrm;它会在你身上有所求

539
00:30:22.904 --> 00:30:26,533
&lrm;引诱你、操纵你 想从你身上获利

540
00:30:26.950 --> 00:30:30,495
&lrm;我们已经走过了
&lrm;以工具为基础的技术环境

541
00:30:31.037 --> 00:30:34,499
&lrm;来到了以致瘾和操纵
&lrm;为基础的技术环境

542
00:30:34.582 --> 00:30:35,708
&lrm;这是技术环境的改变

543
00:30:35.792 --> 00:30:39,420
&lrm;社交媒体
&lrm;不是原地等在那里被使用的工具

544
00:30:39.504 --> 00:30:43,466
&lrm;它有自己的目标
&lrm;有自己的办法去实现这些目标

545
00:30:43.550 --> 00:30:45,677
&lrm;利用你的心理 来对付你

546
00:30:49.055 --> 00:30:52,517
&lrm;（“只有两个行业
&lrm;把他们的客户叫做‘使用者’

547
00:30:52.600 --> 00:30:55,562
&lrm;非法毒品和软件”）

548
00:30:55.645 --> 00:30:57,480
&lrm;（——爱德华·塔夫特）

549
00:30:57.564 --> 00:31:02,193
&lrm;回想几年之前
&lrm;我是Pinterest的总经理

550
00:31:03.152 --> 00:31:08,366
&lrm;我回到家 到家之后就无法放下手机

551
00:31:08.449 --> 00:31:12,161
&lrm;虽然我有两个小孩子 需要我的关爱

552
00:31:12.245 --> 00:31:15,748
&lrm;我在食物储藏室里打字回邮件

553
00:31:15.832 --> 00:31:17,542
&lrm;有时候会看Pinterest

554
00:31:18.001 --> 00:31:19,627
&lrm;我想：“天啊 这真是典型的讽刺

555
00:31:19.711 --> 00:31:22,046
&lrm;我白天去工作

556
00:31:22.130 --> 00:31:26,426
&lrm;构造一个把我当猎物的东西”

557
00:31:26.509 --> 00:31:30,096
&lrm;我无法… 有时候
&lrm;我真的情不自禁使用

558
00:31:32.307 --> 00:31:36,102
&lrm;我最无法摆脱的是推特

559
00:31:36.728 --> 00:31:38,021
&lrm;以前无法摆脱的是Reddit

560
00:31:38.104 --> 00:31:42,859
&lrm;我后来不得不给自己写程序
&lrm;来切断我阅读Reddit的瘾

561
00:31:45.403 --> 00:31:47,780
&lrm;我最成瘾的 可能是邮件

562
00:31:47.864 --> 00:31:49,866
&lrm;真的 我是认真的 我自己能感觉到

563
00:31:52.577 --> 00:31:54,954
&lrm;这很有趣

564
00:31:55.038 --> 00:31:58,166
&lrm;我很清楚 这一切的幕后发生着什么

565
00:31:58.249 --> 00:32:01,628
&lrm;我还是无法控制自己去使用

566
00:32:01.711 --> 00:32:03,046
&lrm;这就有点可怕了

567
00:32:03.630 --> 00:32:07,050
&lrm;即便知道这些手段的原理
&lrm;我还是容易受到它们影响

568
00:32:07.133 --> 00:32:09,886
&lrm;我拿起手机
&lrm;20分钟就不知不觉过去了

569
00:32:12.805 --> 00:32:15,725
&lrm;你晨起排尿之前
&lrm;会看一眼智能手机吗？

570
00:32:15.808 --> 00:32:17,477
&lrm;或者晨起排尿过程中 会看吗？

571
00:32:17.560 --> 00:32:19,479
&lrm;因为只有这两个选择

572
00:32:19.562 --> 00:32:23,274
&lrm;我试过用意志力克制 纯意志力…

573
00:32:23.358 --> 00:32:26,903
&lrm;“我要放下手机
&lrm;我到家之后 要把手机丢在车里”

574
00:32:26.986 --> 00:32:30,573
&lrm;我应该在千万个不同的日子
&lrm;告诉过自己千万次

575
00:32:30.657 --> 00:32:32,617
&lrm;“我不要把手机带到卧室”

576
00:32:32.700 --> 00:32:34,535
&lrm;然后晚上九点到了

577
00:32:34.619 --> 00:32:37,121
&lrm;“哎 我想把手机带进卧室”

578
00:32:37.956 --> 00:32:39,290
&lrm;这就有点…

579
00:32:39.374 --> 00:32:41,125
&lrm;意志力是一种努力

580
00:32:41.209 --> 00:32:44,295
&lrm;兽性在做着另一种努力

581
00:32:44.379 --> 00:32:45,880
&lrm;隆重介绍“厨房保险箱”

582
00:32:45.964 --> 00:32:49,801
&lrm;“厨房保险箱”是革命性的全新发明
&lrm;帮你战胜诱惑的

583
00:32:49.884 --> 00:32:51,678
&lrm;时间锁保鲜盒

584
00:32:51.761 --> 00:32:56,724
&lrm;大卫只需要把各种诱惑
&lrm;放进这个“厨房保险箱”

585
00:32:57.392 --> 00:33:00,561
&lrm;下一步 进行调控 设置时间

586
00:33:01.479 --> 00:33:04,232
&lrm;最后 按下调控 激活锁

587
00:33:04.315 --> 00:33:05,525
&lrm;“厨房保险箱”超级好

588
00:33:05.608 --> 00:33:06,776
&lrm;我们家有 是吧？

589
00:33:06.859 --> 00:33:08,569
&lrm;…电子游戏、信用卡、手机

590
00:33:08.653 --> 00:33:09,654
&lrm;对 有

591
00:33:09.737 --> 00:33:11,072
&lrm;“厨房保险箱”一旦上锁

592
00:33:11.155 --> 00:33:13,866
&lrm;直到计时器归零之前 没办法打开

593
00:33:13.950 --> 00:33:17,537
&lrm;问题是 社交媒体就是一种毒品

594
00:33:17.620 --> 00:33:20,873
&lrm;我们有着基本的生物学欲望

595
00:33:20.957 --> 00:33:23,084
&lrm;去和别人联系

596
00:33:23.167 --> 00:33:28,214
&lrm;这直接影响着
&lrm;奖赏通路中的多巴胺释放

597
00:33:28.297 --> 00:33:32,552
&lrm;这个机制背后 是几百万年的进化

598
00:33:32.635 --> 00:33:35,596
&lrm;让我们聚在一起 群居生活

599
00:33:35.680 --> 00:33:38,016
&lrm;找到伴侣 繁殖我们的物种

600
00:33:38.099 --> 00:33:41,853
&lrm;所以 毫无疑问 社交媒体这种载体

601
00:33:41.936 --> 00:33:45,690
&lrm;它会优化人们之间的联系

602
00:33:45.773 --> 00:33:48,568
&lrm;自然会有致瘾的可能性

603
00:33:52.780 --> 00:33:54,115
&lrm;爸 停！

604
00:33:55.450 --> 00:33:58,453
&lrm;我在晚饭前 还有上千个消息要回

605
00:33:58.536 --> 00:33:59,537
&lrm;消息？

606
00:33:59.620 --> 00:34:01,080
&lrm;我不知道消息是什么

607
00:34:01.164 --> 00:34:03,207
&lrm;-闻起来好香 宝贝
&lrm;-谢谢

608
00:34:03.291 --> 00:34:05,877
&lrm;我想 我们可以用所有五官

609
00:34:05.960 --> 00:34:07,712
&lrm;来享受今晚的晚餐

610
00:34:07.795 --> 00:34:11,382
&lrm;所以我决定
&lrm;今晚的餐桌上不能使用手机

611
00:34:11.466 --> 00:34:13,301
&lrm;好了 交上来

612
00:34:13.801 --> 00:34:14,802
&lrm;-真的吗？
&lrm;-是

613
00:34:15.928 --> 00:34:18,056
&lrm;-好吧
&lrm;-谢谢 本？

614
00:34:18.139 --> 00:34:19,891
&lrm;-好
&lrm;-妈妈是手机海盗

615
00:34:21.100 --> 00:34:21,934
&lrm;-拿走了
&lrm;-妈！

616
00:34:22.602 --> 00:34:26,147
&lrm;晚餐结束前
&lrm;这些手机会安全地放在这里

617
00:34:27.273 --> 00:34:31,277
&lrm;所有人可以安静待着了 好吗？

618
00:34:47.418 --> 00:34:49,253
&lrm;-我能看一眼是谁吗？
&lrm;-不行

619
00:34:54.759 --> 00:34:56,969
&lrm;我去再拿一个叉子

620
00:34:58.304 --> 00:34:59,263
&lrm;谢谢

621
00:35:04.727 --> 00:35:06,771
&lrm;宝贝 不能打开

622
00:35:06.854 --> 00:35:08,856
&lrm;我锁上了一个小时 别动了

623
00:35:11.192 --> 00:35:13,361
&lrm;我们要聊点什么？

624
00:35:13.444 --> 00:35:17,907
&lrm;我们可以聊聊我今天开车
&lrm;身边经过的极端中心政党疯子

625
00:35:17.990 --> 00:35:18,825
&lrm;-算了 弗兰科
&lrm;-怎么了？

626
00:35:18.908 --> 00:35:20,785
&lrm;我不想聊政治

627
00:35:20.868 --> 00:35:23,538
&lrm;-极端中心怎么了？
&lrm;-看吧？他都没明白

628
00:35:23.621 --> 00:35:24,622
&lrm;取决于你问谁

629
00:35:24.705 --> 00:35:26,624
&lrm;这就像是你问：“政治鼓吹怎么了？”

630
00:35:28.709 --> 00:35:29,710
&lrm;艾拉！

631
00:35:32.797 --> 00:35:33,756
&lrm;天啊

632
00:35:37.135 --> 00:35:38,553
&lrm;-需要我去…
&lrm;-嗯

633
00:35:41.973 --> 00:35:43,933
&lrm;我很担心我的孩子们

634
00:35:44.016 --> 00:35:46,686
&lrm;等你们有了孩子
&lrm;我还会担心你们的孩子

635
00:35:46.769 --> 00:35:50,189
&lrm;虽然我有着各种知识储备 各种经验

636
00:35:50.273 --> 00:35:52,108
&lrm;我还是和孩子们争论

637
00:35:52.191 --> 00:35:54,443
&lrm;他们使用手机和电脑的时间

638
00:35:54.527 --> 00:35:58,197
&lrm;我会对我儿子说
&lrm;“你觉得自己会在手机上花多久？”

639
00:35:58.281 --> 00:36:01,075
&lrm;他会说
&lrm;“也就半小时吧 最多半小时了”

640
00:36:01.159 --> 00:36:04,871
&lrm;我觉得比一小时多一点 一个半小时

641
00:36:04.954 --> 00:36:06,789
&lrm;几周之前看了他的屏幕使用报告

642
00:36:06.873 --> 00:36:08,708
&lrm;-是3小时45分
&lrm;-那不是…

643
00:36:11.377 --> 00:36:13,588
&lrm;我觉得没有… 平均每天？

644
00:36:13.671 --> 00:36:15,506
&lrm;-对
&lrm;-我现在去拿来吗？

645
00:36:15.590 --> 00:36:19,177
&lrm;每一天 我都要提醒我的孩子们

646
00:36:19.260 --> 00:36:21,762
&lrm;愉悦和痛苦的平衡

647
00:36:21.846 --> 00:36:26,267
&lrm;多巴胺短缺的状态 上瘾的风险

648
00:36:26.350 --> 00:36:27,310
&lrm;-对
&lrm;-来揭晓真相

649
00:36:27.935 --> 00:36:29,687
&lrm;每天2小时50分

650
00:36:29.770 --> 00:36:31,772
&lrm;-我们看看
&lrm;-其实 我今天用了很多

651
00:36:31.856 --> 00:36:33,357
&lrm;-过去七天
&lrm;-可能这就是原因

652
00:36:33.441 --> 00:36:37,153
&lrm;Instagram 6小时13分
&lrm;好吧 我使用Instagram是最严重的

653
00:36:39.572 --> 00:36:43,201
&lrm;我的屏幕彻底碎了 谢谢你 卡桑

654
00:36:44.410 --> 00:36:45,995
&lrm;“谢谢你 卡桑”是什么意思？

655
00:36:46.078 --> 00:36:49,290
&lrm;你一直让妈妈担心我们的手机问题
&lrm;但其实这根本不是问题

656
00:36:49.373 --> 00:36:51,167
&lrm;我们吃晚餐不需要手机

657
00:36:51.250 --> 00:36:54,170
&lrm;我明白你说的
&lrm;但这又不是什么大事 没什么啊

658
00:36:56.047 --> 00:36:58,382
&lrm;不是什么大事 那就一周别用手机

659
00:37:01.135 --> 00:37:02,178
&lrm;对

660
00:37:02.261 --> 00:37:06,349
&lrm;对 其实 如果你能把那东西
&lrm;收起来一整周…

661
00:37:07.725 --> 00:37:09,518
&lrm;我就给你买一个新的屏幕

662
00:37:11.062 --> 00:37:12,772
&lrm;-从现在开始吗？
&lrm;-现在开始

663
00:37:15.274 --> 00:37:16,859
&lrm;好 成交

664
00:37:16.943 --> 00:37:19,111
&lrm;好 不过你要放在这里 小朋友

665
00:37:19.862 --> 00:37:21,364
&lrm;好 我把它放进去

666
00:37:22.531 --> 00:37:25,076
&lrm;计时开始 我退后了

667
00:37:25.159 --> 00:37:25,993
&lrm;好

668
00:37:27.703 --> 00:37:29,413
&lrm;-计时开始了
&lrm;-一周

669
00:37:29.497 --> 00:37:30,331
&lrm;天啊…

670
00:37:31.457 --> 00:37:32,458
&lrm;你觉得他能做到吗？

671
00:37:33.000 --> 00:37:34,252
&lrm;不知道 走着瞧

672
00:37:35.002 --> 00:37:36,128
&lrm;你吃饭吧 好吗？

673
00:37:44.220 --> 00:37:45,263
&lrm;美好的家庭晚餐！

674
00:37:47.682 --> 00:37:49,809
&lrm;这些技术产品不是由

675
00:37:49.892 --> 00:37:53,896
&lrm;努力保护和培育孩子的
&lrm;儿童心理学家设计的

676
00:37:53.980 --> 00:37:56,148
&lrm;它们的设计 是让这些算法

677
00:37:56.232 --> 00:37:58,734
&lrm;非常擅于给你推荐下一个视频

678
00:37:58.818 --> 00:38:02,321
&lrm;非常擅于让你拍照加滤镜

679
00:38:03.072 --> 00:38:05,324
&lrm;（两个赞）

680
00:38:13.291 --> 00:38:15,126
&lrm;（确定删除吗？否）

681
00:38:15.209 --> 00:38:16,210
&lrm;（是）

682
00:38:16.752 --> 00:38:20,256
&lrm;这些东西不仅在控制
&lrm;他们把注意力花在哪里

683
00:38:21.173 --> 00:38:26,304
&lrm;尤其是社交媒体越来越深入大脑根部

684
00:38:26.387 --> 00:38:29,765
&lrm;夺走孩子们的判断力
&lrm;自我价值和身份

685
00:38:29.849 --> 00:38:31,851
&lrm;（美化我）

686
00:38:42.069 --> 00:38:43,112
&lrm;（莉莉：可爱！）

687
00:38:43.195 --> 00:38:44,822
&lrm;（索薇娅：天啊 好美）

688
00:38:44.905 --> 00:38:46,490
&lrm;（奥利维亚：你太美了）

689
00:38:46.574 --> 00:38:48,200
&lrm;（阿瓦：你把耳朵P大了吗？）

690
00:38:48.284 --> 00:38:49,118
&lrm;（哈哈）

691
00:38:52.496 --> 00:38:55,499
&lrm;我们进化出
&lrm;在意我们社群中的其他人…

692
00:38:55.583 --> 00:38:56,667
&lrm;（布里亚纳：漂亮！）

693
00:38:56.751 --> 00:38:59,128
&lrm;…是否对我们有好印象的机制
&lrm;因为这很重要

694
00:38:59.837 --> 00:39:04,550
&lrm;但我们的进化 需要我们在意
&lrm;一万个人怎么看我们吗？

695
00:39:04.633 --> 00:39:05,885
&lrm;我们的进化

696
00:39:05.968 --> 00:39:10,348
&lrm;不需要每隔五分钟
&lrm;就获得一次社交认可

697
00:39:10.431 --> 00:39:13,142
&lrm;这根本不是我们需要去体验的

698
00:39:15.394 --> 00:39:19,982
&lrm;我们管理自己的生活
&lrm;建立在获得的完美感上

699
00:39:20.733 --> 00:39:23,527
&lrm;因为爱心、点赞、竖起大拇指
&lrm;这些短期的信号

700
00:39:23.611 --> 00:39:25,154
&lrm;给我们奖赏

701
00:39:25.237 --> 00:39:28,407
&lrm;我们把它融合到价值中
&lrm;融合到真相中

702
00:39:29.825 --> 00:39:33,120
&lrm;不论是否虚假 易破碎的人气

703
00:39:33.913 --> 00:39:37,458
&lrm;这是短期的 你需要承认 这让你更加

704
00:39:37.541 --> 00:39:39,919
&lrm;空虚 于是会再次这样做

705
00:39:41.295 --> 00:39:43,381
&lrm;因为这样
&lrm;它会将你逼入这样一个恶性循环

706
00:39:43.464 --> 00:39:47,343
&lrm;你会想：“我接下来要做什么？
&lrm;因为我还想要这种感觉”

707
00:39:48.260 --> 00:39:50,846
&lrm;想一下 这种现象被20亿人复杂化

708
00:39:50.930 --> 00:39:54,767
&lrm;然后想一下 之后人们
&lrm;会怎样回应别人对自己的看法

709
00:39:54.850 --> 00:39:56,435
&lrm;真的… 真的很恶劣

710
00:39:56.977 --> 00:39:58,229
&lrm;真的太恶劣了

711
00:40:00.856 --> 00:40:05,069
&lrm;美国青少年群体中
&lrm;出现了大幅增长的

712
00:40:05.152 --> 00:40:06,529
&lrm;抑郁和焦虑

713
00:40:06.612 --> 00:40:10,950
&lrm;大概就在2011年到2013年开始的

714
00:40:11.033 --> 00:40:15,371
&lrm;这个国家中 每十万名少女中

715
00:40:15.454 --> 00:40:17,123
&lrm;每年因为割腕或者自残

716
00:40:17.206 --> 00:40:19,917
&lrm;进医院接受治疗的人数

717
00:40:20.000 --> 00:40:23,921
&lrm;在2010年到2011年是非常平稳的

718
00:40:24.004 --> 00:40:25,756
&lrm;在那之后 直线上升

719
00:40:28.759 --> 00:40:31,971
&lrm;大一点的少女中 增加了62%

720
00:40:32.054 --> 00:40:33,931
&lrm;（美国非致命性自残住院人数）

721
00:40:34.014 --> 00:40:38,310
&lrm;进入青春期前的少女 增加了189%
&lrm;将近三倍了

722
00:40:40.312 --> 00:40:43,107
&lrm;更可怕的是
&lrm;自杀也呈现出相同的趋势

723
00:40:43.190 --> 00:40:44,900
&lrm;（美国自杀率
&lrm;每百万女孩死亡人数）

724
00:40:44.984 --> 00:40:47,570
&lrm;大一点的少女 15到19岁

725
00:40:47.653 --> 00:40:51,449
&lrm;与本世纪初相比 增长了70%

726
00:40:52.158 --> 00:40:55,077
&lrm;青春期前的少女
&lrm;最开始的比率非常低

727
00:40:55.161 --> 00:40:57,663
&lrm;现在增长了151%

728
00:40:58.831 --> 00:41:01,709
&lrm;这个增长模式 指向了社交媒体

729
00:41:01.792 --> 00:41:03,961
&lrm;（2009年手机上的社交媒体数量）

730
00:41:04.044 --> 00:41:07,214
&lrm;Z代人
&lrm;1996年之后那会儿出生的孩子们

731
00:41:07.298 --> 00:41:10,342
&lrm;那些孩子们是历史上第一代

732
00:41:10.426 --> 00:41:12,636
&lrm;在初中开始使用社交媒体的

733
00:41:15.973 --> 00:41:17,433
&lrm;他们的时间 花在了哪里？

734
00:41:19.727 --> 00:41:22,480
&lrm;他们放学回家 就拿起手机

735
00:41:24.315 --> 00:41:29,195
&lrm;整个一代人都更加焦虑
&lrm;更加脆弱、更加抑郁

736
00:41:30.613 --> 00:41:33,282
&lrm;他们更不愿意冒险

737
00:41:34.325 --> 00:41:37,536
&lrm;他们拿到驾照的比率下降了

738
00:41:38.954 --> 00:41:41,081
&lrm;出去约会过的人数

739
00:41:41.165 --> 00:41:44,251
&lrm;有过任何形式浪漫互动的人数骤减

740
00:41:47.505 --> 00:41:49,715
&lrm;整个一代人 有了真正的改变

741
00:41:53.177 --> 00:41:57,306
&lrm;别忘了 这些人中的每一个
&lrm;每一个住院的人

742
00:41:57.389 --> 00:42:00,267
&lrm;背后都有一个受伤的、惊恐的家庭

743
00:42:00.351 --> 00:42:02,353
&lrm;“天啊 我的孩子们怎么了？”

744
00:42:19.411 --> 00:42:21,038
&lrm;在我看来 问题很显而易见

745
00:42:22.873 --> 00:42:28,128
&lrm;这些服务正在杀人
&lrm;也在导致人们自杀

746
00:42:29.088 --> 00:42:33,300
&lrm;我不认识哪个家长会说
&lrm;“是 我希望我的孩子们 成长过程中

747
00:42:33.384 --> 00:42:36,887
&lrm;感觉被技术设计师操控

748
00:42:36.971 --> 00:42:39,723
&lrm;操控他们的注意力
&lrm;让他们无法完成作业

749
00:42:39.807 --> 00:42:42,560
&lrm;让他们将自己
&lrm;和不切实际的审美标准相对比”

750
00:42:42.643 --> 00:42:44,687
&lrm;没有人希望那样

751
00:42:45.104 --> 00:42:46,355
&lrm;没有一个人

752
00:42:46.438 --> 00:42:48,482
&lrm;我们以前有一些保护措施

753
00:42:48.566 --> 00:42:50,943
&lrm;小孩子们观看周六早间动画片的时候

754
00:42:51.026 --> 00:42:52,778
&lrm;我们关心保护儿童

755
00:42:52.861 --> 00:42:56,574
&lrm;我们会说：“你不能这样
&lrm;给这个年龄段的孩子看广告”

756
00:42:57.366 --> 00:42:58,784
&lrm;然后有了YouTube儿童频道

757
00:42:58.867 --> 00:43:02,454
&lrm;蚕食了注意力经济的全部

758
00:43:02.538 --> 00:43:04,915
&lrm;现在所有的孩子
&lrm;都能看YouTube儿童频道

759
00:43:04.999 --> 00:43:07,668
&lrm;所有的保护措施
&lrm;所有的管理规定都不见了

760
00:43:10.296 --> 00:43:17,261
&lrm;（没有手机的时间）

761
00:43:18.304 --> 00:43:22,141
&lrm;我们在训练、调节整个一代人…

762
00:43:23.434 --> 00:43:29,148
&lrm;我们不自在、孤独、不确定或害怕时

763
00:43:29.231 --> 00:43:31,775
&lrm;有一个自己的数码安慰

764
00:43:32.234 --> 00:43:36,488
&lrm;这有点让我们
&lrm;自己处理这些情绪的能力退化了

765
00:43:53.964 --> 00:43:56,884
&lrm;Photoshop屏幕的另一端
&lrm;没有几千个工程师

766
00:43:56.967 --> 00:43:58,969
&lrm;用通知 用你的朋友

767
00:43:59.053 --> 00:44:02,431
&lrm;用人工智能去预判
&lrm;什么能完美地让你上瘾 引诱你

768
00:44:02.514 --> 00:44:04,516
&lrm;或者操纵你 或者允许广告商

769
00:44:04.600 --> 00:44:06,894
&lrm;去测试六万种不同的文本或颜色

770
00:44:06.977 --> 00:44:08,395
&lrm;（芝加哥反垄断技术会议）

771
00:44:08.479 --> 00:44:11,065
&lrm;…以此来找到
&lrm;怎样能完美地操纵你的思想

772
00:44:11.148 --> 00:44:14,985
&lrm;这是一种全新的力量和影响

773
00:44:16.070 --> 00:44:19,156
&lrm;我想再一次强调 他们使用的

774
00:44:19.239 --> 00:44:22,868
&lrm;玩弄人们的能力
&lrm;让人们成瘾或者受到影响

775
00:44:22.951 --> 00:44:25,204
&lrm;或许这一次是不同的
&lrm;或许他们是不同的

776
00:44:25.287 --> 00:44:28,749
&lrm;报纸问世时 印刷媒体问世时
&lrm;与现在很不同

777
00:44:28.832 --> 00:44:31,835
&lrm;电视问世的时候 与现在很不同

778
00:44:31.919 --> 00:44:34,004
&lrm;当时有三个主要的…

779
00:44:34.463 --> 00:44:36,423
&lrm;-网络
&lrm;-当时 我也想说

780
00:44:36.507 --> 00:44:38,384
&lrm;但我在说 这是一个全新的层次

781
00:44:38.467 --> 00:44:42,054
&lrm;这个新的层次 以前也发生过很多次

782
00:44:42.137 --> 00:44:45,099
&lrm;这只是我们看见的 最新的一个层次

783
00:44:45.182 --> 00:44:48,727
&lrm;有这样一种说法：“我们去适应它

784
00:44:48.811 --> 00:44:51,188
&lrm;我们要学着与这些设备共存

785
00:44:51.271 --> 00:44:53,732
&lrm;就像我们学着
&lrm;和其他所有事物共存一样”

786
00:44:53.816 --> 00:44:56,694
&lrm;但这个说法没有注意到的是
&lrm;有些东西明显是全新的

787
00:44:57.569 --> 00:45:00,322
&lrm;或许这其中最危险的是

788
00:45:00.406 --> 00:45:04,410
&lrm;这是由技术驱动的
&lrm;在成指数地向前发展

789
00:45:04.910 --> 00:45:05,911
&lrm;（计算机处理能力）

790
00:45:05.994 --> 00:45:09,081
&lrm;大体上
&lrm;如果你看从20世纪60年代至今

791
00:45:09.873 --> 00:45:12,960
&lrm;计算机处理能力增长了万亿倍

792
00:45:13.794 --> 00:45:18,340
&lrm;我们身边没有任何其他东西
&lrm;以这个速率增长

793
00:45:18.424 --> 00:45:22,177
&lrm;比如 汽车速度基本上才实现翻倍

794
00:45:22.261 --> 00:45:25,264
&lrm;几乎所有其他的东西都显得微不足道

795
00:45:25.347 --> 00:45:27,182
&lrm;或许最重要的是

796
00:45:27.266 --> 00:45:31,353
&lrm;我们人类… 我们的生理
&lrm;我们的大脑 根本没有丝毫进化

797
00:45:31.854 --> 00:45:35,232
&lrm;（没有手机的时间）

798
00:45:37.401 --> 00:45:41,488
&lrm;人类的思想、身体和体质

799
00:45:41.947 --> 00:45:43,866
&lrm;基本上不会改变了

800
00:45:56.837 --> 00:46:00,924
&lrm;我们可以搞基因工程
&lrm;在未来开发新的人类物种

801
00:46:01.008 --> 00:46:05,220
&lrm;但是现实来讲
&lrm;你生活在大脑这个硬件下

802
00:46:05.304 --> 00:46:07,222
&lrm;已经存在几百万年了

803
00:46:07.306 --> 00:46:10,559
&lrm;然后出现了这样一个屏幕
&lrm;在屏幕的另一端

804
00:46:10.642 --> 00:46:13,562
&lrm;有上千名工程师和超级计算机

805
00:46:13.645 --> 00:46:16,106
&lrm;有着与你不同的目标

806
00:46:16.190 --> 00:46:19,693
&lrm;那么 这个游戏谁能赢呢？谁会赢？

807
00:46:25.699 --> 00:46:26,617
&lrm;我们怎么会输？

808
00:46:27.159 --> 00:46:29,745
&lrm;-我不知道
&lrm;-他在哪里？这太不正常了

809
00:46:29.828 --> 00:46:32,080
&lrm;我给他推送朋友和家人的内容太多
&lrm;他烦了吗？

810
00:46:32.164 --> 00:46:34,082
&lrm;-或许吧
&lrm;-或许是广告太多了

811
00:46:34.166 --> 00:46:37,795
&lrm;不 一定出了严重的问题
&lrm;我们切换到复苏模式吧

812
00:46:39.713 --> 00:46:44,051
&lrm;当你想到人工智能
&lrm;人工智能会毁掉世界

813
00:46:44.134 --> 00:46:47,221
&lrm;你会看到《终结者》 看到施瓦辛格…

814
00:46:47.638 --> 00:46:48,680
&lrm;我会回来的

815
00:46:48.764 --> 00:46:52,684
&lrm;…你会看到无人机 你觉得
&lrm;“人工智能会杀人的”

816
00:46:53.644 --> 00:46:59,817
&lrm;人们忽略的是 人工智能
&lrm;现在已经在运营着当今世界了

817
00:46:59.900 --> 00:47:03,237
&lrm;甚至谈论“人工智能”都只是暗喻

818
00:47:03.320 --> 00:47:09,451
&lrm;在谷歌这种公司 有超级大的房间

819
00:47:10.327 --> 00:47:13,121
&lrm;有些在地下 有些在水下

820
00:47:13.205 --> 00:47:14,498
&lrm;房间里全是电脑

821
00:47:14.581 --> 00:47:17,835
&lrm;无数的电脑 连绵不绝

822
00:47:18.460 --> 00:47:20,504
&lrm;它们互相之间在内部深度连接

823
00:47:20.587 --> 00:47:22,923
&lrm;在运行着极其复杂的程序

824
00:47:23.006 --> 00:47:26,009
&lrm;始终不停地在彼此之间交换信息

825
00:47:26.802 --> 00:47:28,595
&lrm;他们会运行很多不同的程序

826
00:47:28.679 --> 00:47:30,806
&lrm;在同样的机器上 有不同的产品

827
00:47:31.348 --> 00:47:33,684
&lrm;有些东西可以被描述为简单算法

828
00:47:33.767 --> 00:47:35,227
&lrm;有些算法太过复杂

829
00:47:35.310 --> 00:47:37,521
&lrm;就可以被称为“智能”

830
00:47:40.148 --> 00:47:43,777
&lrm;我想说 算法是内嵌在代码中的观点…

831
00:47:45.070 --> 00:47:47,656
&lrm;算法并不是客观的

832
00:47:48.365 --> 00:47:51,577
&lrm;算法被某种成功的定义优化

833
00:47:52.244 --> 00:47:53,370
&lrm;所以 如果你能想象

834
00:47:53.453 --> 00:47:57,124
&lrm;一个商业公司成功的定义

835
00:47:57.207 --> 00:47:59,293
&lrm;需要依靠算法

836
00:47:59.835 --> 00:48:01,211
&lrm;那就是商业利益

837
00:48:01.587 --> 00:48:02,671
&lrm;通常都有利润

838
00:48:03.130 --> 00:48:07,384
&lrm;你给电脑一个目标
&lrm;说“我想要这个结果”

839
00:48:07.467 --> 00:48:10,262
&lrm;电脑自己去学习 怎样实现

840
00:48:10.345 --> 00:48:12,598
&lrm;这是“机器学习”概念的由来

841
00:48:12.681 --> 00:48:14,850
&lrm;所以 每一天 都会更好一点

842
00:48:14.933 --> 00:48:16,977
&lrm;在正确命令获取正确的推送数据

843
00:48:17.060 --> 00:48:19,438
&lrm;让你在这个产品上花的时间越来越多

844
00:48:19.521 --> 00:48:22,232
&lrm;没人能真正明白 为了实现这个目标

845
00:48:22.316 --> 00:48:23,901
&lrm;他们在做什么

846
00:48:23.984 --> 00:48:28,238
&lrm;算法有着自己的思想 虽然是人写的

847
00:48:28.906 --> 00:48:30,657
&lrm;它写出来的目的

848
00:48:30.741 --> 00:48:35,037
&lrm;是你建立一个机器
&lrm;这个机器会自己改变

849
00:48:35.120 --> 00:48:37,873
&lrm;这种公司 员工非常少

850
00:48:37.956 --> 00:48:40,000
&lrm;在脸书、推特和其他公司

851
00:48:40.083 --> 00:48:43,795
&lrm;只有几个人能明白
&lrm;这些系统的工作原理

852
00:48:43.879 --> 00:48:46,715
&lrm;虽然他们不需要完全理解

853
00:48:46.798 --> 00:48:49,551
&lrm;某一条特定的内容 会发生什么

854
00:48:49.968 --> 00:48:55,474
&lrm;作为人类 我们几乎
&lrm;已经失去了对这些系统的控制

855
00:48:55.891 --> 00:48:59,603
&lrm;因为是它们在控制我们看到的信息

856
00:48:59.686 --> 00:49:02,439
&lrm;更多的是它们在控制我们
&lrm;而不是我们控制它们

857
00:49:03.815 --> 00:49:07,319
&lrm;在他的地理区域对他和可以对比的人
&lrm;进行交叉参照

858
00:49:07.402 --> 00:49:09,571
&lrm;他的心理测定相似者

859
00:49:09.655 --> 00:49:13,700
&lrm;在他的地区
&lrm;有13694个和他行为相似的人

860
00:49:13.784 --> 00:49:16,370
&lrm;-他们中盛行什么？
&lrm;-我们需要真实的好东西

861
00:49:16.453 --> 00:49:17,704
&lrm;才能进行有效的复苏

862
00:49:17.788 --> 00:49:19,957
&lrm;因为平常的那些东西已经不起作用了

863
00:49:20.040 --> 00:49:21,875
&lrm;学校那个可爱的姑娘都没用了

864
00:49:22.334 --> 00:49:25,253
&lrm;我的分析显示
&lrm;用极端中心内容搞政治

865
00:49:25.337 --> 00:49:28,256
&lrm;有62.3%的几率能够获得长期参与

866
00:49:28.340 --> 00:49:29,299
&lrm;还不错

867
00:49:30.342 --> 00:49:32,302
&lrm;想用它引导 还不太够

868
00:49:32.386 --> 00:49:35,305
&lrm;好 所以我们已经试过
&lrm;通知给他圈人照片

869
00:49:35.389 --> 00:49:39,017
&lrm;邀请、实事、甚至是瑞贝卡的私信

870
00:49:39.101 --> 00:49:42,813
&lrm;但是用户01265923010呢？

871
00:49:42.896 --> 00:49:44,648
&lrm;是 本点赞了她所有的发帖

872
00:49:44.731 --> 00:49:47,776
&lrm;几个月的所有发帖 真的点了所有
&lrm;然后就没有然后了

873
00:49:47.859 --> 00:49:50,445
&lrm;我算出了通知安娜的内容

874
00:49:50.529 --> 00:49:52,030
&lrm;会有92.3%的复苏概率

875
00:49:53.907 --> 00:49:55,993
&lrm;（新感情）

876
00:49:56.535 --> 00:49:57,494
&lrm;还有她的新朋友

877
00:49:58.495 --> 00:50:04,001
&lrm;（没有手机的时间）

878
00:50:24.354 --> 00:50:26,023
&lrm;（你的前女友有了新感情！）

879
00:50:26.106 --> 00:50:27,315
&lrm;不是吧

880
00:50:35.657 --> 00:50:36,616
&lrm;好吧

881
00:50:37.576 --> 00:50:38,785
&lrm;（安娜与路易斯正在热恋）

882
00:50:38.869 --> 00:50:39,703
&lrm;什么？

883
00:50:41.621 --> 00:50:42,789
&lrm;当！我们回来了！

884
00:50:42.873 --> 00:50:44,374
&lrm;我们继续挣钱 兄弟们

885
00:50:44.458 --> 00:50:46,334
&lrm;好 让他们和整个世界联系起来

886
00:50:46.418 --> 00:50:49,337
&lrm;我给他看所有他可能喜欢的信息

887
00:50:49.755 --> 00:50:53,717
&lrm;你们是否想过
&lrm;这些推送对本是好的吗？

888
00:50:57.220 --> 00:50:58,221
&lrm;-没想过
&lrm;-没有

889
00:51:17.532 --> 00:51:19,076
&lrm;我在你身上下了咒语

890
00:51:25.040 --> 00:51:26,374
&lrm;因为你是我的

891
00:51:34.508 --> 00:51:36,593
&lrm;你最好停止你做的事情

892
00:51:41.181 --> 00:51:42,265
&lrm;我不骗你

893
00:51:42.349 --> 00:51:44,893
&lrm;（A/B测试 极端中心）

894
00:51:44.976 --> 00:51:46,686
&lrm;不 我不骗你

895
00:51:49.981 --> 00:51:51,817
&lrm;你知道我无法忍受

896
00:51:53.026 --> 00:51:54,611
&lrm;你在四处奔跑

897
00:51:55.612 --> 00:51:57,239
&lrm;爸爸 你更清楚

898
00:51:58.782 --> 00:52:02,077
&lrm;我无法忍受 因为你将我放下

899
00:52:03.286 --> 00:52:04,121
&lrm;耶

900
00:52:06.456 --> 00:52:08,375
&lrm;我在你身上下了咒语

901
00:52:12.379 --> 00:52:14,840
&lrm;因为你是我的

902
00:52:18.718 --> 00:52:19,845
&lrm;你是我的

903
00:52:20.929 --> 00:52:24,349
&lrm;想象一下 你在用脸书…

904
00:52:24.766 --> 00:52:29,312
&lrm;你的对手是人工智能

905
00:52:29.396 --> 00:52:31,314
&lrm;它知道你的一切

906
00:52:31.398 --> 00:52:34,568
&lrm;能够预测你未来的举动
&lrm;你对它却一无所知

907
00:52:34.651 --> 00:52:37,404
&lrm;除了上面有猫的视频和出生日期

908
00:52:37.821 --> 00:52:39,656
&lrm;这根本不是公平的竞争

909
00:52:41.575 --> 00:52:43,869
&lrm;本与杰瑞 该走了 孩子？

910
00:52:51.126 --> 00:52:51,960
&lrm;本？

911
00:53:02.679 --> 00:53:03,513
&lrm;本

912
00:53:05.182 --> 00:53:06,057
&lrm;快点

913
00:53:07.225 --> 00:53:08,894
&lrm;该上学了 我们走

914
00:53:13.231 --> 00:53:16,735
&lrm;（人道技术中心）

915
00:53:31.374 --> 00:53:33,543
&lrm;-你今天怎么样？
&lrm;-我很紧张

916
00:53:33.627 --> 00:53:34,628
&lrm;-你紧张吗？
&lrm;-是啊 

917
00:53:37.380 --> 00:53:39,049
&lrm;我们都在当心这个时刻

918
00:53:39.132 --> 00:53:42,969
&lrm;当技术会超越人类力量和智慧

919
00:53:43.053 --> 00:53:47,015
&lrm;技术什么时候会超越人类
&lrm;取代我们的工作 比人类更聪明？

920
00:53:48.141 --> 00:53:50,101
&lrm;但有更早的时刻…

921
00:53:50.977 --> 00:53:55,565
&lrm;技术超越人类的弱点时

922
00:53:57.484 --> 00:54:02,030
&lrm;这个超越的点就是上瘾

923
00:54:02.113 --> 00:54:04,741
&lrm;两极分化、激进化、激化愤怒

924
00:54:04.824 --> 00:54:06,368
&lrm;激化虚荣 一切的根源

925
00:54:07.702 --> 00:54:09,913
&lrm;它在压制人类天性

926
00:54:10.538 --> 00:54:13,500
&lrm;在挫伤人性

927
00:54:30.558 --> 00:54:31,434
&lrm;很抱歉

928
00:54:41.736 --> 00:54:44,656
&lrm;我努力让人们明白

929
00:54:45.198 --> 00:54:49,828
&lrm;脸书这种地方的推送
&lrm;有多错误的一种方式

930
00:54:49.911 --> 00:54:51,454
&lrm;是让他们去想想维基百科

931
00:54:51.538 --> 00:54:52,872
&lrm;（新标签页）

932
00:54:52.956 --> 00:54:55,709
&lrm;当你打开一个维基百科网页
&lrm;你和别人看到的东西是一样的

933
00:54:55.792 --> 00:54:56,960
&lrm;（维基百科 自由的百科全书）

934
00:54:57.043 --> 00:55:00,297
&lrm;所以 这是网络上少有的
&lrm;我们统一共享的东西

935
00:55:00.380 --> 00:55:03,425
&lrm;现在 现象一下 维基百科说

936
00:55:03.508 --> 00:55:07,178
&lrm;我们要给每一个人不同的个性化定义

937
00:55:07.262 --> 00:55:09,472
&lrm;有人给我们钱 让我们这样做”

938
00:55:09.556 --> 00:55:13,435
&lrm;维基百科就会监视你 会计算

939
00:55:13.518 --> 00:55:17,188
&lrm;“我要做什么 才能代表一些商业利益

940
00:55:17.272 --> 00:55:19,899
&lrm;让这个人产生一点改变？” 对吧？

941
00:55:19.983 --> 00:55:21,818
&lrm;然后就会改变整个词条

942
00:55:22.444 --> 00:55:23,570
&lrm;你能想象吗？

943
00:55:23.653 --> 00:55:24,738
&lrm;你应该能够想象得到

944
00:55:24.821 --> 00:55:26,823
&lrm;因为在脸书页面上 就是这样的

945
00:55:26.906 --> 00:55:28,992
&lrm;你的YouTube推送 就是这样的

946
00:55:29.075 --> 00:55:31,786
&lrm;当你登录谷歌 输入“气候变化是…”

947
00:55:31.870 --> 00:55:34,998
&lrm;你会看到 根据你所居住的地区不同
&lrm;会出现不同的结果

948
00:55:35.081 --> 00:55:36,082
&lrm;（气候变化是）

949
00:55:36.166 --> 00:55:38,460
&lrm;在某些城市 你会看到自动完成…

950
00:55:38.543 --> 00:55:40,462
&lrm;“气候变化是一场骗局”

951
00:55:40.545 --> 00:55:42,047
&lrm;在其他地方 你将会看到

952
00:55:42.130 --> 00:55:44,841
&lrm;“气候变化是对自然的破坏”

953
00:55:44.924 --> 00:55:48,428
&lrm;这个功能
&lrm;提供的不都是气候变化的真相

954
00:55:48.511 --> 00:55:51,097
&lrm;而是你在哪里进行谷歌搜索

955
00:55:51.181 --> 00:55:53,600
&lrm;以及谷歌对你个人兴趣的了解

956
00:55:55.185 --> 00:55:58,021
&lrm;即便是两个非常亲近的朋友

957
00:55:58.104 --> 00:56:00,190
&lrm;他们两个有着完全相同的朋友圈子

958
00:56:00.273 --> 00:56:02,817
&lrm;他们会认为
&lrm;“我们会看到脸书上的新推送

959
00:56:02.901 --> 00:56:06,738
&lrm;会看到完全相同的更新”
&lrm;但事实远非如此

960
00:56:06.821 --> 00:56:08,448
&lrm;他们会看到完全不同的世界

961
00:56:08.531 --> 00:56:10,575
&lrm;因为这些是基于计算机的计算

962
00:56:10.658 --> 00:56:12,035
&lrm;对每一个人来说 怎样最完美

963
00:56:12.118 --> 00:56:14,245
&lrm;（直播中）

964
00:56:14.329 --> 00:56:18,416
&lrm;想象这件事的一个方式是
&lrm;这是27亿人的《楚门的世界》

965
00:56:18.500 --> 00:56:21,294
&lrm;每一个人都有自己的现实 自己的…

966
00:56:22.670 --> 00:56:23,671
&lrm;事实

967
00:56:23.755 --> 00:56:27,008
&lrm;你觉得楚门为什么到现在都
&lrm;从来没有接近

968
00:56:27.092 --> 00:56:30,095
&lrm;发现他所在世界的真实本质？

969
00:56:31.054 --> 00:56:34,140
&lrm;我们接受了
&lrm;呈现在我们面前的世界就是现实

970
00:56:34.224 --> 00:56:35,141
&lrm;就是这么简单

971
00:56:35.225 --> 00:56:36,393
&lrm;（直播中）

972
00:56:36.476 --> 00:56:41,064
&lrm;随着时间推移 你会有一种错觉
&lrm;觉得每一个人都认同你

973
00:56:41.147 --> 00:56:44,067
&lrm;因为给你推送的新闻中
&lrm;每个人都和你极其相似

974
00:56:44.567 --> 00:56:49,072
&lrm;一旦你达到了这种状态
&lrm;你就很容易被操纵了

975
00:56:49.155 --> 00:56:51,741
&lrm;和你被魔术师操纵 是同样的方式

976
00:56:51.825 --> 00:56:55,370
&lrm;魔术师给你看纸牌魔术 跟你说
&lrm;“选一张牌 哪张都行”

977
00:56:55.453 --> 00:56:58,373
&lrm;你没有意识到的是
&lrm;他们早就给你设好陷阱了

978
00:56:58.456 --> 00:57:00,583
&lrm;于是你选的那张牌
&lrm;是他们想让你选的

979
00:57:00.667 --> 00:57:03,169
&lrm;这就是脸书的工作原理
&lrm;脸书坐在那里说

980
00:57:03.253 --> 00:57:06,172
&lrm;“喂 选择你的朋友
&lrm;选择你关注的联系人”

981
00:57:06.256 --> 00:57:08,716
&lrm;根本是胡扯 它就跟魔术师一样

982
00:57:08.800 --> 00:57:11,302
&lrm;脸书负责给你进行新闻推送

983
00:57:11.386 --> 00:57:14,514
&lrm;我们都不过是
&lrm;在基于不同的一系列事实行事

984
00:57:14.597 --> 00:57:16,474
&lrm;当大范围发生时

985
00:57:16.558 --> 00:57:20,770
&lrm;你就再也无法考虑甚至消化

986
00:57:20.854 --> 00:57:23,690
&lrm;与你所创造的世界观相悖的信息了

987
00:57:23.773 --> 00:57:28,027
&lrm;那就意味着
&lrm;我们其实不是客观、有建设性的个体

988
00:57:28.778 --> 00:57:32,449
&lrm;睁大你的眼睛 别相信谎言！睁大…

989
00:57:32.532 --> 00:57:35,160
&lrm;然后你扫了一眼另一边

990
00:57:35.243 --> 00:57:38,746
&lrm;你开始想
&lrm;“这些人怎么会如此愚蠢？”

991
00:57:38.830 --> 00:57:42,125
&lrm;他们也看到了我不停看到的这些信息

992
00:57:42.208 --> 00:57:44,627
&lrm;他们怎么会看不到相同的信息？

993
00:57:44.711 --> 00:57:47,297
&lrm;问题的答案是
&lrm;“他们没有看到相同的信息”

994
00:57:47.380 --> 00:57:50,800
&lrm;睁大你的眼睛 别相信谎言！

995
00:57:52.093 --> 00:57:53,678
&lrm;共和党人什么样？

996
00:57:53.761 --> 00:57:55,472
&lrm;愚昧无知

997
00:57:55.555 --> 00:57:58,933
&lrm;民主党就是一个犯罪团伙
&lrm;不是真正的政治党派

998
00:57:59.017 --> 00:58:03,188
&lrm;皮尤研究中心一项全新的大型研究
&lrm;对一万名美国成年人进行调查

999
00:58:03.271 --> 00:58:05,315
&lrm;发现我们比任何时候都要分裂

1000
00:58:05.398 --> 00:58:09,152
&lrm;个人和政治两极分化达到20年来最高

1001
00:58:11.821 --> 00:58:14,199
&lrm;有超过三分之一的共和党人说

1002
00:58:14.282 --> 00:58:16,826
&lrm;民主党是对这个国家的威胁

1003
00:58:16.910 --> 00:58:20,580
&lrm;民主党超过四分之一的人
&lrm;也这样说共和党

1004
00:58:20.663 --> 00:58:22,499
&lrm;我们讨论的很多问题

1005
00:58:22.582 --> 00:58:24,417
&lrm;比如政治两极分化

1006
00:58:24.501 --> 00:58:28,046
&lrm;在有线电视上大量存在

1007
00:58:28.129 --> 00:58:31,007
&lrm;媒体也有着同样的问题

1008
00:58:31.090 --> 00:58:33,343
&lrm;整体上来说 他们的商业模式

1009
00:58:33.426 --> 00:58:35,762
&lrm;是把我们的关注出售给广告商

1010
00:58:35.845 --> 00:58:38,890
&lrm;网络只是一个新的、更有效率的
&lrm;实现方式罢了

1011
00:58:40.391 --> 00:58:44,145
&lrm;我曾在YouTube的工作
&lrm;是研究YouTube推荐

1012
00:58:44.229 --> 00:58:47,148
&lrm;让我担心的是 我研究的一个算法

1013
00:58:47.232 --> 00:58:50,401
&lrm;增加了社会中的两极分化

1014
00:58:50.485 --> 00:58:53,112
&lrm;但从观看时间来看

1015
00:58:53.196 --> 00:58:57,617
&lrm;这种两极分化
&lrm;在让人们持续在线观看上 极其有效

1016
00:58:58.785 --> 00:59:00,870
&lrm;这些老师教这些东西的唯一原因

1017
00:59:00.954 --> 00:59:02,288
&lrm;是有人给他们钱 让他们教

1018
00:59:02.372 --> 00:59:04,207
&lrm;-太扯了
&lrm;-喂 本杰

1019
00:59:04.916 --> 00:59:06,292
&lrm;今天没有足球训练吗？

1020
00:59:06.376 --> 00:59:08,878
&lrm;有 我只想看看今天的新闻

1021
00:59:08.962 --> 00:59:11,506
&lrm;你去研究一下 极端中心说的任何话…

1022
00:59:11.589 --> 00:59:14,008
&lrm;都不会把你看的这个东西称作新闻

1023
00:59:15.552 --> 00:59:18,721
&lrm;你总是说一切都那么混乱 确实是

1024
00:59:19.305 --> 00:59:21,140
&lrm;但那东西只是政治鼓吹

1025
00:59:21.224 --> 00:59:24,060
&lrm;没有一个是真的
&lrm;全都是让你觉得合理

1026
00:59:24.769 --> 00:59:26,938
&lrm;本 我很严肃 这些东西对你有害

1027
00:59:27.021 --> 00:59:28,690
&lrm;你应该去足球训练

1028
00:59:35.154 --> 00:59:37,490
&lrm;我分享这个东西 是因为我在意

1029
00:59:37.574 --> 00:59:41,077
&lrm;我在意你被误导 这是不对的 好吗？

1030
00:59:41.160 --> 00:59:43,121
&lrm;人们认为算法的设计

1031
00:59:43.204 --> 00:59:46,833
&lrm;是给他们真正想要的 但其实不然

1032
00:59:46.916 --> 00:59:52,589
&lrm;算法其实是在试图
&lrm;找到几个非常强大的兔子洞

1033
00:59:52.672 --> 00:59:56,217
&lrm;试图找到哪一个兔子洞
&lrm;最贴近你的兴趣

1034
00:59:56.301 --> 00:59:59,262
&lrm;然后 如果你开始观看其中一个视频

1035
00:59:59.846 --> 01:00:02,223
&lrm;它就会不停继续推荐

1036
01:00:02.682 --> 01:00:04,934
&lrm;这种情况 并不是有人刻意为之

1037
01:00:05.018 --> 01:00:07,812
&lrm;只是推荐系统一直在做而已

1038
01:00:07.895 --> 01:00:10,815
&lrm;以至于著名篮球运动员凯里·欧文

1039
01:00:11.482 --> 01:00:14,235
&lrm;说他相信地球是平的 后来又道歉

1040
01:00:14.319 --> 01:00:16,112
&lrm;因为他把责任推给
&lrm;YouTube的一个兔子洞

1041
01:00:16.487 --> 01:00:18,656
&lrm;你点击 YouTube视频

1042
01:00:18.740 --> 01:00:21,534
&lrm;它会继续 这个兔子洞能有多深

1043
01:00:21.618 --> 01:00:23,369
&lrm;他后来在国家公共广播电台上说

1044
01:00:23.453 --> 01:00:25,955
&lrm;“很抱歉我相信了这个
&lrm;我无意误导人们”

1045
01:00:26.039 --> 01:00:28,291
&lrm;有人采访了教室中的一群学生
&lrm;他们说

1046
01:00:28.374 --> 01:00:29,667
&lrm;“相信地球是圆的人肯定找他谈了”

1047
01:00:31.044 --> 01:00:33,963
&lrm;地球平面阴谋论被算法

1048
01:00:34.047 --> 01:00:37,634
&lrm;推荐了几亿次

1049
01:00:37.717 --> 01:00:43,890
&lrm;很容易去想
&lrm;只有几个愚蠢的人被说服罢了

1050
01:00:43.973 --> 01:00:46,893
&lrm;但是算法每一天都在变得更聪明

1051
01:00:46.976 --> 01:00:50,188
&lrm;今天 它们说服人们相信 地球是平的

1052
01:00:50.271 --> 01:00:53,816
&lrm;但是明天 它们就会说服你相信
&lrm;一个完全虚假的事情

1053
01:00:54.317 --> 01:00:57,820
&lrm;11月7日 话题标签‘披萨门’诞生了

1054
01:00:57.904 --> 01:00:59,197
&lrm;披萨门…

1055
01:01:00.782 --> 01:01:01,658
&lrm;天啊

1056
01:01:03.159 --> 01:01:06,913
&lrm;我还是不能百分之百确定
&lrm;这个最初是从哪里来的

1057
01:01:06.996 --> 01:01:12,377
&lrm;但是订披萨等于订一个贩卖的人口
&lrm;这个想法

1058
01:01:12.460 --> 01:01:15,046
&lrm;由于脸书上的多个小组越来越大

1059
01:01:15.129 --> 01:01:19,967
&lrm;脸书推荐引擎开始建议普通用户

1060
01:01:20.051 --> 01:01:21,761
&lrm;让他们加入披萨门小组

1061
01:01:21.844 --> 01:01:27,392
&lrm;所以 如果一个用户反对疫苗
&lrm;或者相信飞机喷洒重金属阴谋论

1062
01:01:27.475 --> 01:01:30,645
&lrm;或者对脸书的算法表示过

1063
01:01:30.728 --> 01:01:33,398
&lrm;他们易于相信阴谋论

1064
01:01:33.481 --> 01:01:36,859
&lrm;脸熟的推荐引擎
&lrm;就会推荐给他们披萨门小组

1065
01:01:36.943 --> 01:01:41,072
&lrm;最终 这件事达到高潮
&lrm;一名男子携枪出现

1066
01:01:41.155 --> 01:01:44,617
&lrm;决定他要给披萨店地下室的
&lrm;那些孩子们自由

1067
01:01:44.701 --> 01:01:47,036
&lrm;而这个披萨店根本没有地下室

1068
01:01:47.120 --> 01:01:49,997
&lrm;-你当时在这个地方做什么？
&lrm;-确保这里什么都没有

1069
01:01:50.581 --> 01:01:52,333
&lrm;-什么事？
&lrm;-恋童癖怪圈

1070
01:01:52.417 --> 01:01:53,793
&lrm;-什么事？
&lrm;-恋童癖怪圈

1071
01:01:53.876 --> 01:01:55,878
&lrm;披萨门 他在说披萨门

1072
01:01:55.962 --> 01:02:00,216
&lrm;这是阴谋论在所有社交媒体上

1073
01:02:00.299 --> 01:02:03,678
&lrm;到处传播的一个例子

1074
01:02:03.761 --> 01:02:06,097
&lrm;社交网络自己的推荐引擎

1075
01:02:06.180 --> 01:02:07,974
&lrm;自愿把这个东西推送给

1076
01:02:08.057 --> 01:02:10,643
&lrm;这辈子从来没有搜索过
&lrm;“披萨门”的人们

1077
01:02:10.727 --> 01:02:12,687
&lrm;（披萨门
&lrm;民主党和恋童癖的深盘披萨）

1078
01:02:12.770 --> 01:02:14,439
&lrm;有一个研究 麻省理工的研究

1079
01:02:14.522 --> 01:02:19,444
&lrm;说推特上传播的虚假新闻
&lrm;比真实新闻传播速度快六倍

1080
01:02:19.902 --> 01:02:21,863
&lrm;当一个人有着高于另一个人

1081
01:02:21.946 --> 01:02:24,741
&lrm;六倍的优势 这种世界会是什么样？

1082
01:02:25.283 --> 01:02:27,660
&lrm;你可以想象 这些事情有点…

1083
01:02:27.744 --> 01:02:31,706
&lrm;将人类行为的基础平面倾斜了

1084
01:02:31.789 --> 01:02:34,709
&lrm;让一些行为更难 让一些行为更容易

1085
01:02:34.792 --> 01:02:37,420
&lrm;你总是可以自由地走上山坡

1086
01:02:37.503 --> 01:02:38,796
&lrm;但是这样做的人越来越少

1087
01:02:38.880 --> 01:02:43,092
&lrm;所以大范围内 在整个社会范围内
&lrm;你就是将基础平面倾斜了

1088
01:02:43.176 --> 01:02:45,970
&lrm;改变了数十亿人的想法和行为

1089
01:02:46.053 --> 01:02:52,018
&lrm;我们创造了一个
&lrm;偏心于虚假消息的体系

1090
01:02:52.643 --> 01:02:54,437
&lrm;并不是因为我们想这样做

1091
01:02:54.520 --> 01:02:58,816
&lrm;而是因为虚假信息比真实信息
&lrm;能让各个公司

1092
01:02:59.400 --> 01:03:01,319
&lrm;赚到更多钱 真实信息比较无聊

1093
01:03:01.986 --> 01:03:04,489
&lrm;这是一个
&lrm;利用虚假信息牟利的商业模式

1094
01:03:04.906 --> 01:03:08,159
&lrm;允许未受监管的信息传送给更多的人

1095
01:03:08.701 --> 01:03:11,287
&lrm;卖出最好的价钱 以此来赚钱

1096
01:03:11.662 --> 01:03:13,956
&lrm;因为气候变化？对

1097
01:03:14.040 --> 01:03:16,751
&lrm;这是骗局 对 是真的 这才是重点

1098
01:03:16.834 --> 01:03:20,046
&lrm;他们谈论这件事情越多
&lrm;就越会将我们分化

1099
01:03:20.129 --> 01:03:22,423
&lrm;他们越有力量 就越有控制权

1100
01:03:22.507 --> 01:03:25,468
&lrm;脸书有万亿个新闻推送贴

1101
01:03:26.552 --> 01:03:29,180
&lrm;他们无法知道哪些是真的
&lrm;哪些是事实…

1102
01:03:29.972 --> 01:03:33,726
&lrm;所以当下这个议题 才如此重要

1103
01:03:33.810 --> 01:03:37,021
&lrm;传播迅速的 不只是新冠病毒

1104
01:03:37.104 --> 01:03:40,191
&lrm;网上有关于这个病毒的大量虚假信息

1105
01:03:40.274 --> 01:03:43,694
&lrm;多喝水能将新冠病毒
&lrm;从你身体中冲走的提议

1106
01:03:43.778 --> 01:03:47,490
&lrm;是在社交媒体上广泛流传的
&lrm;该病毒的谜题之一

1107
01:03:47.573 --> 01:03:50,451
&lrm;这是政府计划的事件
&lrm;创造了这个病毒

1108
01:03:50.535 --> 01:03:52,954
&lrm;来模拟世界各国将会如何应对

1109
01:03:53.955 --> 01:03:55,581
&lrm;新冠病毒是一场骗局

1110
01:03:56.165 --> 01:03:57,959
&lrm;非典 新冠病毒

1111
01:03:58.376 --> 01:04:01,045
&lrm;看看这是什么时候制造的 2018年

1112
01:04:01.128 --> 01:04:03,798
&lrm;我觉得是美国政府开始的这场闹剧

1113
01:04:04.215 --> 01:04:07,343
&lrm;根本没有人生病 没人生病

1114
01:04:07.426 --> 01:04:09,095
&lrm;没有人认识哪个人真正生病了

1115
01:04:09.512 --> 01:04:13,015
&lrm;或许是政府在利用新冠病毒当借口

1116
01:04:13.099 --> 01:04:15,643
&lrm;让所有人留在家
&lrm;因为有其他的事情要发生

1117
01:04:15.726 --> 01:04:18,020
&lrm;新冠病毒不会杀人

1118
01:04:18.104 --> 01:04:20,940
&lrm;他们是在掩盖5G辐射害死的人

1119
01:04:21.023 --> 01:04:22,525
&lrm;（反监视抗议
&lrm;5G/新冠 虚假宣传标题）

1120
01:04:22.608 --> 01:04:24,569
&lrm;我们被谣言轰炸

1121
01:04:25.403 --> 01:04:28,823
&lrm;人们去毁掉了真实的手机信号塔

1122
01:04:28.906 --> 01:04:32,201
&lrm;我们看到俄罗斯和中国
&lrm;传播谣言和阴谋论

1123
01:04:32.285 --> 01:04:35,246
&lrm;今天早上 乌克兰的恐慌与抗议…

1124
01:04:35.329 --> 01:04:38,916
&lrm;人们不知道什么是真相
&lrm;现在已经闹出人命了

1125
01:04:40.001 --> 01:04:42,628
&lrm;那些传播新冠病毒虚假信息的来源

1126
01:04:42.712 --> 01:04:45,798
&lrm;积累了5200万人参与

1127
01:04:45.882 --> 01:04:50,094
&lrm;你是说 胶银溶液会有效

1128
01:04:50.177 --> 01:04:54,140
&lrm;我们这样说吧
&lrm;虽然没有用新冠病毒的毒株测试过

1129
01:04:54.223 --> 01:04:57,226
&lrm;我们看到的新冠病毒
&lrm;只是发生在我们信息生态系统中的

1130
01:04:57.310 --> 01:05:00,104
&lrm;一个极端案例

1131
01:05:00.187 --> 01:05:01,022
&lrm;（惠特默 希特勒）

1132
01:05:01.105 --> 01:05:05,026
&lrm;社交媒体放大了增长迅速的谣言
&lrm;和增长迅速的道听途说

1133
01:05:05.109 --> 01:05:07,111
&lrm;以至于我们都不知道 什么是真了

1134
01:05:07.194 --> 01:05:08,946
&lrm;不管我们关注的是什么问题

1135
01:05:26.130 --> 01:05:27,465
&lrm;你还在队里吗？

1136
01:05:30.468 --> 01:05:34,430
&lrm;好 如果你想来 我在训练之前
&lrm;先去吃点零食 你要来吗？

1137
01:05:37.642 --> 01:05:38,684
&lrm;当我没说

1138
01:05:45.066 --> 01:05:47,526
&lrm;当前 十个人当中 有九个人不满意

1139
01:05:47.610 --> 01:05:50,613
&lrm;你仔细想想 极端中心和历史上
&lrm;任何政治运动无异

1140
01:05:50.696 --> 01:05:54,492
&lrm;我们要站起来反抗
&lrm;我们要站起来反抗这种杂音

1141
01:05:54.575 --> 01:05:57,036
&lrm;你是我的人民 我相信你们

1142
01:05:59.246 --> 01:06:02,583
&lrm;-极端中心的内容好棒
&lrm;-他非常喜欢

1143
01:06:02.667 --> 01:06:03,626
&lrm;运行一个拍卖

1144
01:06:04.627 --> 01:06:08,547
&lrm;843个竞标人 他以4.35美分
&lrm;卖给了一个武器生产商

1145
01:06:08.631 --> 01:06:10,800
&lrm;我们来宣传一下这些活动

1146
01:06:10.883 --> 01:06:13,511
&lrm;这星期晚些时候
&lrm;将在这片地理区域发生的群众集会

1147
01:06:13.594 --> 01:06:15,179
&lrm;新的视频博主也安排好了

1148
01:06:17.890 --> 01:06:22,979
&lrm;说实话 我告诉你
&lrm;我愿意付出任何代价

1149
01:06:23.062 --> 01:06:24,939
&lrm;我说 任何代价

1150
01:06:32.154 --> 01:06:33,114
&lrm;-订阅…
&lrm;-本？

1151
01:06:33.197 --> 01:06:35,908
&lrm;…记得回来 因为我告诉你们…

1152
01:06:36.659 --> 01:06:38,869
&lrm;我后面会有大事件

1153
01:06:38.953 --> 01:06:40,162
&lrm;非常大的事件

1154
01:06:40.788 --> 01:06:45,292
&lrm;脸书的一个问题是
&lrm;作为一个有劝说性质的工具

1155
01:06:45.793 --> 01:06:47,920
&lrm;它或许是史上最伟大的发明

1156
01:06:48.004 --> 01:06:52,508
&lrm;现在 你来想象一下 落在独裁者
&lrm;或者集权主义者手中 会怎样

1157
01:06:53.718 --> 01:06:57,638
&lrm;如果你想控制你们国家的人民

1158
01:06:57.722 --> 01:07:01,308
&lrm;从未有过像脸书这样有效的工具

1159
01:07:04.937 --> 01:07:07,398
&lrm;一个问题最大的影响是

1160
01:07:07.481 --> 01:07:10,985
&lrm;一些政府和其他不良人士
&lrm;把社交媒体当作武器

1161
01:07:11.610 --> 01:07:13,612
&lrm;导致了真实的线下伤害

1162
01:07:13.696 --> 01:07:15,072
&lrm;我认为最明显的案例

1163
01:07:15.156 --> 01:07:17,658
&lrm;广泛被媒体关注的
&lrm;是缅甸发生的事情

1164
01:07:17.742 --> 01:07:19,160
&lrm;（缅甸总统办公室）

1165
01:07:19.243 --> 01:07:21,203
&lrm;在缅甸 人们想到网络时

1166
01:07:21.287 --> 01:07:22,913
&lrm;他们想到的 是脸书

1167
01:07:22.997 --> 01:07:25,916
&lrm;经常发生的事情是 人们买了手机

1168
01:07:26.000 --> 01:07:29,920
&lrm;手机店主会提前帮他们下载好脸书

1169
01:07:30.004 --> 01:07:31,505
&lrm;帮他们开好账户

1170
01:07:31.589 --> 01:07:34,884
&lrm;于是人们拿到手机之后
&lrm;第一个打开的应用

1171
01:07:34.967 --> 01:07:37,595
&lrm;他们唯一知道怎样打开的 就是脸书

1172
01:07:38.179 --> 01:07:41,891
&lrm;一个新的震惊调查显示
&lrm;脸书日益增长的

1173
01:07:41.974 --> 01:07:43,809
&lrm;对抗缅甸仇恨言论的难题

1174
01:07:43.893 --> 01:07:46,020
&lrm;（停止杀害穆斯林）

1175
01:07:46.103 --> 01:07:49,190
&lrm;脸书真的给军人和其他不良人士

1176
01:07:49.273 --> 01:07:51,776
&lrm;一种控制公众言论的新手段

1177
01:07:51.859 --> 01:07:55,529
&lrm;并协助煽动
&lrm;针对罗兴亚族穆斯林的暴力

1178
01:07:55.613 --> 01:07:57,406
&lrm;包括大屠杀

1179
01:07:58.115 --> 01:07:59,867
&lrm;焚烧整个村庄

1180
01:07:59.950 --> 01:08:03,704
&lrm;违反人道主义的
&lrm;大规模强奸和其他严重犯罪行为

1181
01:08:03.788 --> 01:08:08,209
&lrm;已经导致七十万罗兴亚族穆斯林
&lrm;逃出这个国家

1182
01:08:11.170 --> 01:08:16,550
&lrm;这种情绪高涨的鼓吹
&lrm;以前并不是没有出现过

1183
01:08:16.634 --> 01:08:19,762
&lrm;只是这个平台实现了

1184
01:08:19.845 --> 01:08:23,724
&lrm;让操纵性言论传播变得异常容易

1185
01:08:23.808 --> 01:08:25,434
&lrm;也不用花多少钱

1186
01:08:25.518 --> 01:08:27,812
&lrm;如果我想操纵竞选

1187
01:08:27.895 --> 01:08:30,564
&lrm;我现在可以去脸书上的
&lrm;一个阴谋论小组

1188
01:08:30.648 --> 01:08:32,233
&lrm;可以找到一百个人

1189
01:08:32.316 --> 01:08:34,443
&lrm;他们深信地球是平的

1190
01:08:34.860 --> 01:08:37,780
&lrm;认为我们登月 完全是阴谋论

1191
01:08:37.863 --> 01:08:41,450
&lrm;我可以告诉脸书
&lrm;“给我推荐一千个这种用户”

1192
01:08:42.118 --> 01:08:46,080
&lrm;脸书会非常开心地发给我
&lrm;几千个这种用户

1193
01:08:46.163 --> 01:08:49,250
&lrm;我现在可以给他们讲更多的阴谋论

1194
01:08:51.168 --> 01:08:52,837
&lrm;以3.4美分卖了一个印象

1195
01:08:53.379 --> 01:08:54,922
&lrm;推广新的极端中心

1196
01:08:55.005 --> 01:08:56,048
&lrm;再安排一个广告

1197
01:08:58.509 --> 01:09:02,138
&lrm;算法和操纵人的政治家
&lrm;在学习如何激发我们的方面

1198
01:09:02.221 --> 01:09:04,056
&lrm;变得非常专业

1199
01:09:04.140 --> 01:09:08,352
&lrm;非常擅长制造我们容易接受的
&lrm;虚假新闻 假装这就是事实

1200
01:09:08.435 --> 01:09:10,813
&lrm;给我们造成混乱
&lrm;让我们相信这些谎言

1201
01:09:10.896 --> 01:09:14,150
&lrm;我们似乎对自己是怎样的人
&lrm;自己的信仰 有越来越少的控制权

1202
01:09:31.458 --> 01:09:32,668
&lrm;…来让他们选择站队

1203
01:09:32.751 --> 01:09:34,879
&lrm;到处都是谎言

1204
01:09:34.962 --> 01:09:39,967
&lrm;这样他们就能保持住权力
&lrm;这样他们就能控制一切

1205
01:09:40.050 --> 01:09:44,555
&lrm;他们可以控制我们的思想
&lrm;这样他们就可以保守他们的秘密

1206
01:09:44.638 --> 01:09:46,390
&lrm;（质疑真相）

1207
01:09:46.473 --> 01:09:48,517
&lrm;（疾控中心承认掩盖疫苗/自闭症）

1208
01:09:48.601 --> 01:09:50,895
&lrm;想象一个没有人相信任何真相的世界

1209
01:09:50.978 --> 01:09:53,314
&lrm;（疫苗不普适所有人
&lrm;我们的基因就是证据）

1210
01:09:53.397 --> 01:09:55,649
&lrm;所有人都相信 政府在骗他们

1211
01:09:56.317 --> 01:09:58,444
&lrm;一切都是阴谋论

1212
01:09:58.527 --> 01:10:01,197
&lrm;“我不应该相信任何人
&lrm;我痛恨对立面”

1213
01:10:01.280 --> 01:10:02,698
&lrm;一切正在向这个方向发展

1214
01:10:02.781 --> 01:10:06,160
&lrm;欧洲的政治地震 余震不止

1215
01:10:06.243 --> 01:10:08,412
&lrm;这一次 轮到了意大利和西班牙

1216
01:10:08.495 --> 01:10:11,999
&lrm;整体上来说 欧洲传统的
&lrm;中间派联合政府失去了大多数人支持

1217
01:10:12.082 --> 01:10:15,002
&lrm;同时极左和极右民粹主义政党
&lrm;获得更多支持

1218
01:10:17.588 --> 01:10:19,048
&lrm;（中心）

1219
01:10:19.757 --> 01:10:20,591
&lrm;退后

1220
01:10:21.675 --> 01:10:22,509
&lrm;好  我们走

1221
01:10:28.390 --> 01:10:31,268
&lrm;这些账户专门故意试图

1222
01:10:31.352 --> 01:10:33,896
&lrm;散播香港政治纷争信息

1223
01:10:38.609 --> 01:10:39,610
&lrm;好 本

1224
01:10:42.863 --> 01:10:45,032
&lrm;生活在一个全部信息来自于脸书

1225
01:10:45.115 --> 01:10:48,410
&lrm;和社交媒体的国家 是什么感觉？

1226
01:10:48.953 --> 01:10:50,871
&lrm;民主迅速崩溃

1227
01:10:50.955 --> 01:10:51,830
&lrm;六个月

1228
01:10:51.914 --> 01:10:53,791
&lrm;芝加哥的混乱发生后

1229
01:10:53.874 --> 01:10:57,044
&lrm;抗议者和支持者之间的暴力冲突…

1230
01:10:58.003 --> 01:11:01,632
&lrm;民主正面临着信心危机

1231
01:11:01.715 --> 01:11:04,343
&lrm;我们看到的 是对全球民主的攻击

1232
01:11:04.426 --> 01:11:05,427
&lrm;（极端中心）

1233
01:11:05.511 --> 01:11:07,930
&lrm;多数目标国家 都是

1234
01:11:08.013 --> 01:11:09,723
&lrm;进行民主选举的国家

1235
01:11:10.641 --> 01:11:12,518
&lrm;大范围发生

1236
01:11:12.601 --> 01:11:15,562
&lrm;国家行动者、家财万贯的富翁说

1237
01:11:15.646 --> 01:11:18,524
&lrm;“我想让肯尼亚动摇
&lrm;我想让喀麦隆动摇

1238
01:11:18.607 --> 01:11:20,651
&lrm;安哥拉？只要这么一点钱”

1239
01:11:20.734 --> 01:11:23,362
&lrm;巴西上周日举行了一场特别的选举

1240
01:11:23.445 --> 01:11:25,823
&lrm;选举动员是社交媒体驱动的

1241
01:11:31.036 --> 01:11:33,956
&lrm;我们技术产业的人创造了

1242
01:11:34.039 --> 01:11:37,418
&lrm;动摇和侵蚀社会结构的工具

1243
01:11:37.501 --> 01:11:40,254
&lrm;所有国家都在同时发生
&lrm;世界各地都在发生

1244
01:11:40.337 --> 01:11:44,508
&lrm;德国、西班牙、法国
&lrm;巴西、澳大利亚都有发生

1245
01:11:44.591 --> 01:11:46,927
&lrm;一些世界上最发达的国家

1246
01:11:47.428 --> 01:11:49,221
&lrm;正在互相爆破

1247
01:11:49.305 --> 01:11:50,931
&lrm;他们有什么共同点？

1248
01:11:51.974 --> 01:11:52,975
&lrm;基于你当前的了解

1249
01:11:53.058 --> 01:11:56,312
&lrm;你相信脸书
&lrm;影响了2016年大选的结果吗？

1250
01:11:56.854 --> 01:11:58,188
&lrm;这个问题好难回答

1251
01:11:58.897 --> 01:11:59,773
&lrm;你知道 这个…

1252
01:12:01.275 --> 01:12:04,653
&lrm;事实是
&lrm;有很多不同的力量在产生影响

1253
01:12:04.737 --> 01:12:07,865
&lrm;脸书、推特和谷歌的代表们
&lrm;回到国会山

1254
01:12:07.948 --> 01:12:09,450
&lrm;对俄罗斯干预2016年大选问题

1255
01:12:09.533 --> 01:12:12,578
&lrm;进行第二天的证词发言

1256
01:12:12.661 --> 01:12:17,291
&lrm;第三方政党的操纵没有黑入

1257
01:12:18.500 --> 01:12:21,462
&lrm;对吧？俄罗斯没有黑入脸书

1258
01:12:21.545 --> 01:12:27,843
&lrm;他们所做的是 利用脸书
&lrm;为合法广告商与合法用户创造的工具

1259
01:12:27.926 --> 01:12:30,346
&lrm;用到了罪恶的用途中

1260
01:12:32.014 --> 01:12:33,891
&lrm;就像是远程控制的战争

1261
01:12:34.475 --> 01:12:36,602
&lrm;一个国家可以操纵另一个国家

1262
01:12:36.685 --> 01:12:39,229
&lrm;都不用真正入侵实体边境

1263
01:12:39.605 --> 01:12:40,981
&lrm;我们看到这些暴力的画面

1264
01:12:41.065 --> 01:12:43,317
&lrm;这是一个被推来推去的垃圾箱…

1265
01:12:43.400 --> 01:12:45,736
&lrm;但问题不是你想投票给谁

1266
01:12:46.362 --> 01:12:50,574
&lrm;问题是在社会中散播混乱和分歧

1267
01:12:50.657 --> 01:12:53,035
&lrm;这是在霍廷顿海滩市的示威…

1268
01:12:53.118 --> 01:12:54,870
&lrm;问题是制造了两个对立面

1269
01:12:54.953 --> 01:12:56,413
&lrm;丝毫不再听取对方的观点

1270
01:12:56.497 --> 01:12:58,123
&lrm;不再想听对方的观点

1271
01:12:58.207 --> 01:12:59,875
&lrm;不再相信对方

1272
01:12:59.958 --> 01:13:02,252
&lrm;这是仇恨被暴露出

1273
01:13:03.295 --> 01:13:05,464
&lrm;并转化成种族暴力的城市

1274
01:13:05.547 --> 01:13:07,925
&lrm;（弗吉尼亚紧张局势
&lrm;暴力当天致三人遇害）

1275
01:13:20.145 --> 01:13:20,979
&lrm;本！

1276
01:13:21.605 --> 01:13:22,439
&lrm;卡桑德拉！

1277
01:13:22.981 --> 01:13:23,816
&lrm;-卡桑！
&lrm;-本！

1278
01:13:23.899 --> 01:13:25,484
&lrm;过来！

1279
01:13:27.486 --> 01:13:31,156
&lrm;举起手 膝盖跪地 快 跪下

1280
01:13:36.120 --> 01:13:37,204
&lrm;-冷静……
&lrm;-本！

1281
01:13:37.287 --> 01:13:38,414
&lrm;喂！手举起来！

1282
01:13:39.623 --> 01:13:41,291
&lrm;转过去 趴地上

1283
01:13:56.807 --> 01:13:59,643
&lrm;我们希望这个系统
&lrm;售卖出最高的竞价吗？

1284
01:14:01.437 --> 01:14:05,399
&lrm;完全出售民主
&lrm;你可以控制任何你想控制的思想

1285
01:14:05.482 --> 01:14:08,694
&lrm;对特定人群设定谎言
&lrm;制造文化战争？

1286
01:14:09.236 --> 01:14:10,237
&lrm;我们希望这样吗？

1287
01:14:14.783 --> 01:14:16,201
&lrm;我们这个国家的人民…

1288
01:14:16.952 --> 01:14:18,620
&lrm;不再和彼此说话了

1289
01:14:20.080 --> 01:14:23,000
&lrm;我们这个国家的人民
&lrm;不再和彼此交友了

1290
01:14:23.083 --> 01:14:25,127
&lrm;只因为他们在上一次竞选中投票的人

1291
01:14:26.044 --> 01:14:28,422
&lrm;我们这个国家的人民孤立了自己

1292
01:14:28.505 --> 01:14:30,966
&lrm;只看认同我们的那些频道

1293
01:14:32.259 --> 01:14:35,888
&lrm;我今天想传达的信息是
&lrm;部落主义正在毁掉我们

1294
01:14:37.556 --> 01:14:39,183
&lrm;它正在撕裂我们这个国家

1295
01:14:40.267 --> 01:14:43,103
&lrm;正常的成年人 不可能这样做

1296
01:14:43.187 --> 01:14:45,314
&lrm;如果每个人都有权执着于自己的真相

1297
01:14:45.397 --> 01:14:49,401
&lrm;就真没有必要妥协
&lrm;没有必要让人们团结了

1298
01:14:49.485 --> 01:14:51,695
&lrm;事实上 真的没有必要让人们互动

1299
01:14:52.321 --> 01:14:56,617
&lrm;我们需要对现实有一些共同的理解

1300
01:14:57.201 --> 01:14:58,410
&lrm;不然 我们就不是一个国家了

1301
01:14:58.494 --> 01:14:59,495
&lrm;（扎克伯格先生）

1302
01:14:59.578 --> 01:15:02,998
&lrm;所以长期来看 解决办法
&lrm;是建造更多的人工智能工具

1303
01:15:03.081 --> 01:15:08,128
&lrm;找到人们使用这些服务的行为模式
&lrm;这是任何一个真人都做不到的

1304
01:15:08.212 --> 01:15:11,840
&lrm;我们允许技术专家 把这个当做一个

1305
01:15:11.924 --> 01:15:13,884
&lrm;他们有能力解决的问题呈现

1306
01:15:15.135 --> 01:15:16,470
&lrm;这是骗人的

1307
01:15:17.679 --> 01:15:20,724
&lrm;人们谈论人工智能
&lrm;好像人工智能知道真理一样

1308
01:15:21.683 --> 01:15:23,685
&lrm;人工智能无法解决这些问题

1309
01:15:24.269 --> 01:15:27,189
&lrm;人工智能无法解决虚假新闻的问题

1310
01:15:28.649 --> 01:15:31,026
&lrm;谷歌没有选择去说

1311
01:15:31.109 --> 01:15:34,154
&lrm;“这是阴谋论？这是真相吗？”

1312
01:15:34.696 --> 01:15:36,240
&lrm;因为它们不知道 真相是什么

1313
01:15:36.823 --> 01:15:40,410
&lrm;它们没有真相的代理服务器
&lrm;只有点击

1314
01:15:41.870 --> 01:15:45,123
&lrm;如果我们不同意真相

1315
01:15:45.207 --> 01:15:47,584
&lrm;或者不同意存在真相

1316
01:15:48.293 --> 01:15:49,294
&lrm;我们就完蛋了

1317
01:15:49.753 --> 01:15:52,089
&lrm;这是其他问题之下的问题

1318
01:15:52.172 --> 01:15:54,424
&lrm;因为如果我们不能认同真相

1319
01:15:55.092 --> 01:15:57,803
&lrm;那我们就无法找到
&lrm;我们任何一个问题的解决方法

1320
01:16:05.435 --> 01:16:07,729
&lrm;我们应该建议他
&lrm;关注平面地球足球俱乐部

1321
01:16:07.813 --> 01:16:10,107
&lrm;别再给他展示运动消息了
&lrm;他不感兴趣

1322
01:16:39.970 --> 01:16:42,764
&lrm;硅谷的很多人相信一种理论

1323
01:16:42.848 --> 01:16:45,225
&lrm;我们正在建造一些全球的超级大脑

1324
01:16:45.309 --> 01:16:48,020
&lrm;我们所有的用户
&lrm;都只是可交互的神经元

1325
01:16:48.103 --> 01:16:49,563
&lrm;他们一点都不重要

1326
01:16:50.230 --> 01:16:53,150
&lrm;它让人们服从于这样一个奇怪的角色

1327
01:16:53.233 --> 01:16:56,069
&lrm;你就像是一个小的编程元素

1328
01:16:56.153 --> 01:16:58,905
&lrm;我们通过我们的行为操纵去 编程

1329
01:16:58.989 --> 01:17:02,367
&lrm;为了服务于这个巨型大脑
&lrm;你根本不重要

1330
01:17:02.451 --> 01:17:04,911
&lrm;不会给你钱 不会告诉你真相

1331
01:17:04.995 --> 01:17:06,455
&lrm;你没有自主权

1332
01:17:06.538 --> 01:17:09,374
&lrm;我们会鬼祟地操纵你
&lrm;因为你是编程中的结点

1333
01:17:09.458 --> 01:17:12,336
&lrm;所以我们需要将你编程
&lrm;因为我们就要这样对待编程中的结点

1334
01:17:20.093 --> 01:17:21,094
&lrm;天啊

1335
01:17:21.928 --> 01:17:25,390
&lrm;当你想到技术
&lrm;技术是一种人类存亡的威胁

1336
01:17:25.474 --> 01:17:28,060
&lrm;这个指控很严重…

1337
01:17:29.603 --> 01:17:33,982
&lrm;然后你的脑中就会很容易想
&lrm;“好 我正在拿着手机

1338
01:17:35.609 --> 01:17:37,235
&lrm;互动、点击、使用

1339
01:17:37.319 --> 01:17:39,196
&lrm;人类存亡的威胁在哪里？

1340
01:17:40.280 --> 01:17:41,615
&lrm;好 有一个超级电脑

1341
01:17:41.698 --> 01:17:43,950
&lrm;在屏幕的另一端 正指向我的大脑

1342
01:17:44.409 --> 01:17:47,537
&lrm;让我再看一个视频
&lrm;人类存亡的威胁在哪里？”

1343
01:17:54.252 --> 01:17:59,341
&lrm;技术并不是人类存亡的威胁

1344
01:18:02.636 --> 01:18:04,346
&lrm;（劝服性技术 美国参议院听政会）

1345
01:18:04.429 --> 01:18:08,850
&lrm;是技术能够把
&lrm;社会中最坏的东西带出来的能力

1346
01:18:09.559 --> 01:18:13,522
&lrm;社会中最坏的东西
&lrm;才是人类存亡的威胁

1347
01:18:13.605 --> 01:18:15,899
&lrm;（美国参议院）

1348
01:18:18.819 --> 01:18:23,115
&lrm;如果技术创造了公众混乱

1349
01:18:23.198 --> 01:18:24,533
&lrm;愤怒、无礼

1350
01:18:24.616 --> 01:18:26,326
&lrm;彼此缺乏信任

1351
01:18:27.452 --> 01:18:30,622
&lrm;孤独、疏远、更加两极分化

1352
01:18:30.706 --> 01:18:33,333
&lrm;更多大选黑入、更多平民政治

1353
01:18:33.917 --> 01:18:36,962
&lrm;让人更加分散注意力
&lrm;无法集中在真正的问题上…

1354
01:18:37.963 --> 01:18:39,214
&lrm;那只是社会

1355
01:18:40.340 --> 01:18:46,388
&lrm;现在社会无法自愈

1356
01:18:46.471 --> 01:18:48,515
&lrm;转移成了一种混乱的形式

1357
01:18:51.977 --> 01:18:54,938
&lrm;这影响着每一个人
&lrm;即使你不使用这些产品

1358
01:18:55.021 --> 01:18:57,524
&lrm;这些事情变成了数码的科学怪人

1359
01:18:57.607 --> 01:19:00,068
&lrm;让这个世界变成他们现象中的样子

1360
01:19:00.152 --> 01:19:01,862
&lrm;不论是儿童的心理健康

1361
01:19:01.945 --> 01:19:04,489
&lrm;还是我们的政治 我们的政治演说

1362
01:19:04.573 --> 01:19:07,492
&lrm;而不用因为控制公众舆论
&lrm;承担责任

1363
01:19:07.576 --> 01:19:10,579
&lrm;-所以 还是要回到…
&lrm;-你觉得这一切怪谁？

1364
01:19:10.662 --> 01:19:13,582
&lrm;我认为我们必须让平台负起责任

1365
01:19:13.665 --> 01:19:15,584
&lrm;因为他们接管大选广告的时候

1366
01:19:15.667 --> 01:19:17,794
&lrm;就要负责保护大选

1367
01:19:17.878 --> 01:19:20,380
&lrm;当他们接管儿童心理健康
&lrm;或是儿童频道的时候

1368
01:19:20.464 --> 01:19:22,716
&lrm;他们就有责任保护好儿童频道

1369
01:19:23.717 --> 01:19:27,929
&lrm;保持人们关注的竞争不会结束

1370
01:19:28.388 --> 01:19:31,850
&lrm;我们的技术会在我们生活中更加集成
&lrm;而不会减少

1371
01:19:31.933 --> 01:19:34,895
&lrm;人工智能会更加擅长预判
&lrm;什么内容能让我们持续盯着屏幕

1372
01:19:34.978 --> 01:19:37,105
&lrm;而不是做出更差的预判

1373
01:19:38.940 --> 01:19:42,027
&lrm;我已经62岁了

1374
01:19:42.110 --> 01:19:45,155
&lrm;随着这个对话继续进行
&lrm;我每一分钟都在变老

1375
01:19:45.238 --> 01:19:47,365
&lrm;但我会告诉你

1376
01:19:48.700 --> 01:19:52,370
&lrm;到时候我可能已经死了 不在了
&lrm;但我可能会为此感恩

1377
01:19:52.454 --> 01:19:54,331
&lrm;因为当这些恐怖的东西结出恶果

1378
01:19:54.790 --> 01:19:59,586
&lrm;我觉得能吓死我

1379
01:20:00.921 --> 01:20:03,048
&lrm;你也这样看吗？

1380
01:20:03.548 --> 01:20:06,885
&lrm;还是我对一个我不够了解的情况
&lrm;过度反应了？

1381
01:20:09.930 --> 01:20:11,598
&lrm;你最担心什么？

1382
01:20:15.519 --> 01:20:18,480
&lrm;我认为在最短的时间范围内…

1383
01:20:19.523 --> 01:20:20,524
&lrm;是内战

1384
01:20:24.444 --> 01:20:29,908
&lrm;如果现在的常态继续下去
&lrm;我们说再过20年

1385
01:20:31.117 --> 01:20:34,579
&lrm;我们很可能会因为故意无知
&lrm;毁掉我们的文明

1386
01:20:34.663 --> 01:20:37,958
&lrm;我们或许会无法应对气候变化的挑战

1387
01:20:38.041 --> 01:20:42,087
&lrm;我们或许会瓦解世界的民主

1388
01:20:42.170 --> 01:20:46,132
&lrm;最终衰落成一种奇怪的独裁机能障碍

1389
01:20:46.216 --> 01:20:48,426
&lrm;我们或许会毁掉全球经济

1390
01:20:49.177 --> 01:20:52,264
&lrm;我们或许会无法存活

1391
01:20:52.347 --> 01:20:54,808
&lrm;我真的把它看做
&lrm;人类生死存亡的大问题

1392
01:21:02.524 --> 01:21:04,985
&lrm;这会是知道在这种幻象发生之前

1393
01:21:05.068 --> 01:21:08,488
&lrm;世界是什么样的最后一代人吗？

1394
01:21:11.074 --> 01:21:14,578
&lrm;如果你不知道自己在矩阵中
&lrm;你要怎么从矩阵中醒来？

1395
01:21:17.747 --> 01:21:23,253
&lrm;（“不论是乌托邦还是毁灭
&lrm;都是一场一触即发的接力赛…）

1396
01:21:23.336 --> 01:21:27,299
&lrm;（直接通往最后一刻…”
&lrm;——巴克敏斯特·富勒）

1397
01:21:27.382 --> 01:21:30,635
&lrm;你知道 我们说的很多话
&lrm;听起来像是…

1398
01:21:31.511 --> 01:21:33,680
&lrm;片面的悲观

1399
01:21:33.763 --> 01:21:36,808
&lrm;“天啊 技术正在毁灭世界

1400
01:21:36.892 --> 01:21:38,059
&lrm;正在毁灭孩子们”

1401
01:21:38.143 --> 01:21:39,269
&lrm;不是这样的

1402
01:21:40.228 --> 01:21:45,567
&lrm;这很困惑
&lrm;因为这同时是乌托邦和毁灭

1403
01:21:45.942 --> 01:21:50,447
&lrm;我可以在手机按一个按钮
&lrm;30秒后就能出现一辆车

1404
01:21:50.530 --> 01:21:52,699
&lrm;我就可以去想去的任何地方

1405
01:21:52.782 --> 01:21:55,660
&lrm;这简直是魔法 太神奇了

1406
01:21:56.161 --> 01:21:57,662
&lrm;我们制作“点赞”按钮的时候

1407
01:21:57.746 --> 01:22:01,499
&lrm;我们全部的动机是 “我们可以
&lrm;在世界中传播积极和爱吗？”

1408
01:22:01.583 --> 01:22:05,003
&lrm;时间快进到当下
&lrm;青少年会因为没有得到足够多的点赞

1409
01:22:05.086 --> 01:22:06,379
&lrm;而抑郁 这个想法

1410
01:22:06.463 --> 01:22:08,632
&lrm;或者会导致政治两极分化

1411
01:22:08.715 --> 01:22:09,883
&lrm;当时是完全无法想象的

1412
01:22:09.966 --> 01:22:12,135
&lrm;我不认为这些人
&lrm;最开始的目标是邪恶的

1413
01:22:13.511 --> 01:22:15,764
&lrm;只是这个商业模式有问题

1414
01:22:15.847 --> 01:22:20,226
&lrm;你可以关掉服务 毁掉不管这是什么

1415
01:22:20.310 --> 01:22:24,522
&lrm;200亿美元的股东利益 被起诉…

1416
01:22:24.606 --> 01:22:27,108
&lrm;但现实是 覆水难收

1417
01:22:27.192 --> 01:22:30,403
&lrm;你可以做出一些小的调整 但是最终

1418
01:22:30.487 --> 01:22:34,032
&lrm;你要增加收益和使用
&lrm;每一个季度都要增加

1419
01:22:34.658 --> 01:22:37,535
&lrm;规模做得越大 越难让任何人改变

1420
01:22:38.495 --> 01:22:43,458
&lrm;我看到的是一群被困住的人
&lrm;被商业模式

1421
01:22:43.541 --> 01:22:46,169
&lrm;经济奖励和股东压力困住

1422
01:22:46.252 --> 01:22:48,922
&lrm;几乎无法做其他的任何事情

1423
01:22:49.005 --> 01:22:50,924
&lrm;我认为我们应该接受

1424
01:22:51.007 --> 01:22:53,176
&lrm;公司专注于挣钱 是合情合理的

1425
01:22:53.259 --> 01:22:56,888
&lrm;不合情合理的是
&lrm;当没有监管、没有规定、没有竞争

1426
01:22:56.972 --> 01:23:00,850
&lrm;公司在充当实际政府部门

1427
01:23:00.934 --> 01:23:03,353
&lrm;然后他们说“我们可以监管自己”

1428
01:23:03.436 --> 01:23:05,981
&lrm;这肯定是骗人的 怎么可能呢

1429
01:23:06.064 --> 01:23:09,150
&lrm;经济奖励可以说运营着世界

1430
01:23:09.234 --> 01:23:15,573
&lrm;所以这个问题的任何解决方案
&lrm;一定要符合经济奖励

1431
01:23:16.074 --> 01:23:18,785
&lrm;这些公司没有需要改变的财政理由

1432
01:23:18.868 --> 01:23:21,329
&lrm;所以我才认为 我们需要监管

1433
01:23:21.413 --> 01:23:24,290
&lrm;手机公司有无数的关于你的敏感数据

1434
01:23:24.374 --> 01:23:27,544
&lrm;我们有很多法律去保证
&lrm;他们不会利用这些数据做错事

1435
01:23:27.627 --> 01:23:31,506
&lrm;在数码隐私上 我们几乎没有立法

1436
01:23:31.589 --> 01:23:34,426
&lrm;我们可以对数据收集和处理收税

1437
01:23:34.509 --> 01:23:37,554
&lrm;原理等同于你交水费

1438
01:23:37.637 --> 01:23:39,723
&lrm;监控你自己的用水量

1439
01:23:39.806 --> 01:23:43,226
&lrm;让这些公司因为持有的数据资产交税

1440
01:23:43.309 --> 01:23:44,769
&lrm;就能给他们一个财政理由

1441
01:23:44.853 --> 01:23:47,856
&lrm;不去获取地球上每一条数据

1442
01:23:47.939 --> 01:23:50,567
&lrm;立法在这方面太落后了

1443
01:23:50.650 --> 01:23:55,864
&lrm;但据我所知 当前状况的存在
&lrm;不是为了保护用户

1444
01:23:55.947 --> 01:23:58,700
&lrm;而是为了保护这些巨型的

1445
01:23:58.783 --> 01:24:01,453
&lrm;超级富有公司的权利和特权

1446
01:24:02.245 --> 01:24:05,832
&lrm;我们要一直听从最有钱
&lrm;最有权力的人吗？

1447
01:24:05.915 --> 01:24:07,417
&lrm;还是我们要说

1448
01:24:07.959 --> 01:24:12,047
&lrm;“有时候 确实是有国家利益

1449
01:24:12.130 --> 01:24:15,592
&lrm;有时候 人民的利益 用户利益

1450
01:24:15.675 --> 01:24:17,385
&lrm;其实比一个

1451
01:24:18.011 --> 01:24:21,473
&lrm;已经是亿万富翁的人的利益
&lrm;更加重要？”

1452
01:24:21.890 --> 01:24:26,603
&lrm;这些市场削弱了民主 削弱了自由

1453
01:24:26.686 --> 01:24:28,521
&lrm;应该对他们进行法律的制裁

1454
01:24:29.147 --> 01:24:31,816
&lrm;这不是激进的提议

1455
01:24:31.900 --> 01:24:34,194
&lrm;我们有法律制裁的其他市场

1456
01:24:34.277 --> 01:24:36,988
&lrm;我们制裁人类器官贩卖市场

1457
01:24:37.072 --> 01:24:39,491
&lrm;我们制裁人类奴隶市场

1458
01:24:39.949 --> 01:24:44,037
&lrm;因为它们都有不可避免的破坏性后果

1459
01:24:44.537 --> 01:24:45,830
&lrm;我们生活的世界

1460
01:24:45.914 --> 01:24:50,001
&lrm;死去的树比活着的树更有经济价值

1461
01:24:50.085 --> 01:24:53,838
&lrm;这个世界 死去的鲸
&lrm;比活着的鲸更有价值

1462
01:24:53.922 --> 01:24:56,341
&lrm;只要我们的经济这样运转

1463
01:24:56.424 --> 01:24:58,134
&lrm;公司不受监管

1464
01:24:58.218 --> 01:25:00,678
&lrm;它们就会继续破坏树木

1465
01:25:00.762 --> 01:25:01,763
&lrm;继续捕杀鲸

1466
01:25:01.846 --> 01:25:06,101
&lrm;在地球上挖矿 从地下抽石油

1467
01:25:06.184 --> 01:25:08,394
&lrm;虽然我们知道 这样做会破坏地球

1468
01:25:08.478 --> 01:25:12,148
&lrm;我们知道 这样做会为未来几代人
&lrm;留下一个更不堪的世界

1469
01:25:12.232 --> 01:25:13,858
&lrm;这是目光短浅

1470
01:25:13.942 --> 01:25:16,694
&lrm;为了利益牺牲一切的信仰

1471
01:25:16.778 --> 01:25:20,156
&lrm;指望每个
&lrm;只顾自己私利的公司会突然神奇地

1472
01:25:20.240 --> 01:25:21,950
&lrm;去产生最好的结果

1473
01:25:22.033 --> 01:25:24,494
&lrm;这已经影响环境很久了

1474
01:25:24.577 --> 01:25:27,288
&lrm;恐怖的是 希望这是
&lrm;压倒骆驼的最后一根稻草

1475
01:25:27.372 --> 01:25:29,207
&lrm;让我们作为文明的种族 去幡然醒悟 

1476
01:25:29.290 --> 01:25:31,709
&lrm;这个理论最初就有很多缺点

1477
01:25:31.793 --> 01:25:35,004
&lrm;让我们看到 我们现在就是树 就是鲸

1478
01:25:35.088 --> 01:25:37,048
&lrm;我们的关注就是被挖掘的矿产

1479
01:25:37.132 --> 01:25:39,134
&lrm;如果我们花时间盯着一个屏幕

1480
01:25:39.217 --> 01:25:41,594
&lrm;盯着一个广告 对公司而言

1481
01:25:41.678 --> 01:25:42,971
&lrm;比我们用这个时间

1482
01:25:43.054 --> 01:25:45,890
&lrm;过自己丰富的生活 更加有利可图

1483
01:25:45.974 --> 01:25:47,559
&lrm;我们看到了这样的后果

1484
01:25:47.642 --> 01:25:50,687
&lrm;我们看到公司利用强大的人工智能

1485
01:25:50.770 --> 01:25:53,523
&lrm;凌驾在我们的智能之上
&lrm;研究怎样拉拢我们的关注

1486
01:25:53.606 --> 01:25:55,358
&lrm;让我们去看 他们想让我们看的东西

1487
01:25:55.441 --> 01:25:57,277
&lrm;而不是让我们看
&lrm;与我们目标、价值观

1488
01:25:57.360 --> 01:25:59,237
&lrm;与我们的生活最为一致的东西

1489
01:26:02.991 --> 01:26:04,450
&lrm;（史蒂夫·乔布斯 今日演讲者）

1490
01:26:05.535 --> 01:26:06,911
&lrm;电脑对我来说 是…

1491
01:26:06.995 --> 01:26:10,290
&lrm;是我们人类历史上 最神奇的发明

1492
01:26:11.124 --> 01:26:13,877
&lrm;相当于是我们思想的自行车

1493
01:26:15.628 --> 01:26:20,091
&lrm;人道技术的创想 是硅谷最初的目标

1494
01:26:21.050 --> 01:26:25,722
&lrm;我们已经背离了这个目标
&lrm;因为这样做比较酷

1495
01:26:25.805 --> 01:26:27,265
&lrm;而不是这样做比较正确

1496
01:26:27.348 --> 01:26:29,726
&lrm;网络就是一个奇怪的、可笑的地方

1497
01:26:29.809 --> 01:26:31,394
&lrm;它是实验性的

1498
01:26:31.477 --> 01:26:34,731
&lrm;网络上发生着有创意的事情
&lrm;当然现在也有发生

1499
01:26:34.814 --> 01:26:38,610
&lrm;但是感觉像一个巨大的商场

1500
01:26:38.693 --> 01:26:44,157
&lrm;就是“天啊
&lrm;肯定不止表面上这么简单”

1501
01:26:46.743 --> 01:26:48,411
&lrm;我想我只是一个乐观主义者

1502
01:26:48.494 --> 01:26:52,040
&lrm;因为我认为
&lrm;我们可以改变社交媒体的样子和方式

1503
01:26:54.083 --> 01:26:57,921
&lrm;技术的工作方式不是物理学定律
&lrm;它不是一成不变的

1504
01:26:58.004 --> 01:27:02,175
&lrm;这些都是像我这样的人类
&lrm;做出的选择

1505
01:27:02.759 --> 01:27:05,345
&lrm;人类可以改变这些技术

1506
01:27:06.971 --> 01:27:09,974
&lrm;现在的问题是 我们是否愿意承认

1507
01:27:10.475 --> 01:27:15,438
&lrm;这些后果 是我们杰作的直接产物

1508
01:27:21.027 --> 01:27:24,864
&lrm;这些东西是我们建立起来的
&lrm;我们有责任去改变它们

1509
01:27:37.210 --> 01:27:42,298
&lrm;提取关注模型
&lrm;不是我们想对待人类的方式

1510
01:27:46.094 --> 01:27:48,137
&lrm;只有我这样想吗？还是…

1511
01:27:49.847 --> 01:27:50,848
&lrm;可悲的人

1512
01:27:51.516 --> 01:27:53,226
&lrm;一个健康社会的结构

1513
01:27:53.309 --> 01:27:56,145
&lrm;要依靠我们脱离这种
&lrm;有破坏性的商业模型

1514
01:28:04.696 --> 01:28:07,782
&lrm;我们可以要求
&lrm;这些产品进行人道设计

1515
01:28:09.409 --> 01:28:13,121
&lrm;我们可以要求
&lrm;不被当做可以提取的资源对待

1516
01:28:15.164 --> 01:28:18,334
&lrm;我们的动机可以是
&lrm;“我们怎样让这个世界变得更好？”

1517
01:28:20.461 --> 01:28:23,798
&lrm;在整个人类历史中
&lrm;每一次有事物变得更好

1518
01:28:23.881 --> 01:28:26,342
&lrm;都是因为有人站出来说

1519
01:28:26.426 --> 01:28:28,428
&lrm;“这太蠢了 我们可以做得更好”

1520
01:28:29.178 --> 01:28:32,557
&lrm;是批判者驱动着改进

1521
01:28:33.141 --> 01:28:35,393
&lrm;批判者才是真正的乐观主义者

1522
01:28:38.313 --> 01:28:39,147
&lrm;你好

1523
01:28:46.195 --> 01:28:47,697
&lrm;感觉有点疯狂 是吧？

1524
01:28:47.780 --> 01:28:51,534
&lrm;这东西的设计基本方式

1525
01:28:52.994 --> 01:28:54,704
&lrm;就不会朝着好的方向发展

1526
01:28:55.246 --> 01:28:56,873
&lrm;整个社交媒体

1527
01:28:56.956 --> 01:29:00,626
&lrm;我说要改变这一切
&lrm;听起来有点疯狂

1528
01:29:01.169 --> 01:29:02,670
&lrm;但我们需要这样做

1529
01:29:04.339 --> 01:29:05,923
&lrm;你觉得这一天能实现吗？

1530
01:29:07.383 --> 01:29:08,301
&lrm;必须要实现

1531
01:29:21.314 --> 01:29:24,942
&lrm;你似乎非常乐观

1532
01:29:26.194 --> 01:29:27,195
&lrm;听起来是这样吗？

1533
01:29:27.653 --> 01:29:30,114
&lrm;是 我是说…
&lrm;我无法相信你一直这样说

1534
01:29:30.198 --> 01:29:33,409
&lrm;因为我在想：“真的吗？” 我感觉
&lrm;我们正走向毁灭 而不是乌托邦

1535
01:29:33.493 --> 01:29:35,328
&lrm;我感觉我们正在飞速走向毁灭

1536
01:29:35.411 --> 01:29:37,830
&lrm;需要一个奇迹
&lrm;才能让我们走下这条路“

1537
01:29:37.914 --> 01:29:40,291
&lrm;这个奇迹当然是集体意识

1538
01:29:41.000 --> 01:29:44,587
&lrm;可我是乐观主义者
&lrm;我们一定会有办法解决

1539
01:29:44.670 --> 01:29:47,048
&lrm;但我认为 可能会用很久的时间

1540
01:29:47.131 --> 01:29:50,385
&lrm;因为不是所有的人都意识到了
&lrm;这是一个问题

1541
01:29:50.468 --> 01:29:55,890
&lrm;我认为当今技术最大的一个失败

1542
01:29:55.973 --> 01:29:58,643
&lrm;是领导力的真正失败

1543
01:29:58.726 --> 01:30:01,979
&lrm;人们站出来 去公开讨论

1544
01:30:02.063 --> 01:30:05,900
&lrm;不仅是哪些地方进行得好
&lrm;还应该讨论哪里不完美

1545
01:30:05.983 --> 01:30:08,194
&lrm;才能让有人介入 构建一些新的东西

1546
01:30:08.277 --> 01:30:10,321
&lrm;最终 你知道

1547
01:30:10.405 --> 01:30:14,617
&lrm;在有足够的公众压力之前
&lrm;这台机器是绝对不会回头的

1548
01:30:14.700 --> 01:30:18,329
&lrm;通过这些对话 发出你的声音

1549
01:30:18.413 --> 01:30:21,082
&lrm;在一些情况下 通过某些特定的技术

1550
01:30:21.165 --> 01:30:24,252
&lrm;我们可以开始改变趋势
&lrm;我们可以开始改变对话

1551
01:30:24.335 --> 01:30:27,004
&lrm;听起来可能有点奇怪
&lrm;但这是我的世界 是我生活的环境

1552
01:30:27.088 --> 01:30:29,632
&lrm;我不恨他们
&lrm;我不想伤害谷歌或者脸书

1553
01:30:29.715 --> 01:30:32,885
&lrm;我只是想改革它们
&lrm;别让他们毁了世界 你知道吗？

1554
01:30:32.969 --> 01:30:35,513
&lrm;我在手机上卸载了很多程序

1555
01:30:35.596 --> 01:30:37,723
&lrm;我感觉那些都是浪费时间

1556
01:30:37.807 --> 01:30:40,685
&lrm;所有的社交媒体程序 所有的新程序

1557
01:30:40.768 --> 01:30:42,520
&lrm;我关掉了通知

1558
01:30:42.603 --> 01:30:45,815
&lrm;所有那些让我手机震动的通知

1559
01:30:45.898 --> 01:30:48,943
&lrm;不够及时 对现在我来说
&lrm;并不重要的信息

1560
01:30:49.026 --> 01:30:51,279
&lrm;也正是因为同样的理由
&lrm;我兜里不放饼干

1561
01:30:51.362 --> 01:30:53,197
&lrm;减少你收到的通知数量

1562
01:30:53.281 --> 01:30:54,449
&lrm;关掉通知

1563
01:30:54.532 --> 01:30:55,950
&lrm;关掉所有应用的通知

1564
01:30:56.033 --> 01:30:58,536
&lrm;我已经不再用谷歌了
&lrm;我用Qwant搜索引擎

1565
01:30:58.619 --> 01:31:01,497
&lrm;这个引擎不会存储你的搜索历史

1566
01:31:01.581 --> 01:31:04,459
&lrm;永远不要接受
&lrm;YouTube上给你推荐的视频

1567
01:31:04.542 --> 01:31:07,003
&lrm;永远自己去选择
&lrm;这是另一个抗争的方式

1568
01:31:07.086 --> 01:31:12,133
&lrm;谷歌浏览器有无数扩展程序
&lrm;可以移走推荐

1569
01:31:12.216 --> 01:31:15,636
&lrm;我很喜欢你推荐一个
&lrm;撤销你所做东西的东西

1570
01:31:15.720 --> 01:31:16,554
&lrm;对

1571
01:31:16.929 --> 01:31:21,642
&lrm;在你分享之前 查找一下事实
&lrm;思考一下信息来源 谷歌搜索一下

1572
01:31:21.726 --> 01:31:25,104
&lrm;如果这个东西感觉像是
&lrm;以触发你的情感按钮为目标

1573
01:31:25.188 --> 01:31:26,314
&lrm;很可能确实是

1574
01:31:26.397 --> 01:31:29,025
&lrm;基本可以说 你用点击去投票

1575
01:31:29.108 --> 01:31:30,359
&lrm;如果你点击了钓鱼链接

1576
01:31:30.443 --> 01:31:33,779
&lrm;你就是在创造一个经济奖励
&lrm;延续这个已经存在的体系

1577
01:31:33.863 --> 01:31:36,949
&lrm;在你的生活中 一定要获得

1578
01:31:37.033 --> 01:31:37,909
&lrm;各种不同的信息

1579
01:31:37.992 --> 01:31:40,995
&lrm;我会在推特上关注我不认同的人

1580
01:31:41.078 --> 01:31:44,207
&lrm;因为我想看到不同的观点

1581
01:31:44.665 --> 01:31:46,584
&lrm;要知道 技术行业中的很多人

1582
01:31:46.667 --> 01:31:49,045
&lrm;不会把这些设备给他们自己的小孩用

1583
01:31:49.128 --> 01:31:51,047
&lrm;我的孩子们完全不使用社交媒体

1584
01:31:51.964 --> 01:31:53,549
&lrm;这是规定 还是…

1585
01:31:53.633 --> 01:31:54,509
&lrm;家规

1586
01:31:55.092 --> 01:31:57,845
&lrm;我们对它很狂热

1587
01:31:57.929 --> 01:31:59,222
&lrm;我们很疯狂

1588
01:31:59.305 --> 01:32:05,603
&lrm;我们不会让我们的孩子
&lrm;拥有任何看屏幕的时间

1589
01:32:05.686 --> 01:32:08,564
&lrm;我想出了
&lrm;我自己认为的三个简单原则

1590
01:32:08.648 --> 01:32:12,610
&lrm;能让生活对家人来说更容易
&lrm;这是经过研究验证的

1591
01:32:12.693 --> 01:32:15,571
&lrm;第一个原则是
&lrm;在每晚的固定时间 所有设备

1592
01:32:15.655 --> 01:32:17,281
&lrm;不能进入卧室

1593
01:32:17.365 --> 01:32:20,535
&lrm;不管是什么时间 睡前半小时
&lrm;所有设备全都拿出去

1594
01:32:20.618 --> 01:32:24,038
&lrm;第二个原则是
&lrm;高中之前禁止使用社交媒体

1595
01:32:24.121 --> 01:32:26,374
&lrm;我个人认为 这个年龄应该是16岁

1596
01:32:26.457 --> 01:32:28,960
&lrm;初中已经够难了 上高中之前别用了

1597
01:32:29.043 --> 01:32:32,964
&lrm;第三个原则是
&lrm;和你的孩子研究出一个时间预算

1598
01:32:33.047 --> 01:32:34,757
&lrm;如果你和他们聊 去说

1599
01:32:34.840 --> 01:32:37,927
&lrm;“你每天想在你的设备上花多少时间

1600
01:32:38.010 --> 01:32:39,637
&lrm;你觉得适合的时长是多少”

1601
01:32:39.720 --> 01:32:41,597
&lrm;他们通常会说出一个很合理的时长

1602
01:32:42.056 --> 01:32:44,642
&lrm;看 我非常清楚

1603
01:32:44.725 --> 01:32:48,563
&lrm;我无法让所有人删除社交媒体账号

1604
01:32:48.646 --> 01:32:50,439
&lrm;但我想我可以让几个人这样做

1605
01:32:50.523 --> 01:32:54,402
&lrm;让几个人删除账号
&lrm;就已经能产生很大影响了

1606
01:32:54.485 --> 01:32:58,406
&lrm;理由是 这样能创造一个对话的空间

1607
01:32:58.489 --> 01:33:00,908
&lrm;因为我想让社会中有足够的人

1608
01:33:00.992 --> 01:33:05,204
&lrm;这些人不受到引擎的操纵
&lrm;能够进行社交对话

1609
01:33:05.288 --> 01:33:07,540
&lrm;没有受到操纵引擎的牵制

1610
01:33:07.623 --> 01:33:10,126
&lrm;这样做吧！退出这个体系

1611
01:33:10.209 --> 01:33:12,503
&lrm;对 删掉 下线这个愚蠢的东西

1612
01:33:13.546 --> 01:33:16,507
&lrm;世界很美丽 你们看
&lrm;外面的世界很美好

1613
01:33:18.467 --> 01:33:19,969
&lrm;（在社交媒体上关注我们！）

1614
01:33:20.052 --> 01:33:21,887
&lrm;（开玩笑的）

1615
01:33:21.971 --> 01:33:27,476
&lrm;（我们来聊聊怎样解决这个问题
&lrm;登录TheSocialDilemma.com）

1616
01:33:32.064 --> 01:33:34,609
&lrm;字幕翻译：王成成
